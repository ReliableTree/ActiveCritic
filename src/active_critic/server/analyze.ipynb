{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hendrik/anaconda3/envs/ac/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2022-11-14 01:39:34.122156: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/home/hendrik/anaconda3/envs/ac/lib/python3.10/site-packages/gym/spaces/box.py:73: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch as th\n",
    "from active_critic.learner.active_critic_learner import ActiveCriticLearner, ACLScores\n",
    "from active_critic.learner.active_critic_args import ActiveCriticLearnerArgs\n",
    "from active_critic.policy.active_critic_policy import ActiveCriticPolicy\n",
    "from active_critic.utils.gym_utils import make_vec_env, DummyExtractor, new_epoch_reach, sample_expert_transitions, parse_sampled_transitions\n",
    "from active_critic.utils.pytorch_utils import build_tf_horizon_mask\n",
    "from active_critic.utils.dataset import DatasetAC\n",
    "from active_critic.policy.active_critic_policy import ActiveCriticPolicySetup, ActiveCriticPolicy\n",
    "from active_critic.model_src.state_model import *\n",
    "from active_critic.model_src.whole_sequence_model import WholeSequenceModel, WholeSequenceModelArgs\n",
    "from active_critic.model_src.transformer import ModelSetup\n",
    "\n",
    "\n",
    "from gym import Env\n",
    "th.manual_seed(0)\n",
    "\n",
    "class DummyStateModel(StateModel):\n",
    "    def __init__(self, args: StateModelArgs) -> None:\n",
    "        super().__init__(args)\n",
    "\n",
    "    def forward(self, inpt):\n",
    "        super().forward(inpt)\n",
    "        return inpt\n",
    "\n",
    "def make_wsm_setup(seq_len, d_output, device='cpu'):\n",
    "    wsm = WholeSequenceModelArgs()\n",
    "    wsm.model_setup = ModelSetup()\n",
    "    seq_len = seq_len\n",
    "    d_output = d_output\n",
    "    wsm.model_setup.d_output = d_output\n",
    "    wsm.model_setup.nhead = 1\n",
    "    wsm.model_setup.d_hid = 200\n",
    "    wsm.model_setup.d_model = 200\n",
    "    wsm.model_setup.nlayers = 3\n",
    "    wsm.model_setup.seq_len = seq_len\n",
    "    wsm.model_setup.dropout = 0\n",
    "    wsm.lr = 1e-3\n",
    "    wsm.model_setup.device = device\n",
    "    wsm.optimizer_class = th.optim.Adam\n",
    "    wsm.optimizer_kwargs = {}\n",
    "    return wsm\n",
    "\n",
    "def make_acps(seq_len, extractor, new_epoch, batch_size, device, horizon):\n",
    "    acps = ActiveCriticPolicySetup()\n",
    "    acps.device=device\n",
    "    acps.epoch_len=seq_len\n",
    "    acps.extractor=extractor\n",
    "    acps.new_epoch=new_epoch\n",
    "    acps.opt_steps=100\n",
    "    acps.inference_opt_lr = 1e-2\n",
    "    acps.optimizer_class = th.optim.SGD\n",
    "    acps.optimize = True\n",
    "    acps.batch_size = batch_size\n",
    "    acps.pred_mask = build_tf_horizon_mask(seq_len=seq_len, horizon=horizon, device=device)\n",
    "    acps.opt_mask = th.zeros([seq_len], device=device, dtype=bool)\n",
    "    acps.opt_mask[-1] = 1\n",
    "    acps.opt_goal = True\n",
    "    acps.optimize_goal_emb_acts = False\n",
    "    acps.goal_label_multiplier = 1\n",
    "    return acps\n",
    "\n",
    "def setup_opt_state(batch_size, seq_len, device='cpu'):\n",
    "    num_cpu = 1\n",
    "    env, expert = make_vec_env('reach', num_cpu, seq_len=seq_len)\n",
    "    d_output = env.action_space.shape[0]\n",
    "    embed_dim = 39\n",
    "    lr = 5e-4\n",
    "\n",
    "    actor_args = StateModelArgs()\n",
    "    actor_args.arch = [512,512, env.action_space.shape[0]]\n",
    "    actor_args.device = device\n",
    "    actor_args.lr = lr\n",
    "    actor = StateModel(args=actor_args)\n",
    "\n",
    "    critic_args = StateModelArgs()\n",
    "    critic_args.arch = [512,512, 1]\n",
    "    critic_args.device = device\n",
    "    critic_args.lr = lr\n",
    "    critic = StateModel(args=critic_args)\n",
    "\n",
    "    inv_critic_args = StateModelArgs()\n",
    "    inv_critic_args.arch = [200, embed_dim + env.action_space.shape[0]]\n",
    "    inv_critic_args.device = device\n",
    "    inv_critic_args.lr = lr\n",
    "    inv_critic = StateModel(args=inv_critic_args)\n",
    "\n",
    "    emitter_args = StateModelArgs()\n",
    "    emitter_args.arch = [200, 200, embed_dim]\n",
    "    emitter_args.device = device\n",
    "    emitter_args.lr = lr\n",
    "    #emitter = StateModel(args=emitter_args)\n",
    "    emitter = DummyStateModel(args=emitter_args)\n",
    "\n",
    "    predictor_args = make_wsm_setup(\n",
    "    seq_len=seq_len, d_output=embed_dim, device=device)\n",
    "    predictor_args.model_setup.d_hid = 1024\n",
    "    predictor_args.model_setup.d_model = 1024\n",
    "    predictor_args.model_setup.nlayers = 4\n",
    "    predictor_args.model_setup.nhead = 16\n",
    "    predictor_args.lr = 5e-4\n",
    "    predictor = WholeSequenceModel(args=predictor_args)\n",
    "\n",
    "    horizon = seq_len\n",
    "\n",
    "\n",
    "    acps = make_acps(\n",
    "        seq_len=seq_len, \n",
    "        extractor=DummyExtractor(), \n",
    "        new_epoch=new_epoch_reach, \n",
    "        device=device, \n",
    "        batch_size=batch_size,\n",
    "        horizon=horizon)\n",
    "    acps.clip = False\n",
    "    ac = ActiveCriticPolicy(observation_space=env.observation_space, \n",
    "                            action_space=env.action_space,\n",
    "                            actor=actor,\n",
    "                            critic=critic,\n",
    "                            predictor=predictor,\n",
    "                            emitter=emitter,\n",
    "                            inverse_critic=inv_critic,\n",
    "                            acps=acps)\n",
    "    return ac, acps, batch_size, seq_len, env, expert\n",
    "\n",
    "\n",
    "def make_acl(device):\n",
    "    device = device\n",
    "    acla = ActiveCriticLearnerArgs()\n",
    "    #acla.data_path = '/home/hendrik/Documents/master_project/LokalData/WSM/'\n",
    "    acla.data_path = '/data/bing/hendrik/'\n",
    "    acla.device = device\n",
    "    acla.extractor = DummyExtractor()\n",
    "    acla.imitation_phase = False\n",
    "    acla.logname = 'push data trough 40'\n",
    "    acla.tboard = True\n",
    "    acla.batch_size = 32\n",
    "    acla.validation_episodes = 40\n",
    "    acla.training_epsiodes = 1\n",
    "    acla.actor_threshold = 1e-2\n",
    "    acla.critic_threshold = 1e-3\n",
    "    acla.predictor_threshold = 1e-2\n",
    "    acla.gen_scores_threshold = 1\n",
    "    acla.loss_auto_predictor_threshold = 1e-3\n",
    "    acla.num_cpu = acla.validation_episodes\n",
    "    acla.use_pain = True\n",
    "    acla.patients = 1000\n",
    "    \n",
    "    seq_len = 100\n",
    "    ac, acps, batch_size, seq_len, env, expert= setup_opt_state(device=device, batch_size=acla.batch_size, seq_len=seq_len)\n",
    "    \n",
    "    acps.opt_steps = 0\n",
    "    acla.val_every = 1\n",
    "    acla.add_data_every = 1\n",
    "\n",
    "    \n",
    "\n",
    "    eval_env, expert = make_vec_env('reach', num_cpu=acla.num_cpu, seq_len=seq_len)\n",
    "    acl = ActiveCriticLearner(ac_policy=ac, env=env, eval_env=eval_env, network_args_obj=acla)\n",
    "    return acl, env, expert, seq_len, device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hendrik/anaconda3/envs/ac/lib/python3.10/site-packages/gym/spaces/box.py:73: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  logger.warn(\n",
      "/home/hendrik/anaconda3/envs/ac/lib/python3.10/site-packages/gym/spaces/box.py:73: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  logger.warn(\n",
      "/home/hendrik/anaconda3/envs/ac/lib/python3.10/site-packages/gym/spaces/box.py:73: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  logger.warn(\n",
      "/home/hendrik/anaconda3/envs/ac/lib/python3.10/site-packages/gym/spaces/box.py:73: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  logger.warn(\n",
      "/home/hendrik/anaconda3/envs/ac/lib/python3.10/site-packages/gym/spaces/box.py:73: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  logger.warn(\n",
      "2022-11-14 01:39:40.266589: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "acl, env, expert, seq_len, device = make_acl(device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acl.policy.args_obj.goal_label_multiplier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hendrik/anaconda3/envs/ac/lib/python3.10/site-packages/gym/spaces/box.py:73: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling transitions. 2\n",
      " |███████████████████████████████████████████████████████████████████████████████████████████████████-| 99.0% Predicting Epsiode\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hendrik/Documents/master_project/Code/active_critic/src/active_critic/utils/gym_utils.py:187: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  actions = th.tensor(actions, dtype=th.float, device=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/hendrik/Documents/master_project/LokalData/WSM/push data trough 20/best_validation\n",
      "Success Rate: 0.0\n",
      "Reward: 0.057259440422058105\n",
      "training samples: 0\n",
      "Sampling transitions. 1\n",
      "Training Reward: tensor([[0.0554]], device='cuda:0')█████████████████████████████████████████████████-| 99.0% Predicting Epsiode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hendrik/Documents/master_project/Code/active_critic/src/active_critic/learner/active_critic_learner.py:165: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.write_tboard_scalar({'Pain': th.tensor(pain)}, train=True, step=self.pain_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling transitions. 1\n",
      "Training Reward: tensor([[0.0277]], device='cuda:0')█████████████████████████████████████████████████-| 99.0% Predicting Epsiode\n",
      "Sampling transitions. 2\n",
      "Success Rate: 0.0████████████████████████████████████████████████████████████████████████████████████-| 99.0% Predicting Epsiode\n",
      "Reward: 0.040860578417778015\n",
      "training samples: 2\n",
      "Sampling transitions. 1\n",
      "Training Reward: tensor([[0.0309]], device='cuda:0')█████████████████████████████████████████████████-| 99.0% Predicting Epsiode\n",
      "Sampling transitions. 2\n",
      "Success Rate: 0.0████████████████████████████████████████████████████████████████████████████████████-| 99.0% Predicting Epsiode\n",
      "Reward: 0.03123351000249386\n",
      "training samples: 3\n",
      "Sampling transitions. 1\n",
      "Training Reward: tensor([[0.0276]], device='cuda:0')█████████████████████████████████████████████████-| 99.0% Predicting Epsiode\n",
      "Sampling transitions. 2\n",
      "Success Rate: 0.0████████████████████████████████████████████████████████████████████████████████████-| 99.0% Predicting Epsiode\n",
      "Reward: 0.01808241754770279\n",
      "training samples: 4\n",
      "Sampling transitions. 1\n",
      "Training Reward: tensor([[0.0178]], device='cuda:0')█████████████████████████████████████████████████-| 99.0% Predicting Epsiode\n",
      "Sampling transitions. 2\n",
      "Success Rate: 0.0████████████████████████████████████████████████████████████████████████████████████-| 99.0% Predicting Epsiode\n",
      "Reward: 0.04068562388420105\n",
      "training samples: 5\n",
      "Sampling transitions. 1\n",
      "Training Reward: tensor([[0.0275]], device='cuda:0')█████████████████████████████████████████████████-| 99.0% Predicting Epsiode\n",
      "Sampling transitions. 2\n",
      "Success Rate: 0.0████████████████████████████████████████████████████████████████████████████████████-| 99.0% Predicting Epsiode\n",
      "Reward: 0.03769746050238609\n",
      "training samples: 6\n",
      "Sampling transitions. 1\n",
      "Training Reward: tensor([[0.0424]], device='cuda:0')█████████████████████████████████████████████████-| 99.0% Predicting Epsiode\n",
      "Sampling transitions. 2\n",
      "Success Rate: 0.0████████████████████████████████████████████████████████████████████████████████████-| 99.0% Predicting Epsiode\n",
      "Reward: 0.04815054312348366\n",
      "training samples: 7\n",
      "Sampling transitions. 1\n",
      "Training Reward: tensor([[0.0395]], device='cuda:0')█████████████████████████████████████████████████-| 99.0% Predicting Epsiode\n",
      "Sampling transitions. 2\n",
      "Success Rate: 0.0████████████████████████████████████████████████████████████████████████████████████-| 99.0% Predicting Epsiode\n",
      "Reward: 0.04459378868341446\n",
      "training samples: 8\n",
      "Sampling transitions. 1\n",
      "Training Reward: tensor([[0.0380]], device='cuda:0')█████████████████████████████████████████████████-| 99.0% Predicting Epsiode\n",
      "Sampling transitions. 2\n",
      "Success Rate: 0.0████████████████████████████████████████████████████████████████████████████████████-| 99.0% Predicting Epsiode\n",
      "Reward: 0.04216035455465317\n",
      "training samples: 9\n",
      "Sampling transitions. 1\n",
      "Training Reward: tensor([[0.0432]], device='cuda:0')█████████████████████████████████████████████████-| 99.0% Predicting Epsiode\n",
      "Sampling transitions. 2\n",
      "Success Rate: 0.0████████████████████████████████████████████████████████████████████████████████████-| 99.0% Predicting Epsiode\n",
      "Reward: 0.036488763988018036\n",
      "training samples: 10\n",
      "Sampling transitions. 1\n",
      "Training Reward: tensor([[0.0290]], device='cuda:0')█████████████████████████████████████████████████-| 99.0% Predicting Epsiode\n",
      "Sampling transitions. 2\n",
      "Success Rate: 0.0████████████████████████████████████████████████████████████████████████████████████-| 99.0% Predicting Epsiode\n",
      "Reward: 0.03064633347094059\n",
      "training samples: 11\n",
      "Sampling transitions. 1\n",
      "Training Reward: tensor([[0.0386]], device='cuda:0')█████████████████████████████████████████████████-| 99.0% Predicting Epsiode\n",
      "Sampling transitions. 2\n",
      "Success Rate: 0.0████████████████████████████████████████████████████████████████████████████████████-| 99.0% Predicting Epsiode\n",
      "Reward: 0.032212696969509125\n",
      "training samples: 12\n",
      "Sampling transitions. 1\n",
      "Training Reward: tensor([[0.0415]], device='cuda:0')█████████████████████████████████████████████████-| 99.0% Predicting Epsiode\n",
      "Sampling transitions. 2\n",
      "Success Rate: 0.0████████████████████████████████████████████████████████████████████████████████████-| 99.0% Predicting Epsiode\n",
      "Reward: 0.04091397672891617\n",
      "training samples: 13\n",
      "Sampling transitions. 1\n",
      "Training Reward: tensor([[0.0573]], device='cuda:0')█████████████████████████████████████████████████-| 99.0% Predicting Epsiode\n",
      "Sampling transitions. 2\n",
      "Success Rate: 0.0████████████████████████████████████████████████████████████████████████████████████-| 99.0% Predicting Epsiode\n",
      "Reward: 0.054562583565711975\n",
      "training samples: 14\n",
      "Sampling transitions. 1\n",
      "Training Reward: tensor([[0.0426]], device='cuda:0')█████████████████████████████████████████████████-| 99.0% Predicting Epsiode\n",
      "Sampling transitions. 2\n",
      "Success Rate: 0.0████████████████████████████████████████████████████████████████████████████████████-| 99.0% Predicting Epsiode\n",
      "Reward: 0.040716033428907394\n",
      "training samples: 15\n",
      "Sampling transitions. 1\n",
      "Training Reward: tensor([[0.0379]], device='cuda:0')█████████████████████████████████████████████████-| 99.0% Predicting Epsiode\n",
      "Sampling transitions. 2\n",
      "Success Rate: 0.0████████████████████████████████████████████████████████████████████████████████████-| 99.0% Predicting Epsiode\n",
      "Reward: 0.05061452463269234\n",
      "training samples: 16\n",
      "Sampling transitions. 1\n",
      "Training Reward: tensor([[0.0717]], device='cuda:0')█████████████████████████████████████████████████-| 99.0% Predicting Epsiode\n",
      "Sampling transitions. 2\n",
      "Success Rate: 0.0████████████████████████████████████████████████████████████████████████████████████-| 99.0% Predicting Epsiode\n",
      "Reward: 0.031518541276454926\n",
      "training samples: 17\n",
      "Sampling transitions. 1\n",
      "Training Reward: tensor([[0.0383]], device='cuda:0')█████████████████████████████████████████████████-| 99.0% Predicting Epsiode\n",
      "Sampling transitions. 2\n",
      "Success Rate: 0.0████████████████████████████████████████████████████████████████████████████████████-| 99.0% Predicting Epsiode\n",
      "Reward: 0.04159051179885864\n",
      "training samples: 18\n",
      "Sampling transitions. 1\n",
      "Training Reward: tensor([[0.0343]], device='cuda:0')█████████████████████████████████████████████████-| 99.0% Predicting Epsiode\n",
      "Sampling transitions. 2\n",
      "Success Rate: 0.0████████████████████████████████████████████████████████████████████████████████████-| 99.0% Predicting Epsiode\n",
      "Reward: 0.03601974993944168\n",
      "training samples: 19\n",
      "Sampling transitions. 1\n",
      "Training Reward: tensor([[0.0548]], device='cuda:0')█████████████████████████████████████████████████-| 99.0% Predicting Epsiode\n",
      "Sampling transitions. 2\n",
      "Success Rate: 0.0████████████████████████████████████████████████████████████████████████████████████-| 99.0% Predicting Epsiode\n",
      "Reward: 0.03760422021150589\n",
      "training samples: 20\n",
      "Sampling transitions. 1\n",
      "Training Reward: tensor([[0.0354]], device='cuda:0')█████████████████████████████████████████████████-| 99.0% Predicting Epsiode\n",
      "Sampling transitions. 2\n",
      "Success Rate: 0.0████████████████████████████████████████████████████████████████████████████████████-| 99.0% Predicting Epsiode\n",
      "Reward: 0.040438391268253326\n",
      "training samples: 21\n",
      "Sampling transitions. 1\n",
      "Training Reward: tensor([[0.0322]], device='cuda:0')█████████████████████████████████████████████████-| 99.0% Predicting Epsiode\n",
      "Sampling transitions. 2\n",
      "Success Rate: 0.0████████████████████████████████████████████████████████████████████████████████████-| 99.0% Predicting Epsiode\n",
      "Reward: 0.04342265799641609\n",
      "training samples: 22\n",
      "Sampling transitions. 1\n",
      "Training Reward: tensor([[0.0394]], device='cuda:0')█████████████████████████████████████████████████-| 99.0% Predicting Epsiode\n",
      "Sampling transitions. 2\n",
      "Success Rate: 0.0████████████████████████████████████████████████████████████████████████████████████-| 99.0% Predicting Epsiode\n",
      "Reward: 0.04889941215515137\n",
      "training samples: 23\n",
      "Sampling transitions. 1\n",
      "Training Reward: tensor([[0.0427]], device='cuda:0')█████████████████████████████████████████████████-| 99.0% Predicting Epsiode\n",
      "Sampling transitions. 2\n",
      "/home/hendrik/Documents/master_project/LokalData/WSM/push data trough 20/best_validation█████████████-| 99.0% Predicting Epsiode\n",
      "Success Rate: 0.0\n",
      "Reward: 0.05851075053215027\n",
      "training samples: 24\n",
      "Sampling transitions. 1\n",
      "Training Reward: tensor([[0.0730]], device='cuda:0')█████████████████████████████████████████████████-| 99.0% Predicting Epsiode\n",
      "Sampling transitions. 2\n",
      "/home/hendrik/Documents/master_project/LokalData/WSM/push data trough 20/best_validation█████████████-| 99.0% Predicting Epsiode\n",
      "Success Rate: 0.0\n",
      "Reward: 0.3712944984436035\n",
      "training samples: 25\n",
      "Sampling transitions. 1\n",
      "Training Reward: tensor([[0.3457]], device='cuda:0')█████████████████████████████████████████████████-| 99.0% Predicting Epsiode\n",
      "Sampling transitions. 2\n",
      "Success Rate: 0.0████████████████████████████████████████████████████████████████████████████████████-| 99.0% Predicting Epsiode\n",
      "Reward: 0.16860046982765198\n",
      "training samples: 26\n",
      "Sampling transitions. 1\n",
      "Training Reward: tensor([[0.0975]], device='cuda:0')█████████████████████████████████████████████████-| 99.0% Predicting Epsiode\n"
     ]
    }
   ],
   "source": [
    "acl.train(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_env, expert = make_vec_env('reach', num_cpu=1, seq_len=seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acl.policy.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = eval_env.reset()\n",
    "action = acl.policy.predict(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acl.policy.history.scores[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acl.policy.history.emb[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings, actions = acl.policy.build_sequence(\n",
    "                embeddings=acl.policy.current_embeddings, \n",
    "                actions=actions[:,:0], \n",
    "                seq_len=10, \n",
    "                goal_emb_acts=acl.policy.goal_emb_acts,\n",
    "                goal_state=None,\n",
    "                tf_mask=acl.policy.args_obj.pred_mask,\n",
    "                actor=acl.policy.actor,\n",
    "                predictor=acl.policy.predicor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acl.policy.eval()\n",
    "acl.policy.reset()\n",
    "seq_len = acl.policy.args_obj.epoch_len\n",
    "transitions = sample_expert_transitions(\n",
    "    acl.policy.predict, eval_env, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions, observations, rewards = parse_sampled_transitions(\n",
    "            transitions=transitions, extractor=acl.policy.args_obj.extractor, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = acl.policy.emitter.forward(observations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "critic_input = acl.policy.get_critic_input(embeddings=embeddings, actions=actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = acl.policy.critic.forward(critic_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calcMSE(scores, rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observations.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acl.policy.history.emb[0][:,0,-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_env, expert = make_vec_env('reach', num_cpu=1, seq_len=seq_len)\n",
    "acl.policy.reset()\n",
    "obs = eval_env.reset()\n",
    "action = acl.policy.predict(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings, actions = acl.policy.build_sequence(\n",
    "    embeddings=acl.policy.current_embeddings, \n",
    "    actions=None, \n",
    "    seq_len=seq_len, \n",
    "    goal_emb_acts=acl.policy.goal_emb_acts,\n",
    "    goal_state=None,\n",
    "    tf_mask=acl.policy.args_obj.pred_mask,\n",
    "    actor=acl.policy.actor,\n",
    "    predictor=acl.policy.predicor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = acl.policy.critic.forward(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_step = 49\n",
    "predicotr_input = acl.policy.get_predictor_input(embeddings[:,:current_step], actions[:,:current_step])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_states, attention = acl.policy.predicor.model.forward(src=predicotr_input, mask = acl.policy.args_obj.pred_mask[:current_step,:current_step], return_attention=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set_ylabel('Query')\n",
    "ax.set_xlabel('Key')\n",
    "cax = ax.matshow(attention[0].to('cpu'), interpolation='nearest')\n",
    "fig.colorbar(cax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set_ylabel('Query')\n",
    "ax.set_xlabel('Key')\n",
    "cax = ax.matshow(attention[0].to('cpu'), interpolation='nearest')\n",
    "fig.colorbar(cax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('ac')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c27e8fa6375f4d15af5a5f5541d8bb88746b588c9fe1102cfd8de011d36c10c2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
