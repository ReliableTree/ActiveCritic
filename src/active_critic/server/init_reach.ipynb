{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from active_critic.server.analyze import make_acl\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'\n",
    "acl, env, expert, seq_len, epsiodes, device = make_acl(device, env_tag='reach', logname='test_plots')\n",
    "acl.train(epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acl.train_data.reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "th.all(acl.train_data.obsv[0][1:] == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acl.policy.eval()\n",
    "acl.policy.reset()\n",
    "obs = env.reset()\n",
    "transitions = sample_expert_transitions(policy=acl.policy.predict, env=env, episodes=1)\n",
    "attention = acl.policy.critic.attention\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set_ylabel('Query')\n",
    "ax.set_xlabel('Key')\n",
    "cax = ax.matshow(attention[0].to('cpu'), interpolation='nearest')\n",
    "fig.colorbar(cax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "can't retain_grad on Tensor that has requires_grad=False",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [17], line 26\u001b[0m\n\u001b[1;32m     24\u001b[0m steps \u001b[39m=\u001b[39m th\u001b[39m.\u001b[39mzeros([batch_size], dtype\u001b[39m=\u001b[39m\u001b[39mbool\u001b[39m)\n\u001b[1;32m     25\u001b[0m a \u001b[39m=\u001b[39m proj_actions(\u001b[39mself\u001b[39m\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, org_actions\u001b[39m=\u001b[39mb, new_actions\u001b[39m=\u001b[39ma, steps\u001b[39m=\u001b[39msteps)\n\u001b[0;32m---> 26\u001b[0m a\u001b[39m.\u001b[39;49mretain_grad()\n",
      "\u001b[0;31mRuntimeError\u001b[0m: can't retain_grad on Tensor that has requires_grad=False"
     ]
    }
   ],
   "source": [
    "import torch as th\n",
    "\n",
    "def make_step_mask(steps, seq_len, device):\n",
    "    indices_tensor = th.arange(seq_len, device=device).unsqueeze(0)\n",
    "    mask = indices_tensor < steps[:, None]\n",
    "    return mask\n",
    "\n",
    "def proj_actions(self, org_actions: th.Tensor, new_actions: th.Tensor, steps: int):\n",
    "    with th.no_grad():\n",
    "        device = org_actions.device\n",
    "        step_input = steps + 1\n",
    "        step_input[step_input == 1] = 0\n",
    "        mask = make_step_mask(steps=step_input, seq_len=org_actions.shape[1], device=device)\n",
    "\n",
    "        new_actions[mask] = org_actions[mask]\n",
    "    return new_actions\n",
    "\n",
    "batch_size = 3\n",
    "seq_len = 4\n",
    "dim = 2\n",
    "\n",
    "a = th.rand([batch_size, seq_len, dim])\n",
    "b = th.rand([batch_size, seq_len, dim], requires_grad=True)\n",
    "steps = th.zeros([batch_size], dtype=bool)\n",
    "a = proj_actions(self=None, org_actions=b, new_actions=a, steps=steps)\n",
    "a.retain_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = ((a-th.ones_like(a))**2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0796, -0.0142],\n",
       "         [-0.0500, -0.0380],\n",
       "         [-0.0789, -0.0299],\n",
       "         [-0.0714, -0.0559]],\n",
       "\n",
       "        [[-0.0537, -0.0786],\n",
       "         [-0.0754, -0.0034],\n",
       "         [-0.0497, -0.0448],\n",
       "         [-0.0582, -0.0185]],\n",
       "\n",
       "        [[-0.0370, -0.0398],\n",
       "         [-0.0300, -0.0797],\n",
       "         [-0.0032, -0.0080],\n",
       "         [-0.0605, -0.0485]]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.backward()\n",
    "a.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('ac')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c27e8fa6375f4d15af5a5f5541d8bb88746b588c9fe1102cfd8de011d36c10c2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
