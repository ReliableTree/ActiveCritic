{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as th\n",
    "from active_critic.learner.active_critic_learner import ActiveCriticLearner, ACLScores\n",
    "from active_critic.learner.active_critic_args import ActiveCriticLearnerArgs\n",
    "from active_critic.policy.active_critic_policy import ActiveCriticPolicy\n",
    "from active_critic.utils.gym_utils import make_dummy_vec_env, make_policy_dict, parse_sampled_transitions, sample_expert_transitions \\\n",
    "    ,DummyExtractor, new_epoch_reach, sample_new_episode, make_policy_dict, TimeLimit, RolloutInfoWrapper, ImitationLearningWrapper, \\\n",
    "        make_vec_env\n",
    "from active_critic.utils.pytorch_utils import make_part_obs_data, count_parameters\n",
    "from active_critic.utils.dataset import DatasetAC\n",
    "from stable_baselines3.common.policies import BasePolicy\n",
    "from stable_baselines3.common.torch_layers import BaseFeaturesExtractor\n",
    "from active_critic.utils.dataset import DatasetAC\n",
    "from active_critic.model_src.whole_sequence_model import (\n",
    "    WholeSequenceModelSetup, WholeSequenceModel)\n",
    "from active_critic.model_src.transformer import (\n",
    "    ModelSetup, generate_square_subsequent_mask)\n",
    "from active_critic.policy.active_critic_policy import ActiveCriticPolicySetup, ActiveCriticPolicy\n",
    "from metaworld.envs import ALL_V2_ENVIRONMENTS_GOAL_OBSERVABLE\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, SubprocVecEnv\n",
    "import numpy as np\n",
    "from gym import Env\n",
    "th.manual_seed(0)\n",
    "\n",
    "\n",
    "def make_wsm_setup(seq_len, d_output, device='cuda'):\n",
    "    wsm = WholeSequenceModelSetup()\n",
    "    wsm.model_setup = ModelSetup()\n",
    "    seq_len = seq_len\n",
    "    d_output = d_output\n",
    "    wsm.model_setup.d_output = d_output\n",
    "    wsm.model_setup.nhead = 1\n",
    "    wsm.model_setup.d_hid = 512\n",
    "    wsm.model_setup.d_model = 512\n",
    "    wsm.model_setup.nlayers = 4\n",
    "    wsm.model_setup.seq_len = seq_len\n",
    "    wsm.model_setup.dropout = 0\n",
    "    wsm.lr = 1e-4\n",
    "    wsm.model_setup.device = device\n",
    "    wsm.optimizer_class = th.optim.Adam\n",
    "    wsm.optimizer_kwargs = {}\n",
    "    return wsm\n",
    "\n",
    "\n",
    "def make_acps(seq_len, extractor, new_epoch, batch_size=32):\n",
    "    acps = ActiveCriticPolicySetup()\n",
    "    acps.device = 'cuda'\n",
    "    acps.epoch_len = seq_len\n",
    "    acps.extractor = extractor\n",
    "    acps.new_epoch = new_epoch\n",
    "    acps.opt_steps = 100\n",
    "    acps.optimisation_threshold = 0.95\n",
    "    acps.inference_opt_lr = 5e-2\n",
    "    acps.optimize = True\n",
    "    acps.batch_size = 32\n",
    "    return acps\n",
    "\n",
    "\n",
    "def setup_ac_reach(seq_len, num_cpu):\n",
    "    seq_len = seq_len\n",
    "    env, expert = make_vec_env('reach', num_cpu, seq_len=seq_len)\n",
    "    d_output = env.action_space.shape[0]\n",
    "    wsm_actor_setup = make_wsm_setup(\n",
    "        seq_len=seq_len, d_output=d_output)\n",
    "    wsm_critic_setup = make_wsm_setup(\n",
    "        seq_len=seq_len, d_output=1)\n",
    "    acps = make_acps(\n",
    "        seq_len=seq_len, extractor=DummyExtractor(), new_epoch=new_epoch_reach)\n",
    "    actor = WholeSequenceModel(wsm_actor_setup)\n",
    "    critic = WholeSequenceModel(wsm_critic_setup)\n",
    "    ac = ActiveCriticPolicy(observation_space=env.observation_space, action_space=env.action_space,\n",
    "                            actor=actor, critic=critic, acps=acps)\n",
    "    return ac, acps, env, expert\n",
    "\n",
    "\n",
    "def make_acl():\n",
    "    device = 'cuda'\n",
    "    acla = ActiveCriticLearnerArgs()\n",
    "    acla.data_path = '/home/hendrik/Documents/master_project/LokalData/TransformerImitationLearning/'\n",
    "    acla.device = device\n",
    "    acla.extractor = DummyExtractor()\n",
    "    acla.imitation_phase = False\n",
    "    acla.logname = 'reach_org_test'\n",
    "    acla.tboard = True\n",
    "    acla.batch_size = 32\n",
    "    acla.val_every = 10\n",
    "    acla.add_data_every = 1\n",
    "    acla.validation_episodes = 10\n",
    "    acla.training_epsiodes = 4\n",
    "    acla.actor_threshold = 5e-2\n",
    "    acla.critic_threshold = 5e-2\n",
    "    acla.num_cpu = 5\n",
    "    seq_len = 10\n",
    "    ac, acps, env, expert = setup_ac_reach(seq_len=seq_len, num_cpu=acla.num_cpu)\n",
    "    acl = ActiveCriticLearner(ac_policy=ac, env=env, eval_env=env, network_args_obj=acla)\n",
    "    return acl, env, expert, seq_len, device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acl, env, expert, seq_len, device = make_acl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling expert transitions. 4\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [15], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m acl\u001b[39m.\u001b[39madd_training_data()\n\u001b[0;32m----> 2\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mlen\u001b[39m(acl\u001b[39m.\u001b[39mtrain_data) \u001b[39m==\u001b[39m acl\u001b[39m.\u001b[39mnetwork_args\u001b[39m.\u001b[39mtraining_epsiodes \u001b[39m*\u001b[39m seq_len\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "acl.add_training_data()\n",
    "assert len(acl.train_data) == acl.network_args.training_epsiodes * seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling expert transitions. 10\n"
     ]
    }
   ],
   "source": [
    "opt_actions, gen_actions, observations, rewards, expected_rewards_before, expected_rewards_after = sample_new_episode(acl.policy, env, episodes=acl.network_args.validation_episodes, return_gen_trj=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert list(opt_actions.shape) == [acl.network_args.validation_episodes, seq_len, env.action_space.shape[0]]\n",
    "assert list(gen_actions.shape) == [acl.network_args.validation_episodes, seq_len, env.action_space.shape[0]]\n",
    "assert list(observations.shape) == [acl.network_args.validation_episodes, seq_len, env.observation_space.shape[0]]\n",
    "assert list(rewards.shape) == [acl.network_args.validation_episodes, seq_len, 1]\n",
    "assert list(expected_rewards_before.shape) == [acl.network_args.validation_episodes, seq_len, acl.policy.critic.model.model_setup.d_output]\n",
    "assert list(expected_rewards_after.shape) == [acl.network_args.validation_episodes, seq_len, acl.policy.critic.model.model_setup.d_output]\n",
    "assert th.all(expected_rewards_after.mean(dim=[1,2]) > expected_rewards_before.mean(dim=[1,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('ac')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c27e8fa6375f4d15af5a5f5541d8bb88746b588c9fe1102cfd8de011d36c10c2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
