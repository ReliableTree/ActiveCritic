{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hendrik/anaconda3/envs/tfTest/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2022-10-11 17:13:18.709355: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "/home/hendrik/anaconda3/envs/tfTest/lib/python3.9/site-packages/gym/spaces/box.py:73: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f9f697ee990>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch as th\n",
    "from active_critic.learner.active_critic_learner import ActiveCriticLearner, ACLScores\n",
    "from active_critic.learner.active_critic_args import ActiveCriticLearnerArgs\n",
    "from active_critic.policy.active_critic_policy import ActiveCriticPolicy\n",
    "from active_critic.utils.test_utils import setup_ac_reach\n",
    "from active_critic.utils.gym_utils import make_dummy_vec_env, parse_sampled_transitions, sample_expert_transitions, DummyExtractor, new_epoch_reach, sample_new_episode\n",
    "from active_critic.utils.pytorch_utils import make_part_obs_data\n",
    "from active_critic.utils.dataset import DatasetAC\n",
    "from stable_baselines3.common.policies import BasePolicy\n",
    "from stable_baselines3.common.torch_layers import BaseFeaturesExtractor\n",
    "from active_critic.utils.dataset import DatasetAC\n",
    "from gym import Env\n",
    "th.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-11 17:13:20.466736: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-10-11 17:13:20.466839: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2022-10-11 17:13:20.466926: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-11 17:13:20.467061: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:09:00.0 name: NVIDIA GeForce GTX 1080 computeCapability: 6.1\n",
      "coreClock: 1.7335GHz coreCount: 20 deviceMemorySize: 7.92GiB deviceMemoryBandwidth: 298.32GiB/s\n",
      "2022-10-11 17:13:20.467098: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-10-11 17:13:20.467135: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2022-10-11 17:13:20.467152: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2022-10-11 17:13:20.468158: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-10-11 17:13:20.468309: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-10-11 17:13:20.469202: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-10-11 17:13:20.469706: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-10-11 17:13:20.471755: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-10-11 17:13:20.471823: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-11 17:13:20.472116: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-11 17:13:20.472204: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2022-10-11 17:13:20.472487: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-11 17:13:20.472927: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-10-11 17:13:20.472977: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-11 17:13:20.473076: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:09:00.0 name: NVIDIA GeForce GTX 1080 computeCapability: 6.1\n",
      "coreClock: 1.7335GHz coreCount: 20 deviceMemorySize: 7.92GiB deviceMemoryBandwidth: 298.32GiB/s\n",
      "2022-10-11 17:13:20.473099: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-10-11 17:13:20.473106: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2022-10-11 17:13:20.473112: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2022-10-11 17:13:20.473123: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-10-11 17:13:20.473135: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-10-11 17:13:20.473146: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-10-11 17:13:20.473158: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-10-11 17:13:20.473169: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-10-11 17:13:20.473196: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-11 17:13:20.473302: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-11 17:13:20.473385: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2022-10-11 17:13:20.473409: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-10-11 17:13:20.759250: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-10-11 17:13:20.759274: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2022-10-11 17:13:20.759278: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2022-10-11 17:13:20.759396: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-11 17:13:20.759531: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-11 17:13:20.759639: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-11 17:13:20.759739: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 4295 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce GTX 1080, pci bus id: 0000:09:00.0, compute capability: 6.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n",
      "log dir: /home/hendrik/Documents/master_project/LokalData/TransformerImitationLearning/gboard/test_acl/train/\n",
      "Sampling expert transitions. 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hendrik/Documents/master_project/Code/active_critic/metaworld/metaworld/policies/policy.py:41: UserWarning: Constant(s) may be too high. Environments clip response to [-1, 1]\n",
      "  warnings.warn('Constant(s) may be too high. Environments clip response to [-1, 1]')\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAVqklEQVR4nO3dX4ic9b3H8ffnZBsPBFqL5kLWhWTddHPSNBSdWHvTCr1IIiG50EKWgk1JCMUNvehNhQP9YymnvSpIpJLGoN4k6QlCV+uuSD1BeqHrpGjOLpKTNVmbLBY3WoTSuprley7mSZxM5l93n9nMPL/PCwbmmee3M78fH57PTObPE0UEZmZWfP92sydgZmYrw4VvZpYIF76ZWSJc+GZmiXDhm5klwoVvZpaIloUv6aik9yVNNdgvSY9LmpF0RtLd+U/T8uZci8vZWiPtvMJ/GtjeZP8OYEN2OQD8ZvnTshXwNM61qJ7G2VodLQs/Il4FPmwyZDfwbFS8Btwq6Y68Jmid4VyLy9laI3053Ec/cLFq+1J223u1AyUdoPKKgjVr1tyzcePGHB7elmrz5s3MzMwgaT4i1tbsdq49bPPmzUxNTS022N1Wts61O50+ffpyneO1LXkUftsi4jBwGKBUKkW5XF7Jh7cas7Oz7Ny5k+np6XeXcz/OtfvMzs6yfv36T5dzH861O0la8vGax7d05oCBqu07s9ustznX4nK2icqj8MeAh7NP/u8DPoqIG/7Zbz3HuRaXs01Uy7d0JB0D7gdul3QJ+AnwOYCIeBJ4EXgAmAH+AXyvU5O1/IyMjHDq1CkuX74MsEXSPpxrIVzNFrjFx6xVa1n4ETHSYn8Ao7nNyFbEsWPHrl2XdCYinqre71x719VsJf05Ikq1+51tuvxLWzOzRLjwzcwS4cI3M0uEC9/MLBEufDOzRLjwzcwS4cI3M0uEC9/MLBEufDOzRLjwzcwS4cI3M0uEC9/MLBEufDOzRLjwzcwS4cI3M0uEC9/MLBEufDOzRLjwzcwS4cI3M0uEC9/MLBEufDOzRLjwzcwS4cI3M0tEW4Uvabuks5JmJD1aZ/9eSfOS3swu+/OfquVtYmKC4eFhgM3OtTicqzXSsvAlrQKeAHYAm4ARSZvqDD0REV/NLkdynqflbHFxkdHRUcbHxwGmca6F4FytmXZe4d8LzETE+Yj4BDgO7O7stKzTJicnGRoaYnBwECBwroXgXK2Zdgq/H7hYtX0pu63Wg5LOSDopaaDeHUk6IKksqTw/P7+E6Vpe5ubmGBi4LibnWgDO1ZrJ60Pb54F1EbEFeBl4pt6giDgcEaWIKK1duzanh7YOcq7F5FwT1U7hzwHVrwDuzG67JiI+iIiFbPMIcE8+07NO6e/v5+LF6n+4OdcicK7WTDuF/wawQdJ6SauBPcBY9QBJd1Rt7gLezm+K1glbt27l3LlzXLhwAUA410JwrtZMX6sBEXFF0kHgJWAVcDQipiU9BpQjYgz4gaRdwBXgQ2BvB+dsOejr6+PQoUNs27YN4MvAz51r73Ou1owi4qY8cKlUinK5fFMe264n6XRElPK4L+faPZxrMS0nV//S1swsES58M7NEuPDNzBLhwjczS4QL38wsES58M7NEuPDNzBLhwjczS4QL38wsES58M7NEuPDNzBLhwjczS4QL38wsES58M7NEuPDNzBLhwjczS4QL38wsES58M7NEuPDNzBLhwjczS4QL38wsES58M7NEuPDNzBLRVuFL2i7prKQZSY/W2X+LpBPZ/tclrct9ppa7iYkJhoeHATY71+JwrtZIy8KXtAp4AtgBbAJGJG2qGbYP+FtEDAG/Bn6V90QtX4uLi4yOjjI+Pg4wjXMtBOdqzbTzCv9eYCYizkfEJ8BxYHfNmN3AM9n1k8C3JCm/aVreJicnGRoaYnBwECBwroXgXK2ZvjbG9AMXq7YvAV9rNCYirkj6CLgNuFw9SNIB4EC2uSBpaimT7iK3U7PGHvJF4POS3gWGca7VnCuFzBV6O9urhpf6h+0Ufm4i4jBwGEBSOSJKK/n4eevlNUh6CNgeEfsllZdzX861ezjX5oqwjuXk2s5bOnPAQNX2ndltdcdI6gO+AHyw1EnZinCuxeRcraF2Cv8NYIOk9ZJWA3uAsZoxY8B3s+sPAa9EROQ3TeuAa7kCwrkWhXO1hloWfkRcAQ4CLwFvA7+LiGlJj0nalQ17CrhN0gzwQ+CGr4LVcXiJc+4mPbuGmlwHcK7VenYNzrWlIqxjyWuQn9jNzNLgX9qamSXChW9mloiOF34RTsvQxhr2SpqX9GZ22X8z5tmMpKOS3m/0XWpVPJ6t8Yyku1vcn3PtAs71Rs61iYjo2AVYBbwDDAKrgbeATTVjHgGezK7vAU50ck4dWsNe4NDNnmuLdXwDuBuYarD/AWCcyjc77gNed67O1bn2fq7Vl3bOpbOcZ5oinJahnTV0vYh4Ffjw6nadXHcDz0bFa8Ctko441+5WmyvckG29XO9ocMw61y5RL9cadXNtdb/tvKXzNLC9yf4dwIbscgD4TdW+eqdl6K/5++t+5g1c/Zl3t2hnDQAPZgfPSUkDdfZ3m6e5Ptfadf4T+A+ca6/lCtdnW2+d36b+Metce0e767xOO9/D78gzTcE8D6yLiC3Ay3z2CqhrtZHrWuAPzrW3coW2sv0maR+zPZlrHtr6Hn72wcwLEbG5zr4XgF9GxJ+y7T8CP4qIsqSvAz+NiG3Zvueo/JPrr2vWrLln48aN+a3E/mULCwvMzMzw8ccfXwaeA05FxDEASX8HvhMRv8+2nWsPWVhYYGpqapHKj6yqcz0L/AX4We0xC3wO59r1Tp8+Xe94PQvcHxHvNfvbTp88rfpn3nPAXcC2iJgulUpRLi/r3E62TLOzs+zcuZPp6el3qfzc/qCk41TOrvgpjc+v4ly73OzsLOvXr/+UG3P9CFho8GfOtQeocibUG3JtVfaQz9cyG56sKZqcliGHx7V8vQicB2aA3wKv4FyLoDbXR2hwzDrXnlIv15byKPwx4OHs2zr3UfNMExEvRsSXIuKuiPhFdtuPc3hcy1H2fu5oltNXgKM4155Xm2tElGlyzDrX3tAg15ZavqUj6RhwP3C7pEvAT6i810dEPEnlmeYBKs80/wC+t7Ql2EoaGRnh1KlTXL58GWCLpH0410K4mi1wi49Zq9ay8CNipMX+AEZzm5GtiGPHjl27LulMRDxVvd+59q6r2Ur6c9T5zz6cbbp8Lh0zs0S48M3MEuHCNzNLhAvfzCwRLnwzs0S48M3MEuHCNzNLhAvfzCwRLnwzs0S48M3MEuHCNzNLhAvfzCwRLnwzs0S48M3MEuHCNzNLhAvfzCwRLnwzs0S48M3MEuHCNzNLhAvfzCwRLnwzs0S48M3MEuHCNzNLRFuFL2m7pLOSZiQ9Wmf/Xknzkt7MLvvzn6rlbWJiguHhYYDNzrU4nKs10rLwJa0CngB2AJuAEUmb6gw9ERFfzS5Hcp6n5WxxcZHR0VHGx8cBpnGuheBcrZl2XuHfC8xExPmI+AQ4Duzu7LSs0yYnJxkaGmJwcBAgcK6F4FytmXYKvx+4WLV9Kbut1oOSzkg6KWmg3h1JOiCpLKk8Pz+/hOlaXubm5hgYuC4m51oAztWayetD2+eBdRGxBXgZeKbeoIg4HBGliCitXbs2p4e2DnKuxeRcE9VO4c8B1a8A7sxuuyYiPoiIhWzzCHBPPtOzTunv7+fixep/uDnXInCu1kw7hf8GsEHSekmrgT3AWPUASXdUbe4C3s5vitYJW7du5dy5c1y4cAFAONdCcK7WTF+rARFxRdJB4CVgFXA0IqYlPQaUI2IM+IGkXcAV4ENgbwfnbDno6+vj0KFDbNu2DeDLwM+da+9zrtaMIuKmPHCpVIpyuXxTHtuuJ+l0RJTyuC/n2j2cazEtJ1f/0tbMLBEufDOzRLjwzcwS4cI3M0uEC9/MLBEufDOzRLjwzcwS4cI3M0uEC9/MLBEufDOzRLjwzcwS4cI3M0uEC9/MLBEufDOzRLjwzcwS4cI3M0uEC9/MLBEufDOzRLjwzcwS4cI3M0uEC9/MLBEufDOzRLjwzcwS0VbhS9ou6aykGUmP1tl/i6QT2f7XJa3LfaaWu4mJCYaHhwE2O9ficK7WSMvCl7QKeALYAWwCRiRtqhm2D/hbRAwBvwZ+lfdELV+Li4uMjo4yPj4OMI1zLQTnas208wr/XmAmIs5HxCfAcWB3zZjdwDPZ9ZPAtyQpv2la3iYnJxkaGmJwcBAgcK6F4Fytmb42xvQDF6u2LwFfazQmIq5I+gi4DbhcPUjSAeBAtrkgaWopk+4it1Ozxh7yReDzkt4FhnGu1ZwrhcwVejvbq4aX+oftFH5uIuIwcBhAUjkiSiv5+Hnr5TVIegjYHhH7JZWXc1/OtXs41+aKsI7l5NrOWzpzwEDV9p3ZbXXHSOoDvgB8sNRJ2YpwrsXkXK2hdgr/DWCDpPWSVgN7gLGaMWPAd7PrDwGvRETkN03rgGu5AsK5FoVztYZaFn5EXAEOAi8BbwO/i4hpSY9J2pUNewq4TdIM8EPghq+C1XF4iXPuJj27hppcB3Cu1Xp2Dc61pSKsY8lrkJ/YzczS4F/ampklwoVvZpaIjhd+EU7L0MYa9kqal/Rmdtl/M+bZjKSjkt5v9F1qVTyerfGMpLtb3J9z7QLO9UbOtYmI6NgFWAW8AwwCq4G3gE01Yx4Bnsyu7wFOdHJOHVrDXuDQzZ5ri3V8A7gbmGqw/wFgnMo3O+4DXneuztW59n6u1Zd2zqWznGeaIpyWoZ01dL2IeBX48Op2nVx3A89GxWvArZKOONfuVpsr3JBtvVzvaHDMOtcuUS/XGnVzbXW/7byl8zSwvcn+HcCG7HIA+E3VvnqnZeiv+fvrfuYNXP2Zd7doZw0AD2YHz0lJA3X2d5unuT7X2nX+E/gPnGuv5QrXZ1tvnd+m/jHrXHtHu+u8Tjvfw+/IM03BPA+si4gtwMt89gqoa7WR61rgD861t3KFtrL9Jmkfsz2Zax7a+h5+9sHMCxGxuc6+F4BfRsSfsu0/Aj+KiLKkrwM/jYht2b7nqPyT669r1qy5Z+PGjfmtxP5lCwsLzMzM8PHHH18GngNORcQxAEl/B74TEb/Ptp1rD1lYWGBqamqRyo+sqnM9C/wF+FntMQt8Dufa9U6fPl3veD0L3B8R7zX7206fPK36Z95zwF3AtoiYLpVKUS4v69xOtkyzs7Ps3LmT6enpd6n83P6gpONUzq74KY3Pr+Jcu9zs7Czr16//lBtz/QhYaPBnzrUHqHIm1BtybVX2kM/XMhuerCmanJYhh8e1fL0InAdmgN8Cr+Bci6A210docMw6155SL9eW8ij8MeDh7Ns691HzTBMRL0bElyLiroj4RXbbj3N4XMtR9n7uaJbTV4CjONeeV5trRJRpcsw6197QINeWWr6lI+kYcD9wu6RLwE+ovNdHRDxJ5ZnmASrPNP8Avre0JdhKGhkZ4dSpU1y+fBlgi6R9ONdCuJotcIuPWavWsvAjYqTF/gBGc5uRrYhjx45duy7pTEQ8Vb3fufauq9lK+nPU+c8+nG26fC4dM7NEuPDNzBLhwjczS4QL38wsES58M7NEuPDNzBLhwjczS4QL38wsES58M7NEuPDNzBLhwjczS4QL38wsES58M7NEuPDNzBLhwjczS4QL38wsES58M7NEuPDNzBLhwjczS4QL38wsES58M7NEuPDNzBLhwjczS0RbhS9pu6SzkmYkPVpn/15J85LezC7785+q5W1iYoLh4WGAzc61OJyrNdKy8CWtAp4AdgCbgBFJm+oMPRERX80uR3Kep+VscXGR0dFRxsfHAaZxroXgXK2Zdl7h3wvMRMT5iPgEOA7s7uy0rNMmJycZGhpicHAQIHCuheBcrZl2Cr8fuFi1fSm7rdaDks5IOilpoN4dSTogqSypPD8/v4TpWl7m5uYYGLguJudaAM7VmsnrQ9vngXURsQV4GXim3qCIOBwRpYgorV27NqeHtg5yrsXkXBPVTuHPAdWvAO7MbrsmIj6IiIVs8whwTz7Ts07p7+/n4sXqf7g51yJwrtZMO4X/BrBB0npJq4E9wFj1AEl3VG3uAt7Ob4rWCVu3buXcuXNcuHABQDjXQnCu1kxfqwERcUXSQeAlYBVwNCKmJT0GlCNiDPiBpF3AFeBDYG8H52w56Ovr49ChQ2zbtg3gy8DPnWvvc67WjCLipjxwqVSKcrl8Ux7brifpdESU8rgv59o9nGsxLSdX/9LWzCwRLnwzs0S48M3MEuHCNzNLhAvfzCwRLnwzs0S48M3MEuHCNzNLhAvfzCwRLnwzs0S48M3MEuHCNzNLhAvfzCwRLnwzs0S48M3MEuHCNzNLhAvfzCwRLnwzs0S48M3MEuHCNzNLhAvfzCwRLnwzs0S48M3MEtFW4UvaLumspBlJj9bZf4ukE9n+1yWty32mlruJiQmGh4cBNjvX4nCu1kjLwpe0CngC2AFsAkYkbaoZtg/4W0QMAb8GfpX3RC1fi4uLjI6OMj4+DjCNcy0E52rNtPMK/15gJiLOR8QnwHFgd82Y3cAz2fWTwLckKb9pWt4mJycZGhpicHAQIHCuheBcrZm+Nsb0Axerti8BX2s0JiKuSPoIuA24XD1I0gHgQLa5IGlqKZPuIrdTs8Ye8kXg85LeBYZxrtWcK4XMFXo726uGl/qH7RR+biLiMHAYQFI5Ikor+fh56+U1SHoI2B4R+yWVl3NfzrV7ONfmirCO5eTazls6c8BA1fad2W11x0jqA74AfLDUSdmKcK7F5FytoXYK/w1gg6T1klYDe4CxmjFjwHez6w8Br0RE5DdN64BruQLCuRaFc7WGWhZ+RFwBDgIvAW8Dv4uIaUmPSdqVDXsKuE3SDPBD4IavgtVxeIlz7iY9u4aaXAdwrtV6dg3OtaUirGPJa5Cf2M3M0uBf2pqZJcKFb2aWiI4XfhFOy9DGGvZKmpf0ZnbZfzPm2Yyko5Leb/RdalU8nq3xjKS7W9yfc+0CzvVGzrWJiOjYBVgFvAMMAquBt4BNNWMeAZ7Mru8BTnRyTh1aw17g0M2ea4t1fAO4G5hqsP8BYJzKNzvuA153rs7VufZ+rtWXTr/CL8JpGdpZQ9eLiFeBD5sM2Q08GxWvAbdKuqPBWOfaJZzrDZxrE50u/HqnZehvNCYqXym7+jPvbtHOGgAezP5pdVLSQJ393a7ddbY71rl2B+fqXK/xh7b5eB5YFxFbgJf57BWQ9TbnWkzJ5trpwi/Cz7xbriEiPoiIhWzzCHDPCs0tT+1k9a+Mda7dwbk612s6XfhFOC1DyzXUvHe2i8ovknvNGPBw9un/fcBHEfFeg7HOtXc4V+f6mRX4tPkB4P+ofHL+n9ltjwG7suv/Dvw3MANMAoM3+xPyJazhv6j8ZxNvAf8DbLzZc66zhmPAe8CnVN7v2wd8H/h+tl9U/qObd4D/BUrO1bk612LkevXiUyuYmSXCH9qamSXChW9mlggXvplZIlz4ZmaJcOGbmSXChW9mlggXvplZIv4fsij07nbMvU4AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "device = 'cuda'\n",
    "acla = ActiveCriticLearnerArgs()\n",
    "acla.data_path = '/home/hendrik/Documents/master_project/LokalData/TransformerImitationLearning/'\n",
    "acla.device = device\n",
    "acla.extractor = DummyExtractor()\n",
    "acla.imitation_phase = False\n",
    "acla.logname = 'test_acl'\n",
    "acla.tboard = True\n",
    "acla.batch_size = 32\n",
    "acla.validation_episodes = 5\n",
    "acla.val_every = 100\n",
    "seq_len = 100\n",
    "epsiodes = 2\n",
    "ac, acps, env = setup_ac_reach(seq_len=seq_len)\n",
    "acl = ActiveCriticLearner(ac_policy=ac, env=env, network_args_obj=acla)\n",
    "env, expert = make_dummy_vec_env(name='reach', seq_len=seq_len)\n",
    "transitions = sample_expert_transitions(policy=expert.predict, env=env, episodes=epsiodes)\n",
    "exp_actions, exp_observations, exp_rewards = parse_sampled_transitions(transitions=transitions, new_epoch=new_epoch_reach, extractor=DummyExtractor(), device=device)\n",
    "assert th.all(exp_rewards[:,-1]==1), 'Expert cant solve Environment.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n",
      "log dir: /home/hendrik/Documents/master_project/LokalData/TransformerImitationLearning/gboard/test_acl/train/\n",
      "Sampling expert transitions. 2\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "device = 'cuda'\n",
    "acla = ActiveCriticLearnerArgs()\n",
    "acla.data_path = '/home/hendrik/Documents/master_project/LokalData/TransformerImitationLearning/'\n",
    "acla.device = device\n",
    "acla.extractor = DummyExtractor()\n",
    "acla.imitation_phase = True\n",
    "acla.logname = 'test_acl'\n",
    "acla.tboard = True\n",
    "acla.batch_size = 32\n",
    "acla.val_every = 10000\n",
    "acla.validation_episodes = 5\n",
    "seq_len = 5\n",
    "epsiodes = 2\n",
    "ac, acps, env = setup_ac_reach(seq_len=seq_len)\n",
    "acl = ActiveCriticLearner(ac_policy=ac, env=env, network_args_obj=acla)\n",
    "env, expert = make_dummy_vec_env(name='reach', seq_len=seq_len)\n",
    "transitions = sample_expert_transitions(policy=expert.predict, env=env, episodes=epsiodes)\n",
    "exp_actions, exp_observations, exp_rewards = parse_sampled_transitions(transitions=transitions, new_epoch=new_epoch_reach, extractor=DummyExtractor(), device=device)\n",
    "\n",
    "part_acts, part_obsv, part_rews = make_part_obs_data(actions=exp_actions, observations=exp_observations, rewards=exp_rewards)\n",
    "\n",
    "for i in range(seq_len*epsiodes):\n",
    "    org_index = int(i/seq_len)\n",
    "    part_obs = th.clone(exp_observations[org_index])\n",
    "    part_obs[i%seq_len + 1 :] = 0\n",
    "    assert th.equal(part_acts[i], exp_actions[org_index]), 'make_part_obs_data corrupted'\n",
    "    assert th.equal(part_obsv[i], part_obs), 'make_part_obs_data corrupted'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "acl_scores = ACLScores()\n",
    "acl_scores.update_min_score(acl_scores.mean_actor, 0)\n",
    "assert acl_scores.mean_actor == [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling expert transitions. 1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/hendrik/Documents/master_project/Code/active_critic/tests/learner/test_learner.ipynb Cell 6\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/hendrik/Documents/master_project/Code/active_critic/tests/learner/test_learner.ipynb#W5sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m actions, observations, rewards, expected_rewards_before, expected_rewards_after \u001b[39m=\u001b[39m sample_new_episode(\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/hendrik/Documents/master_project/Code/active_critic/tests/learner/test_learner.ipynb#W5sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     policy\u001b[39m=\u001b[39;49mac,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/hendrik/Documents/master_project/Code/active_critic/tests/learner/test_learner.ipynb#W5sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     env\u001b[39m=\u001b[39;49menv,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/hendrik/Documents/master_project/Code/active_critic/tests/learner/test_learner.ipynb#W5sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     episodes\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/hendrik/Documents/master_project/Code/active_critic/tests/learner/test_learner.ipynb#W5sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mlist\u001b[39m(actions\u001b[39m.\u001b[39mshape) \u001b[39m==\u001b[39m [\u001b[39m1\u001b[39m, seq_len, env\u001b[39m.\u001b[39maction_space\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]]\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/hendrik/Documents/master_project/Code/active_critic/tests/learner/test_learner.ipynb#W5sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mlist\u001b[39m(observations\u001b[39m.\u001b[39mshape) \u001b[39m==\u001b[39m [\u001b[39m1\u001b[39m, seq_len, env\u001b[39m.\u001b[39mobservation_space\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]]\n",
      "File \u001b[0;32m~/Documents/master_project/Code/active_critic/src/active_critic/utils/gym_utils.py:136\u001b[0m, in \u001b[0;36msample_new_episode\u001b[0;34m(policy, env, episodes)\u001b[0m\n\u001b[1;32m    134\u001b[0m policy\u001b[39m.\u001b[39meval()\n\u001b[1;32m    135\u001b[0m policy\u001b[39m.\u001b[39mreset()\n\u001b[0;32m--> 136\u001b[0m transitions \u001b[39m=\u001b[39m sample_expert_transitions(\n\u001b[1;32m    137\u001b[0m     policy\u001b[39m.\u001b[39;49mpredict, env, episodes)\n\u001b[1;32m    138\u001b[0m expected_rewards_after \u001b[39m=\u001b[39m policy\u001b[39m.\u001b[39mscore_history_after\n\u001b[1;32m    139\u001b[0m expected_rewards_before \u001b[39m=\u001b[39m policy\u001b[39m.\u001b[39mscore_history_before\n",
      "File \u001b[0;32m~/Documents/master_project/Code/active_critic/src/active_critic/utils/gym_utils.py:111\u001b[0m, in \u001b[0;36msample_expert_transitions\u001b[0;34m(policy, env, episodes)\u001b[0m\n\u001b[1;32m    108\u001b[0m expert \u001b[39m=\u001b[39m policy\n\u001b[1;32m    110\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mSampling expert transitions. \u001b[39m\u001b[39m{\u001b[39;00mepisodes\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 111\u001b[0m rollouts \u001b[39m=\u001b[39m rollout\u001b[39m.\u001b[39;49mrollout(\n\u001b[1;32m    112\u001b[0m     expert,\n\u001b[1;32m    113\u001b[0m     env,\n\u001b[1;32m    114\u001b[0m     rollout\u001b[39m.\u001b[39;49mmake_sample_until(min_timesteps\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m, min_episodes\u001b[39m=\u001b[39;49mepisodes),\n\u001b[1;32m    115\u001b[0m     unwrap\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    116\u001b[0m     exclude_infos\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m\n\u001b[1;32m    117\u001b[0m )\n\u001b[1;32m    118\u001b[0m \u001b[39mreturn\u001b[39;00m rollout\u001b[39m.\u001b[39mflatten_trajectories(rollouts)\n",
      "File \u001b[0;32m~/Documents/master_project/Code/imitation/src/imitation/data/rollout.py:595\u001b[0m, in \u001b[0;36mrollout\u001b[0;34m(policy, venv, sample_until, unwrap, exclude_infos, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrollout\u001b[39m(\n\u001b[1;32m    560\u001b[0m     policy: AnyPolicy,\n\u001b[1;32m    561\u001b[0m     venv: VecEnv,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m    568\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Sequence[types\u001b[39m.\u001b[39mTrajectoryWithRew]:\n\u001b[1;32m    569\u001b[0m     \u001b[39m\"\"\"Generate policy rollouts.\u001b[39;00m\n\u001b[1;32m    570\u001b[0m \n\u001b[1;32m    571\u001b[0m \u001b[39m    The `.infos` field of each Trajectory is set to `None` to save space.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    593\u001b[0m \u001b[39m        should truncate if required.\u001b[39;00m\n\u001b[1;32m    594\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 595\u001b[0m     trajs \u001b[39m=\u001b[39m generate_trajectories(policy, venv, sample_until, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    596\u001b[0m     \u001b[39mif\u001b[39;00m unwrap:\n\u001b[1;32m    597\u001b[0m         trajs \u001b[39m=\u001b[39m [unwrap_traj(traj) \u001b[39mfor\u001b[39;00m traj \u001b[39min\u001b[39;00m trajs]\n",
      "File \u001b[0;32m~/Documents/master_project/Code/imitation/src/imitation/data/rollout.py:366\u001b[0m, in \u001b[0;36mgenerate_trajectories\u001b[0;34m(policy, venv, sample_until, deterministic_policy, rng)\u001b[0m\n\u001b[1;32m    364\u001b[0m active \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mones(venv\u001b[39m.\u001b[39mnum_envs, dtype\u001b[39m=\u001b[39m\u001b[39mbool\u001b[39m)\n\u001b[1;32m    365\u001b[0m \u001b[39mwhile\u001b[39;00m np\u001b[39m.\u001b[39many(active):\n\u001b[0;32m--> 366\u001b[0m     acts \u001b[39m=\u001b[39m get_actions(obs)\n\u001b[1;32m    367\u001b[0m     obs, rews, dones, infos \u001b[39m=\u001b[39m venv\u001b[39m.\u001b[39mstep(acts)\n\u001b[1;32m    369\u001b[0m     \u001b[39m# If an environment is inactive, i.e. the episode completed for that\u001b[39;00m\n\u001b[1;32m    370\u001b[0m     \u001b[39m# environment after `sample_until(trajectories)` was true, then we do\u001b[39;00m\n\u001b[1;32m    371\u001b[0m     \u001b[39m# *not* want to add any subsequent trajectories from it. We avoid this\u001b[39;00m\n\u001b[1;32m    372\u001b[0m     \u001b[39m# by just making it never done.\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/master_project/Code/active_critic/src/active_critic/policy/active_critic_policy.py:105\u001b[0m, in \u001b[0;36mActiveCriticPolicy.predict\u001b[0;34m(self, observation, state, episode_start, deterministic)\u001b[0m\n\u001b[1;32m    101\u001b[0m     action_seq \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcurrent_result\u001b[39m.\u001b[39mgen_trj\n\u001b[1;32m    103\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobs_seq[:, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcurrent_step:\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcurrent_step\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m, :] \u001b[39m=\u001b[39m vec_obsv\n\u001b[0;32m--> 105\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcurrent_result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(\n\u001b[1;32m    106\u001b[0m     observation_seq\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mobs_seq, action_seq\u001b[39m=\u001b[39;49maction_seq, optimize\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49margs_obj\u001b[39m.\u001b[39;49moptimize, current_step\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcurrent_step)\n\u001b[1;32m    107\u001b[0m batch_size \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcurrent_result\u001b[39m.\u001b[39mexpected_succes_before\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n\u001b[1;32m    108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs_obj\u001b[39m.\u001b[39moptimize:\n",
      "File \u001b[0;32m~/Documents/master_project/Code/active_critic/src/active_critic/policy/active_critic_policy.py:140\u001b[0m, in \u001b[0;36mActiveCriticPolicy.forward\u001b[0;34m(self, observation_seq, action_seq, optimize, current_step)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n\u001b[1;32m    139\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 140\u001b[0m     actions, expected_success_opt \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptimize_act_sequence(\n\u001b[1;32m    141\u001b[0m         actions\u001b[39m=\u001b[39;49mactions, observations\u001b[39m=\u001b[39;49mobservation_seq, current_step\u001b[39m=\u001b[39;49mcurrent_step)\n\u001b[1;32m    143\u001b[0m     \u001b[39mreturn\u001b[39;00m ACPOptResult(\n\u001b[1;32m    144\u001b[0m         gen_trj\u001b[39m=\u001b[39mactions\u001b[39m.\u001b[39mdetach(),\n\u001b[1;32m    145\u001b[0m         expected_succes_before\u001b[39m=\u001b[39mexpected_success,\n\u001b[1;32m    146\u001b[0m         expected_succes_after\u001b[39m=\u001b[39mexpected_success_opt)\n",
      "File \u001b[0;32m~/Documents/master_project/Code/active_critic/src/active_critic/policy/active_critic_policy.py:161\u001b[0m, in \u001b[0;36mActiveCriticPolicy.optimize_act_sequence\u001b[0;34m(self, actions, observations, current_step)\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcritic\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39meval()\n\u001b[1;32m    159\u001b[0m \u001b[39mwhile\u001b[39;00m (\u001b[39mnot\u001b[39;00m th\u001b[39m.\u001b[39mall(expected_success[:, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs_obj\u001b[39m.\u001b[39moptimisation_threshold)) \u001b[39mand\u001b[39;00m (step \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs_obj\u001b[39m.\u001b[39mopt_steps):\n\u001b[0;32m--> 161\u001b[0m     optimized_actions, expected_success \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minference_opt_step(\n\u001b[1;32m    162\u001b[0m         org_actions\u001b[39m=\u001b[39;49mactions,\n\u001b[1;32m    163\u001b[0m         opt_actions\u001b[39m=\u001b[39;49moptimized_actions,\n\u001b[1;32m    164\u001b[0m         obs_seq\u001b[39m=\u001b[39;49mobservations,\n\u001b[1;32m    165\u001b[0m         optimizer\u001b[39m=\u001b[39;49moptimizer,\n\u001b[1;32m    166\u001b[0m         goal_label\u001b[39m=\u001b[39;49mgoal_label,\n\u001b[1;32m    167\u001b[0m         current_step\u001b[39m=\u001b[39;49mcurrent_step)\n\u001b[1;32m    168\u001b[0m     step \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    170\u001b[0m \u001b[39mreturn\u001b[39;00m optimized_actions, expected_success\n",
      "File \u001b[0;32m~/Documents/master_project/Code/active_critic/src/active_critic/policy/active_critic_policy.py:174\u001b[0m, in \u001b[0;36mActiveCriticPolicy.inference_opt_step\u001b[0;34m(self, org_actions, opt_actions, obs_seq, optimizer, goal_label, current_step)\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minference_opt_step\u001b[39m(\u001b[39mself\u001b[39m, org_actions: th\u001b[39m.\u001b[39mTensor, opt_actions: th\u001b[39m.\u001b[39mTensor, obs_seq: th\u001b[39m.\u001b[39mTensor, optimizer: th\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mOptimizer, goal_label: th\u001b[39m.\u001b[39mTensor, current_step: \u001b[39mint\u001b[39m):\n\u001b[1;32m    173\u001b[0m     critic_inpt \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_critic_input(acts\u001b[39m=\u001b[39mopt_actions, obs_seq\u001b[39m=\u001b[39mobs_seq)\n\u001b[0;32m--> 174\u001b[0m     critic_result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcritic\u001b[39m.\u001b[39;49mforward(inputs\u001b[39m=\u001b[39;49mcritic_inpt)\n\u001b[1;32m    175\u001b[0m     critic_loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcritic\u001b[39m.\u001b[39mloss_fct(\n\u001b[1;32m    176\u001b[0m         result\u001b[39m=\u001b[39mcritic_result, label\u001b[39m=\u001b[39mgoal_label)\n\u001b[1;32m    178\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m~/Documents/master_project/Code/active_critic/src/active_critic/model_src/whole_sequence_model.py:33\u001b[0m, in \u001b[0;36mWholeSequenceModel.forward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwsms\u001b[39m.\u001b[39mmodel_setup\u001b[39m.\u001b[39mntoken \u001b[39m=\u001b[39m inputs\u001b[39m.\u001b[39msize(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     31\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel \u001b[39m=\u001b[39m TransformerModel(\n\u001b[1;32m     32\u001b[0m         model_setup\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwsms\u001b[39m.\u001b[39mmodel_setup)\u001b[39m.\u001b[39mto(inputs\u001b[39m.\u001b[39mdevice)\n\u001b[0;32m---> 33\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mforward(inputs)\n\u001b[1;32m     34\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     35\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwsms\u001b[39m.\u001b[39moptimizer_class(\n\u001b[1;32m     36\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mparameters(), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwsms\u001b[39m.\u001b[39mlr, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwsms\u001b[39m.\u001b[39moptimizer_kwargs)\n",
      "File \u001b[0;32m~/Documents/master_project/Code/active_critic/src/active_critic/model_src/transformer.py:64\u001b[0m, in \u001b[0;36mTransformerModel.forward\u001b[0;34m(self, src, mask, return_attention)\u001b[0m\n\u001b[1;32m     62\u001b[0m     output, attention \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransformer_encoder\u001b[39m.\u001b[39mforward(src\u001b[39m=\u001b[39msrc, mask\u001b[39m=\u001b[39mmask, return_attention\u001b[39m=\u001b[39mreturn_attention)\n\u001b[1;32m     63\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransformer_encoder\u001b[39m.\u001b[39;49mforward(src\u001b[39m=\u001b[39;49msrc, mask\u001b[39m=\u001b[39;49mmask)\n\u001b[1;32m     65\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdecoder(output)\n\u001b[1;32m     66\u001b[0m \u001b[39mif\u001b[39;00m return_attention:\n",
      "File \u001b[0;32m~/Documents/master_project/Code/active_critic/src/active_critic/model_src/base_transformer.py:58\u001b[0m, in \u001b[0;36mDebugTE.forward\u001b[0;34m(self, src, return_attention, mask, src_key_padding_mask)\u001b[0m\n\u001b[1;32m     55\u001b[0m         output, attention \u001b[39m=\u001b[39m mod(output, src_mask\u001b[39m=\u001b[39mmask, src_key_padding_mask\u001b[39m=\u001b[39msrc_key_padding_mask,\n\u001b[1;32m     56\u001b[0m                                 return_attention\u001b[39m=\u001b[39mreturn_attention)\n\u001b[1;32m     57\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m         output \u001b[39m=\u001b[39m mod(output, src_mask\u001b[39m=\u001b[39;49mmask, src_key_padding_mask\u001b[39m=\u001b[39;49msrc_key_padding_mask)\n\u001b[1;32m     60\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     61\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm(output)\n",
      "File \u001b[0;32m~/anaconda3/envs/tfTest/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Documents/master_project/Code/active_critic/src/active_critic/model_src/base_transformer.py:22\u001b[0m, in \u001b[0;36mDebugTEL.forward\u001b[0;34m(self, src, src_mask, src_key_padding_mask, return_attention)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, src: Tensor, src_mask: Optional[Tensor] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, src_key_padding_mask: Optional[Tensor] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m     11\u001b[0m             return_attention: Optional[\u001b[39mbool\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m     12\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"Pass the input through the encoder layer.\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \n\u001b[1;32m     14\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[39m        see the docs in Transformer class.\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m     attn \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mself_attn(src, src, src, attn_mask\u001b[39m=\u001b[39;49msrc_mask,\n\u001b[1;32m     23\u001b[0m                           key_padding_mask\u001b[39m=\u001b[39;49msrc_key_padding_mask)\n\u001b[1;32m     24\u001b[0m     src \u001b[39m=\u001b[39m src \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout1(attn[\u001b[39m0\u001b[39m])\n\u001b[1;32m     25\u001b[0m     src \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm1(src)\n",
      "File \u001b[0;32m~/anaconda3/envs/tfTest/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/tfTest/lib/python3.9/site-packages/torch/nn/modules/activation.py:1134\u001b[0m, in \u001b[0;36mMultiheadAttention.forward\u001b[0;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights)\u001b[0m\n\u001b[1;32m   1132\u001b[0m \u001b[39mif\u001b[39;00m key \u001b[39mis\u001b[39;00m value:\n\u001b[1;32m   1133\u001b[0m     \u001b[39mif\u001b[39;00m query \u001b[39mis\u001b[39;00m key:\n\u001b[0;32m-> 1134\u001b[0m         query \u001b[39m=\u001b[39m key \u001b[39m=\u001b[39m value \u001b[39m=\u001b[39m query\u001b[39m.\u001b[39;49mtranspose(\u001b[39m1\u001b[39;49m, \u001b[39m0\u001b[39;49m)\n\u001b[1;32m   1135\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1136\u001b[0m         query, key \u001b[39m=\u001b[39m [x\u001b[39m.\u001b[39mtranspose(\u001b[39m1\u001b[39m, \u001b[39m0\u001b[39m) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m (query, key)]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "actions, observations, rewards, expected_rewards_before, expected_rewards_after = sample_new_episode(\n",
    "    policy=ac,\n",
    "    env=env,\n",
    "    episodes=1,)\n",
    "assert list(actions.shape) == [1, seq_len, env.action_space.shape[0]]\n",
    "assert list(observations.shape) == [1, seq_len, env.observation_space.shape[0]]\n",
    "assert list(rewards.shape) == [1, seq_len, 1]\n",
    "assert list(expected_rewards_after.shape) == [1, seq_len, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imitation_data = DatasetAC(device='cuda')\n",
    "imitation_data.onyl_positiv = False\n",
    "imitation_data.add_data(obsv=part_obsv, actions=part_acts, reward=part_rews)\n",
    "assert len(imitation_data) == epsiodes * seq_len\n",
    "assert list(imitation_data.actions.shape) == [epsiodes * seq_len, seq_len, env.action_space.shape[0]]\n",
    "assert list(imitation_data.obsv.shape) == [epsiodes * seq_len, seq_len, env.observation_space.shape[0]]\n",
    "assert list(imitation_data.reward.shape) == [epsiodes * seq_len, seq_len, 1]\n",
    "imitation_data.onyl_positiv = True\n",
    "assert len(imitation_data) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imitation_data.onyl_positiv = False\n",
    "dataloader = th.utils.data.DataLoader(imitation_data, batch_size=2*len(imitation_data))\n",
    "for data in dataloader:\n",
    "    dobsv, dact, drews = data\n",
    "assert th.equal(dact, part_acts)\n",
    "assert th.equal(dobsv, part_obsv)\n",
    "assert th.equal(drews, part_rews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imitation_data.add_data(obsv=part_obsv, actions=part_acts, reward=part_rews)\n",
    "imitation_data.onyl_positiv = False\n",
    "dataloader = th.utils.data.DataLoader(imitation_data, batch_size=2*len(imitation_data))\n",
    "for data in dataloader:\n",
    "    dobsv, dact, drews = data\n",
    "assert list(dobsv.shape) == [2*epsiodes * seq_len, seq_len, env.observation_space.shape[0]]\n",
    "assert list(dact.shape) == [2*epsiodes * seq_len, seq_len, env.action_space.shape[0]]\n",
    "assert list(drews.shape) == [2*epsiodes * seq_len, seq_len, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acl.setDatasets(train_data=imitation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acl.policy.args_obj.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acl.train(epochs=100)\n",
    "#assert acl.scores.mean_actor[0] < 1e-3\n",
    "#assert acl.scores.mean_critic[0] < 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(0.0213, device='cuda:0')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acl.scores.mean_actor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as th\n",
    "from active_critic.learner.active_critic_learner import ActiveCriticLearner, ACLScores\n",
    "from active_critic.learner.active_critic_args import ActiveCriticLearnerArgs\n",
    "from active_critic.policy.active_critic_policy import ActiveCriticPolicy\n",
    "from active_critic.utils.test_utils import setup_ac_reach\n",
    "from active_critic.utils.gym_utils import make_dummy_vec_env, parse_sampled_transitions, sample_expert_transitions, DummyExtractor, new_epoch_reach, sample_new_episode\n",
    "from active_critic.utils.pytorch_utils import make_part_obs_data\n",
    "from active_critic.utils.dataset import DatasetAC\n",
    "from stable_baselines3.common.policies import BasePolicy\n",
    "from stable_baselines3.common.torch_layers import BaseFeaturesExtractor\n",
    "from active_critic.utils.dataset import DatasetAC\n",
    "from gym import Env\n",
    "th.manual_seed(0)\n",
    "\n",
    "def make_acl():\n",
    "        device = 'cuda'\n",
    "        acla = ActiveCriticLearnerArgs()\n",
    "        acla.data_path = '/home/hendrik/Documents/master_project/LokalData/TransformerImitationLearning/'\n",
    "        acla.device = device\n",
    "        acla.extractor = DummyExtractor()\n",
    "        acla.imitation_phase = True\n",
    "        acla.logname = 'test_acl'\n",
    "        acla.tboard = False\n",
    "        acla.batch_size = 32\n",
    "        acla.val_every = 10000\n",
    "        acla.validation_episodes = 5\n",
    "        seq_len = 5\n",
    "        epsiodes = 2\n",
    "        ac, acps, env = setup_ac_reach(seq_len=seq_len)\n",
    "        acl = ActiveCriticLearner(ac_policy=ac, env=env, network_args_obj=acla)\n",
    "        env, expert = make_dummy_vec_env(name='reach', seq_len=seq_len)\n",
    "        return acl, env, expert, seq_len, epsiodes, device\n",
    "seq_len = 5\n",
    "epsiodes = 2\n",
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling expert transitions. 30\n"
     ]
    }
   ],
   "source": [
    "seq_len = 100\n",
    "epsiodes = 30\n",
    "device = 'cuda'\n",
    "env, expert = make_dummy_vec_env(name='reach', seq_len=seq_len)\n",
    "transitions = sample_expert_transitions(policy=expert.predict, env=env, episodes=epsiodes)\n",
    "exp_actions, exp_observations, exp_rewards = parse_sampled_transitions(transitions=transitions, new_epoch=new_epoch_reach, extractor=DummyExtractor(), device=device)\n",
    "part_acts, part_obsv, part_rews = make_part_obs_data(actions=exp_actions, observations=exp_observations, rewards=exp_rewards)\n",
    "imitation_data = DatasetAC(device='cuda')\n",
    "imitation_data.onyl_positiv = False\n",
    "imitation_data.add_data(obsv=part_obsv, actions=part_acts, reward=part_rews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'make_acl' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/hendrik/Documents/master_project/Code/active_critic/tests/learner/test_learner.ipynb Cell 16\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/hendrik/Documents/master_project/Code/active_critic/tests/learner/test_learner.ipynb#X21sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m th\u001b[39m.\u001b[39mmanual_seed(\u001b[39m0\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/hendrik/Documents/master_project/Code/active_critic/tests/learner/test_learner.ipynb#X21sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m acl, env, expert, seq_len, epsiodes, device \u001b[39m=\u001b[39m make_acl()\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/hendrik/Documents/master_project/Code/active_critic/tests/learner/test_learner.ipynb#X21sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m acl\u001b[39m.\u001b[39msetDatasets(train_data\u001b[39m=\u001b[39mimitation_data)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/hendrik/Documents/master_project/Code/active_critic/tests/learner/test_learner.ipynb#X21sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m acl\u001b[39m.\u001b[39mtrain(epochs\u001b[39m=\u001b[39m\u001b[39m200\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'make_acl' is not defined"
     ]
    }
   ],
   "source": [
    "th.manual_seed(0)\n",
    "acl, env, expert, seq_len, epsiodes, device = make_acl()\n",
    "acl.setDatasets(train_data=imitation_data)\n",
    "acl.train(epochs=200)\n",
    "acl.run_validation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_before = acl.scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/hendrik/Documents/master_project/LokalData/TransformerImitationLearning/best\n"
     ]
    }
   ],
   "source": [
    "th.manual_seed(0)\n",
    "acl, env, expert, seq_len, epsiodes, device = make_acl()\n",
    "acl.setDatasets(train_data=imitation_data)\n",
    "acl.train(epochs=200)\n",
    "acl.saveNetworkToFile(data_path='/home/hendrik/Documents/master_project/LokalData/TransformerImitationLearning/', add='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling expert transitions. 1\n",
      "Sampling expert transitions. 5\n",
      "/home/hendrik/Documents/master_project/LokalData/TransformerImitationLearning/best_validation\n"
     ]
    }
   ],
   "source": [
    "acl, env, expert, seq_len, epsiodes, device = make_acl()\n",
    "acl.loadNetworkFromFile(path='/home/hendrik/Documents/master_project/LokalData/TransformerImitationLearning/best/')\n",
    "acl.train(epochs=200)\n",
    "acl.run_validation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(0.0028, device='cuda:0')]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acl.scores.mean_actor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(0.0028, device='cuda:0')]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_before.mean_actor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert th.allclose(acl.scores.mean_actor[0], scores_before.mean_actor[0])\n",
    "assert th.allclose(acl.scores.mean_critic[0], scores_before.mean_critic[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1099, device='cuda:0')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acl.scores.mean_reward[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1253, device='cuda:0')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_before.mean_reward[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0009, device='cuda:0')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_before.mean_actor[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('tfTest')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bee90e249730b85f00f3915f0cf4f21bc0729131dcc7008c941068256fd0d344"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
