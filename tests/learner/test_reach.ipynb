{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-03 01:30:39.572305: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/home/hendrik/miniconda3/envs/ac/lib/python3.10/site-packages/gym/spaces/box.py:73: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  logger.warn(\n",
      "/home/hendrik/miniconda3/envs/ac/lib/python3.10/site-packages/gym/spaces/box.py:73: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  logger.warn(\n",
      "/home/hendrik/miniconda3/envs/ac/lib/python3.10/site-packages/gym/spaces/box.py:73: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  logger.warn(\n",
      "/home/hendrik/miniconda3/envs/ac/lib/python3.10/site-packages/gym/spaces/box.py:73: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  logger.warn(\n",
      "/home/hendrik/miniconda3/envs/ac/lib/python3.10/site-packages/gym/spaces/box.py:73: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  logger.warn(\n",
      "2022-11-03 01:30:52.791031: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import torch as th\n",
    "from active_critic.learner.active_critic_learner import ActiveCriticLearner, ACLScores\n",
    "from active_critic.learner.active_critic_args import ActiveCriticLearnerArgs\n",
    "from active_critic.policy.active_critic_policy import ActiveCriticPolicy\n",
    "from active_critic.utils.gym_utils import make_dummy_vec_env, make_vec_env, parse_sampled_transitions, sample_expert_transitions, DummyExtractor, new_epoch_reach, sample_new_episode\n",
    "from active_critic.utils.pytorch_utils import make_part_obs_data, count_parameters, build_tf_horizon_mask\n",
    "from active_critic.utils.dataset import DatasetAC\n",
    "from stable_baselines3.common.policies import BasePolicy\n",
    "from stable_baselines3.common.torch_layers import BaseFeaturesExtractor\n",
    "from active_critic.utils.dataset import DatasetAC\n",
    "from active_critic.model_src.whole_sequence_model import (\n",
    "    WholeSequenceModel)\n",
    "from active_critic.model_src.transformer import (\n",
    "    ModelSetup)\n",
    "from active_critic.policy.active_critic_policy import ActiveCriticPolicySetup, ActiveCriticPolicy\n",
    "from active_critic.model_src.state_model import *\n",
    "\n",
    "\n",
    "from gym import Env\n",
    "th.manual_seed(0)\n",
    "\n",
    "def make_acps(seq_len, extractor, new_epoch, batch_size = 2, device='cpu', horizon = 0):\n",
    "    acps = ActiveCriticPolicySetup()\n",
    "    acps.device=device\n",
    "    acps.epoch_len=seq_len\n",
    "    acps.extractor=extractor\n",
    "    acps.new_epoch=new_epoch\n",
    "    acps.opt_steps=100\n",
    "    acps.inference_opt_lr = 1e-1\n",
    "    acps.optimizer_class = th.optim.Adam\n",
    "    acps.optimize = True\n",
    "    acps.batch_size = batch_size\n",
    "    acps.pred_mask = build_tf_horizon_mask(seq_len=seq_len, horizon=horizon, device=device)\n",
    "    acps.opt_mask = th.zeros([seq_len, 1], device=device, dtype=bool)\n",
    "    acps.opt_mask[:,-1] = 1\n",
    "    return acps\n",
    "\n",
    "def setup_opt_state(batch_size, seq_len, device='cpu'):\n",
    "    num_cpu = 1\n",
    "    env, expert = make_vec_env('reach', num_cpu, seq_len=seq_len)\n",
    "    d_output = env.action_space.shape[0]\n",
    "    embed_dim = 10\n",
    "    lr = 1e-3\n",
    "\n",
    "    actor_args = StateModelArgs()\n",
    "    actor_args.arch = [200, 200, env.action_space.shape[0]]\n",
    "    actor_args.device = device\n",
    "    actor_args.lr = lr\n",
    "    actor = StateModel(args=actor_args)\n",
    "\n",
    "    critic_args = StateModelArgs()\n",
    "    critic_args.arch = [200, 200, 1]\n",
    "    critic_args.device = device\n",
    "    critic_args.lr = lr\n",
    "    critic = StateModel(args=critic_args)\n",
    "\n",
    "    emitter_args = StateModelArgs()\n",
    "    emitter_args.arch = [200, 200, embed_dim]\n",
    "    emitter_args.device = device\n",
    "    emitter_args.lr = lr\n",
    "    emitter = StateModel(args=emitter_args)\n",
    "\n",
    "    predictor_args = StateModelArgs()\n",
    "    predictor_args.arch = [200, 200, embed_dim]\n",
    "    predictor_args.device = device\n",
    "    predictor_args.lr = lr\n",
    "    predictor = StateModel(args=emitter_args)\n",
    "\n",
    "\n",
    "    acps = make_acps(\n",
    "        seq_len=seq_len, extractor=DummyExtractor(), new_epoch=new_epoch_reach, device=device, batch_size=batch_size)\n",
    "    acps.opt_steps = 10\n",
    "    acps.clip = True\n",
    "    ac = ActiveCriticPolicy(observation_space=env.observation_space, \n",
    "                            action_space=env.action_space,\n",
    "                            actor=actor,\n",
    "                            critic=critic,\n",
    "                            predictor=predictor,\n",
    "                            emitter=emitter,\n",
    "                            acps=acps)\n",
    "    return ac, acps, batch_size, seq_len, env, expert\n",
    "\n",
    "\n",
    "def make_acl():\n",
    "    device = 'cpu'\n",
    "    acla = ActiveCriticLearnerArgs()\n",
    "    acla.data_path = '/home/hendrik/Documents/master_project/LokalData/TransformerImitationLearning/'\n",
    "    acla.device = device\n",
    "    acla.extractor = DummyExtractor()\n",
    "    acla.imitation_phase = False\n",
    "    acla.logname = 'reach_plot_embedding'\n",
    "    acla.tboard = True\n",
    "    acla.batch_size = 32\n",
    "    acla.val_every = 1000\n",
    "    acla.add_data_every = 100\n",
    "    acla.validation_episodes = 1\n",
    "    acla.training_epsiodes = 1\n",
    "    acla.actor_threshold = 1e-2\n",
    "    acla.critic_threshold = 1e-2\n",
    "    acla.predictor_threshold = 1e-2\n",
    "    acla.num_cpu = 1\n",
    "\n",
    "    batch_size = 2\n",
    "    seq_len = 5\n",
    "    ac, acps, batch_size, seq_len, env, expert= setup_opt_state(device=device, batch_size=batch_size, seq_len=seq_len)\n",
    "    eval_env, expert = make_vec_env('reach', num_cpu=acla.num_cpu, seq_len=seq_len)\n",
    "    acl = ActiveCriticLearner(ac_policy=ac, env=env, eval_env=eval_env, network_args_obj=acla)\n",
    "    return acl, env, expert, seq_len, device\n",
    "acl, env, expert, seq_len, device = make_acl()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'transitions = sample_expert_transitions(\\n    policy=expert.predict, env=env, episodes=100)\\n\\nexp_actions, exp_observations, exp_rewards = parse_sampled_transitions(\\n    transitions=transitions, extractor=DummyExtractor(), device=device)\\nimitation_data = DatasetAC(device=device)\\nimitation_data.onyl_positiv = False\\nimitation_data.add_data(obsv=exp_observations, actions=exp_actions, reward=exp_rewards)\\nacl.setDatasets(train_data=imitation_data)'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''transitions = sample_expert_transitions(\n",
    "    policy=expert.predict, env=env, episodes=100)\n",
    "\n",
    "exp_actions, exp_observations, exp_rewards = parse_sampled_transitions(\n",
    "    transitions=transitions, extractor=DummyExtractor(), device=device)\n",
    "imitation_data = DatasetAC(device=device)\n",
    "imitation_data.onyl_positiv = False\n",
    "imitation_data.add_data(obsv=exp_observations, actions=exp_actions, reward=exp_rewards)\n",
    "acl.setDatasets(train_data=imitation_data)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling transitions. 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hendrik/Documents/MasterProjct/ActiveCritic/src/active_critic/utils/gym_utils.py:187: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  actions = th.tensor(actions, dtype=th.float, device=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling transitions. 1\n",
      "/home/hendrik/Documents/master_project/LokalData/TransformerImitationLearning/reach_plot_embedding/best_validation\n",
      "Success Rate: 0.0\n",
      "Reward: 0.11843143403530121\n",
      "training samples: 1\n",
      "Sampling transitions. 1\n",
      "Sampling transitions. 1\n",
      "/home/hendrik/Documents/master_project/LokalData/TransformerImitationLearning/reach_plot_embedding/best_validation\n",
      "Success Rate: 0.0\n",
      "Reward: 0.15702444314956665\n",
      "training samples: 2\n",
      "Sampling transitions. 1\n",
      "Sampling transitions. 1\n",
      "/home/hendrik/Documents/master_project/LokalData/TransformerImitationLearning/reach_plot_embedding/best_validation\n",
      "Success Rate: 0.0\n",
      "Reward: 0.17711839079856873\n",
      "training samples: 3\n",
      "Sampling transitions. 1\n",
      "Sampling transitions. 1\n",
      "Success Rate: 0.0\n",
      "Reward: 0.13051263988018036\n",
      "training samples: 4\n",
      "Sampling transitions. 1\n",
      "Sampling transitions. 1\n",
      "Success Rate: 0.0\n",
      "Reward: 0.14634986221790314\n",
      "training samples: 5\n",
      "Sampling transitions. 1\n",
      "Sampling transitions. 1\n",
      "Success Rate: 0.0\n",
      "Reward: 0.15402697026729584\n",
      "training samples: 6\n",
      "Sampling transitions. 1\n",
      "Sampling transitions. 1\n",
      "Success Rate: 0.0\n",
      "Reward: 0.12032772600650787\n",
      "training samples: 7\n",
      "Sampling transitions. 1\n",
      "Sampling transitions. 1\n",
      "Success Rate: 0.0\n",
      "Reward: 0.15881046652793884\n",
      "training samples: 8\n",
      "Sampling transitions. 1\n",
      "Sampling transitions. 1\n",
      "/home/hendrik/Documents/master_project/LokalData/TransformerImitationLearning/reach_plot_embedding/best_validation\n",
      "Success Rate: 0.0\n",
      "Reward: 0.185349240899086\n",
      "training samples: 9\n",
      "Sampling transitions. 1\n",
      "Sampling transitions. 1\n",
      "Success Rate: 0.0\n",
      "Reward: 0.11919929832220078\n",
      "training samples: 10\n",
      "Sampling transitions. 1\n",
      "Sampling transitions. 1\n",
      "Success Rate: 0.0\n",
      "Reward: 0.15086326003074646\n",
      "training samples: 11\n",
      "Sampling transitions. 1\n",
      "Sampling transitions. 1\n",
      "Success Rate: 0.0\n",
      "Reward: 0.16412648558616638\n",
      "training samples: 12\n",
      "Sampling transitions. 1\n",
      "Sampling transitions. 1\n",
      "Success Rate: 0.0\n",
      "Reward: 0.14718349277973175\n",
      "training samples: 13\n",
      "Sampling transitions. 1\n",
      "Sampling transitions. 1\n",
      "Success Rate: 0.0\n",
      "Reward: 0.14900964498519897\n",
      "training samples: 14\n",
      "Sampling transitions. 1\n",
      "Sampling transitions. 1\n",
      "/home/hendrik/Documents/master_project/LokalData/TransformerImitationLearning/reach_plot_embedding/best_validation\n",
      "Success Rate: 0.0\n",
      "Reward: 0.18554285168647766\n",
      "training samples: 15\n",
      "Sampling transitions. 1\n",
      "Sampling transitions. 1\n",
      "Success Rate: 0.0\n",
      "Reward: 0.16427959501743317\n",
      "training samples: 16\n",
      "Sampling transitions. 1\n",
      "Sampling transitions. 1\n",
      "Success Rate: 0.0\n",
      "Reward: 0.1254706233739853\n",
      "training samples: 17\n",
      "Sampling transitions. 1\n",
      "Sampling transitions. 1\n"
     ]
    }
   ],
   "source": [
    "acl.train(epochs=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------+------------+\n",
      "|            Modules             | Parameters |\n",
      "+--------------------------------+------------+\n",
      "|  actor.model.layers.0.weight   |    2200    |\n",
      "|   actor.model.layers.0.bias    |    200     |\n",
      "|  actor.model.layers.2.weight   |   40000    |\n",
      "|   actor.model.layers.2.bias    |    200     |\n",
      "|  actor.model.layers.4.weight   |    800     |\n",
      "|   actor.model.layers.4.bias    |     4      |\n",
      "|  critic.model.layers.0.weight  |    2800    |\n",
      "|   critic.model.layers.0.bias   |    200     |\n",
      "|  critic.model.layers.2.weight  |   40000    |\n",
      "|   critic.model.layers.2.bias   |    200     |\n",
      "|  critic.model.layers.4.weight  |    200     |\n",
      "|   critic.model.layers.4.bias   |     1      |\n",
      "| predicor.model.layers.0.weight |    546     |\n",
      "|  predicor.model.layers.0.bias  |     39     |\n",
      "| predicor.model.layers.2.weight |    7800    |\n",
      "|  predicor.model.layers.2.bias  |    200     |\n",
      "| predicor.model.layers.4.weight |   40000    |\n",
      "|  predicor.model.layers.4.bias  |    200     |\n",
      "| predicor.model.layers.6.weight |    2000    |\n",
      "|  predicor.model.layers.6.bias  |     10     |\n",
      "| emitter.model.layers.0.weight  |    7800    |\n",
      "|  emitter.model.layers.0.bias   |    200     |\n",
      "| emitter.model.layers.2.weight  |   40000    |\n",
      "|  emitter.model.layers.2.bias   |    200     |\n",
      "| emitter.model.layers.4.weight  |    2000    |\n",
      "|  emitter.model.layers.4.bias   |     10     |\n",
      "+--------------------------------+------------+\n",
      "Total Trainable Params: 187810\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "187810"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_parameters(acl.policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('ac')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "55d3bc2b8c4272bbea65d85e1c1c189fa11db70743df9511061edc4d7dc4f3cd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
