{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hendrik/anaconda3/envs/ac/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2022-10-12 16:18:32.018152: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-12 16:18:32.110695: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/hendrik/Documents/master_project/CoppeliaSim_Player_V4_1_0_Ubuntu20_04:/home/hendrik/.mujoco/mujoco210/bin:/usr/lib/nvidia\n",
      "2022-10-12 16:18:32.110709: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-10-12 16:18:32.134609: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-10-12 16:18:32.515851: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/hendrik/Documents/master_project/CoppeliaSim_Player_V4_1_0_Ubuntu20_04:/home/hendrik/.mujoco/mujoco210/bin:/usr/lib/nvidia\n",
      "2022-10-12 16:18:32.515906: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/hendrik/Documents/master_project/CoppeliaSim_Player_V4_1_0_Ubuntu20_04:/home/hendrik/.mujoco/mujoco210/bin:/usr/lib/nvidia\n",
      "2022-10-12 16:18:32.515910: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "/home/hendrik/anaconda3/envs/ac/lib/python3.10/site-packages/gym/spaces/box.py:73: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch as th\n",
    "from active_critic.learner.active_critic_learner import ActiveCriticLearner, ACLScores\n",
    "from active_critic.learner.active_critic_args import ActiveCriticLearnerArgs\n",
    "from active_critic.policy.active_critic_policy import ActiveCriticPolicy\n",
    "from active_critic.utils.gym_utils import make_dummy_vec_env, parse_sampled_transitions, sample_expert_transitions, DummyExtractor, new_epoch_reach, sample_new_episode\n",
    "from active_critic.utils.pytorch_utils import make_part_obs_data, count_parameters\n",
    "from active_critic.utils.dataset import DatasetAC\n",
    "from stable_baselines3.common.policies import BasePolicy\n",
    "from stable_baselines3.common.torch_layers import BaseFeaturesExtractor\n",
    "from active_critic.utils.dataset import DatasetAC\n",
    "from active_critic.model_src.whole_sequence_model import (\n",
    "    WholeSequenceModelSetup, WholeSequenceModel)\n",
    "from active_critic.model_src.transformer import (\n",
    "    ModelSetup, generate_square_subsequent_mask)\n",
    "from active_critic.policy.active_critic_policy import ActiveCriticPolicySetup, ActiveCriticPolicy\n",
    "\n",
    "\n",
    "from gym import Env\n",
    "th.manual_seed(0)\n",
    "\n",
    "\n",
    "def make_wsm_setup(seq_len, d_output, device='cuda'):\n",
    "    wsm = WholeSequenceModelSetup()\n",
    "    wsm.model_setup = ModelSetup()\n",
    "    seq_len = seq_len\n",
    "    d_output = d_output\n",
    "    wsm.model_setup.d_output = d_output\n",
    "    wsm.model_setup.nhead = 1\n",
    "    wsm.model_setup.d_hid = 512\n",
    "    wsm.model_setup.d_model = 512\n",
    "    wsm.model_setup.nlayers = 4\n",
    "    wsm.model_setup.seq_len = seq_len\n",
    "    wsm.model_setup.dropout = 0\n",
    "    wsm.lr = 1e-4\n",
    "    wsm.model_setup.device = device\n",
    "    wsm.optimizer_class = th.optim.Adam\n",
    "    wsm.optimizer_kwargs = {}\n",
    "    return wsm\n",
    "\n",
    "\n",
    "def make_acps(seq_len, extractor, new_epoch, batch_size=32):\n",
    "    acps = ActiveCriticPolicySetup()\n",
    "    acps.device = 'cuda'\n",
    "    acps.epoch_len = seq_len\n",
    "    acps.extractor = extractor\n",
    "    acps.new_epoch = new_epoch\n",
    "    acps.opt_steps = 100\n",
    "    acps.optimisation_threshold = 0.95\n",
    "    acps.inference_opt_lr = 5e-2\n",
    "    acps.optimize = True\n",
    "    acps.batch_size = 32\n",
    "    return acps\n",
    "\n",
    "\n",
    "def setup_ac_reach(seq_len=5):\n",
    "    seq_len = seq_len\n",
    "    env, gt_policy = make_dummy_vec_env('reach', seq_len=seq_len)\n",
    "    d_output = env.action_space.shape[0]\n",
    "    wsm_actor_setup = make_wsm_setup(\n",
    "        seq_len=seq_len, d_output=d_output)\n",
    "    wsm_critic_setup = make_wsm_setup(\n",
    "        seq_len=seq_len, d_output=1)\n",
    "    acps = make_acps(\n",
    "        seq_len=seq_len, extractor=DummyExtractor(), new_epoch=new_epoch_reach)\n",
    "    actor = WholeSequenceModel(wsm_actor_setup)\n",
    "    critic = WholeSequenceModel(wsm_critic_setup)\n",
    "    ac = ActiveCriticPolicy(observation_space=env.observation_space, action_space=env.action_space,\n",
    "                            actor=actor, critic=critic, acps=acps)\n",
    "    return ac, acps, env\n",
    "\n",
    "\n",
    "def make_acl():\n",
    "    device = 'cuda'\n",
    "    acla = ActiveCriticLearnerArgs()\n",
    "    acla.data_path = '/home/hendrik/Documents/master_project/LokalData/TransformerImitationLearning/'\n",
    "    acla.device = device\n",
    "    acla.extractor = DummyExtractor()\n",
    "    acla.imitation_phase = False\n",
    "    acla.logname = 'reach_org_test'\n",
    "    acla.tboard = True\n",
    "    acla.batch_size = 32\n",
    "    acla.val_every = 10\n",
    "    acla.add_data_every = 1\n",
    "    acla.validation_episodes = 5\n",
    "    acla.actor_threshold = 1e-2\n",
    "    acla.critic_threshold = 1e-2\n",
    "    seq_len = 100\n",
    "    epsiodes = 30\n",
    "    ac, acps, env = setup_ac_reach(seq_len=seq_len)\n",
    "    acl = ActiveCriticLearner(ac_policy=ac, env=env, network_args_obj=acla)\n",
    "    env, expert = make_dummy_vec_env(name='reach', seq_len=seq_len)\n",
    "    return acl, env, expert, seq_len, epsiodes, device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-12 16:18:34.168502: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-12 16:18:34.168710: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/hendrik/Documents/master_project/CoppeliaSim_Player_V4_1_0_Ubuntu20_04:/home/hendrik/.mujoco/mujoco210/bin:/usr/lib/nvidia\n",
      "2022-10-12 16:18:34.168756: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/hendrik/Documents/master_project/CoppeliaSim_Player_V4_1_0_Ubuntu20_04:/home/hendrik/.mujoco/mujoco210/bin:/usr/lib/nvidia\n",
      "2022-10-12 16:18:34.168798: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/hendrik/Documents/master_project/CoppeliaSim_Player_V4_1_0_Ubuntu20_04:/home/hendrik/.mujoco/mujoco210/bin:/usr/lib/nvidia\n",
      "2022-10-12 16:18:34.168839: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/hendrik/Documents/master_project/CoppeliaSim_Player_V4_1_0_Ubuntu20_04:/home/hendrik/.mujoco/mujoco210/bin:/usr/lib/nvidia\n",
      "2022-10-12 16:18:34.168879: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/hendrik/Documents/master_project/CoppeliaSim_Player_V4_1_0_Ubuntu20_04:/home/hendrik/.mujoco/mujoco210/bin:/usr/lib/nvidia\n",
      "2022-10-12 16:18:34.168921: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/hendrik/Documents/master_project/CoppeliaSim_Player_V4_1_0_Ubuntu20_04:/home/hendrik/.mujoco/mujoco210/bin:/usr/lib/nvidia\n",
      "2022-10-12 16:18:34.168961: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/hendrik/Documents/master_project/CoppeliaSim_Player_V4_1_0_Ubuntu20_04:/home/hendrik/.mujoco/mujoco210/bin:/usr/lib/nvidia\n",
      "2022-10-12 16:18:34.169003: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/hendrik/Documents/master_project/CoppeliaSim_Player_V4_1_0_Ubuntu20_04:/home/hendrik/.mujoco/mujoco210/bin:/usr/lib/nvidia\n",
      "2022-10-12 16:18:34.169008: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-10-12 16:18:34.169627: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling expert transitions. 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hendrik/anaconda3/envs/ac/lib/python3.10/site-packages/metaworld/policies/policy.py:41: UserWarning: Constant(s) may be too high. Environments clip response to [-1, 1]\n",
      "  warnings.warn('Constant(s) may be too high. Environments clip response to [-1, 1]')\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "acl, env, expert, seq_len, epsiodes, device = make_acl()\n",
    "env, expert = make_dummy_vec_env(name='reach', seq_len=seq_len)\n",
    "transitions = sample_expert_transitions(\n",
    "    policy=expert.predict, env=env, episodes=epsiodes)\n",
    "exp_actions, exp_observations, exp_rewards = parse_sampled_transitions(\n",
    "    transitions=transitions, new_epoch=new_epoch_reach, extractor=DummyExtractor(), device=device)\n",
    "part_acts, part_obsv, part_rews = make_part_obs_data(\n",
    "    actions=exp_actions, observations=exp_observations, rewards=exp_rewards)\n",
    "imitation_data = DatasetAC(device='cuda')\n",
    "imitation_data.onyl_positiv = False\n",
    "imitation_data.add_data(obsv=part_obsv, actions=part_acts, reward=part_rews)\n",
    "# acl.setDatasets(train_data=imitation_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling expert transitions. 1\n",
      "Sampling expert transitions. 5\n",
      "/home/hendrik/Documents/master_project/LokalData/TransformerImitationLearning/best_validation\n",
      "Sampling expert transitions. 1\n",
      "Sampling expert transitions. 5\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m acl\u001b[39m.\u001b[39;49mtrain(epochs\u001b[39m=\u001b[39;49m\u001b[39m10000\u001b[39;49m)\n",
      "File \u001b[0;32m~/Documents/master_project/Code/active_critic/src/active_critic/learner/active_critic_learner.py:147\u001b[0m, in \u001b[0;36mActiveCriticLearner.train\u001b[0;34m(self, epochs)\u001b[0m\n\u001b[1;32m    145\u001b[0m next_val \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnetwork_args\u001b[39m.\u001b[39mval_every\n\u001b[1;32m    146\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnetwork_args\u001b[39m.\u001b[39mtboard:\n\u001b[0;32m--> 147\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun_validation()\n",
      "File \u001b[0;32m~/Documents/master_project/Code/active_critic/src/active_critic/learner/active_critic_learner.py:162\u001b[0m, in \u001b[0;36mActiveCriticLearner.run_validation\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun_validation\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 162\u001b[0m     actions, observations, rewards, expected_rewards_before, expected_rewards_after \u001b[39m=\u001b[39m sample_new_episode(\n\u001b[1;32m    163\u001b[0m         policy\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpolicy,\n\u001b[1;32m    164\u001b[0m         env\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv,\n\u001b[1;32m    165\u001b[0m         episodes\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnetwork_args\u001b[39m.\u001b[39;49mvalidation_episodes)\n\u001b[1;32m    166\u001b[0m     opt_trj \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpolicy\u001b[39m.\u001b[39mhistory\u001b[39m.\u001b[39mgen_trj[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m]\n\u001b[1;32m    167\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcreateGraphsMW(d_in\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, d_out\u001b[39m=\u001b[39mactions[\u001b[39m0\u001b[39m], result\u001b[39m=\u001b[39mactions[\u001b[39m0\u001b[39m], toy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    168\u001b[0m                             inpt\u001b[39m=\u001b[39mobservations[:,\u001b[39m0\u001b[39m], name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mTrajectory\u001b[39m\u001b[39m'\u001b[39m, window\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, opt_trj\u001b[39m=\u001b[39mopt_trj)\n",
      "File \u001b[0;32m~/Documents/master_project/Code/active_critic/src/active_critic/utils/gym_utils.py:136\u001b[0m, in \u001b[0;36msample_new_episode\u001b[0;34m(policy, env, episodes, return_gen_trj)\u001b[0m\n\u001b[1;32m    134\u001b[0m policy\u001b[39m.\u001b[39meval()\n\u001b[1;32m    135\u001b[0m policy\u001b[39m.\u001b[39mreset()\n\u001b[0;32m--> 136\u001b[0m transitions \u001b[39m=\u001b[39m sample_expert_transitions(\n\u001b[1;32m    137\u001b[0m     policy\u001b[39m.\u001b[39;49mpredict, env, episodes)\n\u001b[1;32m    138\u001b[0m expected_rewards_after \u001b[39m=\u001b[39m policy\u001b[39m.\u001b[39mhistory\u001b[39m.\u001b[39mopt_scores[\u001b[39m0\u001b[39m]\n\u001b[1;32m    139\u001b[0m expected_rewards_before \u001b[39m=\u001b[39m policy\u001b[39m.\u001b[39mhistory\u001b[39m.\u001b[39mgen_scores[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/Documents/master_project/Code/active_critic/src/active_critic/utils/gym_utils.py:111\u001b[0m, in \u001b[0;36msample_expert_transitions\u001b[0;34m(policy, env, episodes)\u001b[0m\n\u001b[1;32m    108\u001b[0m expert \u001b[39m=\u001b[39m policy\n\u001b[1;32m    110\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mSampling expert transitions. \u001b[39m\u001b[39m{\u001b[39;00mepisodes\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 111\u001b[0m rollouts \u001b[39m=\u001b[39m rollout(\n\u001b[1;32m    112\u001b[0m     expert,\n\u001b[1;32m    113\u001b[0m     env,\n\u001b[1;32m    114\u001b[0m     make_sample_until(min_timesteps\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m, min_episodes\u001b[39m=\u001b[39;49mepisodes),\n\u001b[1;32m    115\u001b[0m     unwrap\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    116\u001b[0m     exclude_infos\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m\n\u001b[1;32m    117\u001b[0m )\n\u001b[1;32m    118\u001b[0m \u001b[39mreturn\u001b[39;00m flatten_trajectories(rollouts)\n",
      "File \u001b[0;32m~/Documents/master_project/Code/active_critic/src/active_critic/utils/rollout.py:582\u001b[0m, in \u001b[0;36mrollout\u001b[0;34m(policy, venv, sample_until, unwrap, exclude_infos, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    546\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrollout\u001b[39m(\n\u001b[1;32m    547\u001b[0m     policy: AnyPolicy,\n\u001b[1;32m    548\u001b[0m     venv: VecEnv,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    554\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m    555\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Sequence[types\u001b[39m.\u001b[39mTrajectoryWithRew]:\n\u001b[1;32m    556\u001b[0m     \u001b[39m\"\"\"Generate policy rollouts.\u001b[39;00m\n\u001b[1;32m    557\u001b[0m \n\u001b[1;32m    558\u001b[0m \u001b[39m    The `.infos` field of each Trajectory is set to `None` to save space.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    580\u001b[0m \u001b[39m        should truncate if required.\u001b[39;00m\n\u001b[1;32m    581\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 582\u001b[0m     trajs \u001b[39m=\u001b[39m generate_trajectories(policy, venv, sample_until, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    583\u001b[0m     \u001b[39mif\u001b[39;00m unwrap:\n\u001b[1;32m    584\u001b[0m         trajs \u001b[39m=\u001b[39m [unwrap_traj(traj) \u001b[39mfor\u001b[39;00m traj \u001b[39min\u001b[39;00m trajs]\n",
      "File \u001b[0;32m~/Documents/master_project/Code/active_critic/src/active_critic/utils/rollout.py:362\u001b[0m, in \u001b[0;36mgenerate_trajectories\u001b[0;34m(policy, venv, sample_until, deterministic_policy, rng)\u001b[0m\n\u001b[1;32m    360\u001b[0m active \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mones(venv\u001b[39m.\u001b[39mnum_envs, dtype\u001b[39m=\u001b[39m\u001b[39mbool\u001b[39m)\n\u001b[1;32m    361\u001b[0m \u001b[39mwhile\u001b[39;00m np\u001b[39m.\u001b[39many(active):\n\u001b[0;32m--> 362\u001b[0m     acts \u001b[39m=\u001b[39m get_actions(obs)\n\u001b[1;32m    363\u001b[0m     obs, rews, dones, infos \u001b[39m=\u001b[39m venv\u001b[39m.\u001b[39mstep(acts)\n\u001b[1;32m    365\u001b[0m     \u001b[39m# If an environment is inactive, i.e. the episode completed for that\u001b[39;00m\n\u001b[1;32m    366\u001b[0m     \u001b[39m# environment after `sample_until(trajectories)` was true, then we do\u001b[39;00m\n\u001b[1;32m    367\u001b[0m     \u001b[39m# *not* want to add any subsequent trajectories from it. We avoid this\u001b[39;00m\n\u001b[1;32m    368\u001b[0m     \u001b[39m# by just making it never done.\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/master_project/Code/active_critic/src/active_critic/policy/active_critic_policy.py:117\u001b[0m, in \u001b[0;36mActiveCriticPolicy.predict\u001b[0;34m(self, observation, state, episode_start, deterministic)\u001b[0m\n\u001b[1;32m    113\u001b[0m     action_seq \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcurrent_result\u001b[39m.\u001b[39mgen_trj\n\u001b[1;32m    115\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobs_seq[:, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcurrent_step:\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcurrent_step\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m, :] \u001b[39m=\u001b[39m vec_obsv\n\u001b[0;32m--> 117\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcurrent_result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(\n\u001b[1;32m    118\u001b[0m     observation_seq\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mobs_seq, action_seq\u001b[39m=\u001b[39;49maction_seq, optimize\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49margs_obj\u001b[39m.\u001b[39;49moptimize, current_step\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcurrent_step)\n\u001b[1;32m    120\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs_obj\u001b[39m.\u001b[39moptimize:\n\u001b[1;32m    121\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhistory\u001b[39m.\u001b[39madd_value(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhistory\u001b[39m.\u001b[39mopt_scores, value\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcurrent_result\u001b[39m.\u001b[39mexpected_succes_after[:, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcurrent_step]\u001b[39m.\u001b[39mdetach(), current_step\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcurrent_step)\n",
      "File \u001b[0;32m~/Documents/master_project/Code/active_critic/src/active_critic/policy/active_critic_policy.py:150\u001b[0m, in \u001b[0;36mActiveCriticPolicy.forward\u001b[0;34m(self, observation_seq, action_seq, optimize, current_step)\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n\u001b[1;32m    149\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m     actions, expected_success_opt \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptimize_act_sequence(\n\u001b[1;32m    151\u001b[0m         actions\u001b[39m=\u001b[39;49mactions, observations\u001b[39m=\u001b[39;49mobservation_seq, current_step\u001b[39m=\u001b[39;49mcurrent_step)\n\u001b[1;32m    153\u001b[0m     \u001b[39mreturn\u001b[39;00m ACPOptResult(\n\u001b[1;32m    154\u001b[0m         gen_trj\u001b[39m=\u001b[39mactions\u001b[39m.\u001b[39mdetach(),\n\u001b[1;32m    155\u001b[0m         expected_succes_before\u001b[39m=\u001b[39mexpected_success,\n\u001b[1;32m    156\u001b[0m         expected_succes_after\u001b[39m=\u001b[39mexpected_success_opt)\n",
      "File \u001b[0;32m~/Documents/master_project/Code/active_critic/src/active_critic/policy/active_critic_policy.py:171\u001b[0m, in \u001b[0;36mActiveCriticPolicy.optimize_act_sequence\u001b[0;34m(self, actions, observations, current_step)\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcritic\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39meval()\n\u001b[1;32m    169\u001b[0m \u001b[39mwhile\u001b[39;00m (\u001b[39mnot\u001b[39;00m th\u001b[39m.\u001b[39mall(expected_success[:, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs_obj\u001b[39m.\u001b[39moptimisation_threshold)) \u001b[39mand\u001b[39;00m (step \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs_obj\u001b[39m.\u001b[39mopt_steps):\n\u001b[0;32m--> 171\u001b[0m     optimized_actions, expected_success \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minference_opt_step(\n\u001b[1;32m    172\u001b[0m         org_actions\u001b[39m=\u001b[39;49mactions,\n\u001b[1;32m    173\u001b[0m         opt_actions\u001b[39m=\u001b[39;49moptimized_actions,\n\u001b[1;32m    174\u001b[0m         obs_seq\u001b[39m=\u001b[39;49mobservations,\n\u001b[1;32m    175\u001b[0m         optimizer\u001b[39m=\u001b[39;49moptimizer,\n\u001b[1;32m    176\u001b[0m         goal_label\u001b[39m=\u001b[39;49mgoal_label,\n\u001b[1;32m    177\u001b[0m         current_step\u001b[39m=\u001b[39;49mcurrent_step)\n\u001b[1;32m    178\u001b[0m     step \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    180\u001b[0m \u001b[39mreturn\u001b[39;00m optimized_actions, expected_success\n",
      "File \u001b[0;32m~/Documents/master_project/Code/active_critic/src/active_critic/policy/active_critic_policy.py:189\u001b[0m, in \u001b[0;36mActiveCriticPolicy.inference_opt_step\u001b[0;34m(self, org_actions, opt_actions, obs_seq, optimizer, goal_label, current_step)\u001b[0m\n\u001b[1;32m    185\u001b[0m critic_loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcritic\u001b[39m.\u001b[39mloss_fct(\n\u001b[1;32m    186\u001b[0m     result\u001b[39m=\u001b[39mcritic_result, label\u001b[39m=\u001b[39mgoal_label)\n\u001b[1;32m    188\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m--> 189\u001b[0m critic_loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m    190\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m    192\u001b[0m actions \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mproj_actions(\n\u001b[1;32m    193\u001b[0m     org_actions\u001b[39m=\u001b[39morg_actions, new_actions\u001b[39m=\u001b[39mopt_actions, current_step\u001b[39m=\u001b[39mcurrent_step)\n",
      "File \u001b[0;32m~/anaconda3/envs/ac/lib/python3.10/site-packages/torch/_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    388\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    389\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    390\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    394\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[1;32m    395\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[0;32m--> 396\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[0;32m~/anaconda3/envs/ac/lib/python3.10/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    175\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "acl.train(epochs=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acl.policy.score_history_after\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('ac')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c27e8fa6375f4d15af5a5f5541d8bb88746b588c9fe1102cfd8de011d36c10c2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
