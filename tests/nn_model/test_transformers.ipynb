{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "from active_critic.model_src.transformer import ModelSetup, TransformerModel, generate_square_subsequent_mask\n",
    "from active_critic.model_src.base_transformer import DebugTEL\n",
    "import torch as th\n",
    "from active_critic.utils.pytorch_utils import calcMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms = ModelSetup()\n",
    "seq_len = 3\n",
    "ntoken = 3\n",
    "batch_size = 2\n",
    "d_output = 4\n",
    "\n",
    "ms.d_output = d_output\n",
    "ms.nhead = 2\n",
    "ms.d_hid = 10\n",
    "ms.d_model = 10\n",
    "ms.nlayers = 1\n",
    "ms.seq_len = seq_len\n",
    "ms.dropout = 0\n",
    "ms.ntoken = 1\n",
    "ms.lr = None\n",
    "ms.device = 'cpu'\n",
    "device = 'cpu'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_seq_encoding_data(batch_size, seq_len, ntoken, d_out, device = 'cuda'):\n",
    "    inpt_seq = th.ones([batch_size,seq_len,ntoken], dtype=th.float, device=device)\n",
    "    outpt_seq = th.ones([batch_size,seq_len,d_out], dtype=th.float, device=device)\n",
    "    outpt_seq[:,::2] = 0\n",
    "    return inpt_seq, outpt_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tm = TransformerModel(model_setup=ms)\n",
    "mask = generate_square_subsequent_mask(3)\n",
    "mask = mask.unsqueeze(0).repeat([2, 1, 1])\n",
    "mask[0] = 0\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "o_req: torch.Size([6, 3, 4])\n",
      "attention_mask: torch.Size([12, 3, 3])\n",
      "src: torch.Size([6, 3, 10])\n",
      "mask: torch.Size([12, 3, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0289, -0.0063,  0.0144, -0.0289],\n",
       "         [ 0.0194,  0.0019,  0.0216, -0.0212],\n",
       "         [ 0.0169,  0.0015,  0.0225, -0.0183]],\n",
       "\n",
       "        [[ 0.0124, -0.0052,  0.0108, -0.0006],\n",
       "         [ 0.0115, -0.0010,  0.0121, -0.0034],\n",
       "         [ 0.0112, -0.0003,  0.0115, -0.0053]],\n",
       "\n",
       "        [[ 0.0133,  0.0013,  0.0081, -0.0046],\n",
       "         [ 0.0131,  0.0015,  0.0087, -0.0050],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[ 0.0174,  0.0020,  0.0126,  0.0090],\n",
       "         [ 0.0190,  0.0018,  0.0105,  0.0027],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[ 0.0123, -0.0005,  0.0078, -0.0144],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[ 0.0080, -0.0123,  0.0179,  0.0036],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000]]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def pull_tens_to_front(src, i):\n",
    "    if i > 0:\n",
    "        src[i, :, :-i] = src[i,:,i:]\n",
    "        src[i, :, -i:] = -1\n",
    "\n",
    "    return src\n",
    "\n",
    "def pull_tens_to_front_sparse(src, i):\n",
    "    pulled = src[i,:,i:]\n",
    "    max_pulled = pulled.max(dim=-2).values == 1\n",
    "    max_pulled = max_pulled.unsqueeze(-2).repeat([1, 1, src.shape[2] - i, 1])\n",
    "    if i > 0:\n",
    "        src[i, :, :-i] = max_pulled\n",
    "        src[i, :, -i:] = -1\n",
    "    else:\n",
    "        src[i, :] = max_pulled\n",
    "\n",
    "    return src\n",
    "\n",
    "def repeat_along_seq_td(src):\n",
    "    src = src.repeat([src.shape[1], 1, 1]).reshape([src.shape[1], src.shape[0], src.shape[1], src.shape[2]])\n",
    "    return src\n",
    "\n",
    "def repeat_along_seq(src, seq_len):\n",
    "    src = src.repeat([1, seq_len, 1])\n",
    "    return src\n",
    "\n",
    "def generate_square_subsequent_mask_dense(seq_len, rewards):\n",
    "    obsv = th.rand([2,3,4], requires_grad=True)\n",
    "\n",
    "\n",
    "def make_dense_seq_encoding_data(actions, obsv, rewards):\n",
    "    actions = repeat_along_seq_td(actions)\n",
    "    obsv = repeat_along_seq_td(obsv)\n",
    "    rewards = repeat_along_seq_td(rewards)\n",
    "    for i in range(len(obsv)):\n",
    "        obsv[i] = obsv[i,:,i].unsqueeze(1)\n",
    "\n",
    "        actions = pull_tens_to_front(actions, i)\n",
    "        rewards = pull_tens_to_front_sparse(rewards, i)\n",
    "    return actions.reshape([-1, actions.shape[-2], actions.shape[-1]]), obsv.reshape([-1, obsv.shape[-2], obsv.shape[-1]]), rewards.reshape([-1, rewards.shape[-2], rewards.shape[-1]])\n",
    "\n",
    "def generate_partial_observed_mask(reward, nheads):\n",
    "    device = reward.device\n",
    "    inv_result_mask = reward.squeeze() == -1\n",
    "    result_mask = ~inv_result_mask\n",
    "    args = th.argwhere(inv_result_mask)\n",
    "    restructured_args = args.repeat([1, reward.shape[1]]).reshape([-1, 2])\n",
    "    exp_ind = th.arange(reward.shape[1], device=device).repeat(args.shape[0])\n",
    "    full_ind = th.cat((restructured_args[:, :1], exp_ind.unsqueeze(1), restructured_args[:, 1:]), dim=-1)\n",
    "    attention_mask = th.zeros([reward.shape[0], reward.shape[1], reward.shape[1]], device=device)\n",
    "    attention_mask[tuple(full_ind.T)] = -float('inf')\n",
    "    attention_mask = attention_mask.repeat([1,1,nheads]).reshape([2*attention_mask.shape[0], attention_mask.shape[1], attention_mask.shape[2]])\n",
    "    return attention_mask, result_mask\n",
    "\n",
    "obsv = th.rand([2,3,4], requires_grad=True)\n",
    "act = th.rand([2,3,2])\n",
    "rewards = th.rand([2,3,1])\n",
    "\n",
    "rewards[0,0,0] = 1\n",
    "a, o, r = make_dense_seq_encoding_data(actions=act, obsv=obsv, rewards=rewards)\n",
    "attention_mask, result_mask = generate_partial_observed_mask(r, ms.nhead)\n",
    "o_req = o.detach()\n",
    "o_req.requires_grad = True\n",
    "print(f'o_req: {o_req.shape}')\n",
    "print(f'attention_mask: {attention_mask.shape}')\n",
    "result = tm.forward(src=o_req, mask=attention_mask)\n",
    "result[result_mask].mean().backward()\n",
    "o_req.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obsv = th.rand([2,1,4], requires_grad=True)\n",
    "rep_obsv = repeat_along_seq(src=obsv, seq_len=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards[0,0,0] = 1\n",
    "a, o, r = make_dense_seq_encoding_data(actions=act, obsv=obsv, rewards=rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_mask, result_mask = generate_partial_observed_mask(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o_req = o.detach()\n",
    "o_req.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = tm.forward(src=o_req, mask=attention_mask)\n",
    "result[result_mask].mean().backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o_req.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = th.argwhere(r.squeeze() == -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restructured_args = args.repeat([1, 3]).reshape([18, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_ind = th.arange(3).repeat(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_ind = th.cat((restructured_args[:, :1], exp_ind.unsqueeze(1), restructured_args[:, 1:]), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_ind.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = th.zeros([r.shape[0], r.shape[1], r.shape[1]])\n",
    "mask[tuple(full_ind.T)] = -float('inf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_args = th.cat((args[:, :1], exp_ind))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_partial_sequence(seq):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = tm.forward(src=obsv, mask=mask)\n",
    "loss = ((result[:, -2])**2).mean()\n",
    "loss.backward()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obsv.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_mask_data(batch_size, seq_len, ntoken, device = 'cuda'):\n",
    "    mask = generate_square_subsequent_mask(seq_len).to(device)\n",
    "    inpt_seq = th.ones([batch_size,seq_len,ntoken], dtype=th.float, device=device)\n",
    "    inpt_seq[0,-1,0] = 0\n",
    "    outpt_seq = th.ones_like(inpt_seq)\n",
    "    outpt_seq[0] = 0\n",
    "    return inpt_seq, outpt_seq, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inpt_seq, outpt_seq = make_seq_encoding_data(batch_size, seq_len, ntoken, d_out = d_output, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_no_conflict_part_data(batch_size, seq_len, obs_dim, d_out, device='cpu'):\n",
    "    inpt = th.ones([batch_size, seq_len, obs_dim])\n",
    "    inpt[0, 1:] = 2\n",
    "    actions = th.arange(seq_len)\n",
    "    actions = actions.reshape([1,-1,1]).repeat([batch_size, 1, d_out])\n",
    "    actions[0] += 1\n",
    "\n",
    "    res, actions = make_part_observed(inpt, actions)\n",
    "    return res, actions\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_part_observed(inpt, actions):\n",
    "    #batch, seq, dim\n",
    "    inpt = inpt.unsqueeze(1).repeat([1,inpt.shape[1], 1, 1])\n",
    "    inpt = inpt.permute([0,3,1,2])\n",
    "    res = th.triu(inpt)\n",
    "    res = res.permute([0,2,3,1]).reshape([-1,seq_len, obs_dim])\n",
    "    \n",
    "    rep_actions = actions.repeat([1,seq_len,1]).reshape([-1,seq_len, d_output])\n",
    "    return res, rep_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_conflict_part_data(batch_size, seq_len, obs_dim, d_out, device='cpu'):\n",
    "    inpt = th.ones([batch_size, seq_len, obs_dim])\n",
    "    inpt[0, :1] = 2\n",
    "    actions = th.arange(seq_len)\n",
    "    actions = actions.reshape([1,-1,1]).repeat([batch_size, 1, d_out])\n",
    "    actions[0, :1] += 1\n",
    "\n",
    "    res, actions = make_part_observed(inpt, actions)\n",
    "    rew = th.ones([batch_size * seq_len, seq_len], device = device)\n",
    "    \n",
    "    return res, actions, rew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_conflict_part_data_neg(batch_size, seq_len, obs_dim, d_out, device='cpu'):\n",
    "    inpt = th.ones([batch_size, seq_len, obs_dim])\n",
    "    inpt[0, -1:] = 2\n",
    "    actions = th.arange(seq_len)\n",
    "    actions = actions.reshape([1,-1,1]).repeat([batch_size, 1, d_out])\n",
    "    actions[0, -1:] += 1\n",
    "\n",
    "    res, actions = make_part_observed(inpt, actions)\n",
    "    rew = th.ones([batch_size * seq_len, seq_len], device = device)\n",
    "    scale = th.arange(seq_len).reshape([1,-1]).repeat([rew.shape[0], 1])\n",
    "    rew = rew * scale / (seq_len - 1)\n",
    "    rew[:,-1:] = 0\n",
    "    \n",
    "    res_copy = res.clone()\n",
    "    res[:seq_len] = res_copy[seq_len:]\n",
    "    res[seq_len:] = res_copy[:seq_len]\n",
    "    \n",
    "    return res, actions, rew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sequence(obs, acts):\n",
    "    result = th.cat((obs, acts), dim=-1)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_dim = 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_nc, act_nc = make_no_conflict_part_data(batch_size, seq_len, obs_dim, d_output, device='cpu')\n",
    "obs_c, act_c, rew_c_pos = make_conflict_part_data(batch_size, seq_len, obs_dim, d_output, device='cpu')\n",
    "obs_c_n, act_c_n, rew_c_neg = make_conflict_part_data_neg(batch_size, seq_len, obs_dim, d_output, device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rew_c_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_n = make_sequence(obs_c_n,act_c_n)\n",
    "seq_p = make_sequence(obs_c,act_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = th.cat((seq_n, seq_p), dim=0)\n",
    "rew = th.cat((rew_c_pos, rew_c_neg), dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms = ModelSetup()\n",
    "seq_len = 3\n",
    "ntoken = 3 + 4\n",
    "batch_size = 2\n",
    "d_output = 1\n",
    "\n",
    "ms.d_output = d_output\n",
    "ms.nhead = 1\n",
    "ms.d_hid = 10\n",
    "ms.d_model = 10\n",
    "ms.nlayers = 1\n",
    "ms.seq_len = seq_len\n",
    "ms.dropout = 0\n",
    "ms.ntoken = 1\n",
    "ms.lr = None\n",
    "ms.device = 'cpu'\n",
    "ms.optimizer_class = th.optim.AdamW\n",
    "ms.optimizer_kwargs = {}\n",
    "ms.model_class:TransformerModel = TransformerModel\n",
    "device = 'cpu'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inpt = seq\n",
    "\n",
    "model = TransformerModel(model_setup=ms).to(device)\n",
    "with th.no_grad():\n",
    "    answer = model.forward(inpt)\n",
    "optimizer = th.optim.Adam(params=model.parameters(), lr=1e-3)\n",
    "loss = 0\n",
    "for i in range(3000):\n",
    "    result = model.forward(inpt)\n",
    "    loss = calcMSE(result, rew)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inpt[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = model.forward(inpt[5].unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rew[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inpt[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result, attention = model.forward(res_c[0].unsqueeze(0), return_attention=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result, attention = model.forward(res[4].unsqueeze(0), return_attention=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = generate_square_subsequent_mask(seq_len).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inpt_seq = th.ones([2,seq_len,1], dtype=th.float, device='cuda')\n",
    "inpt_seq[0,-1,0] = 0\n",
    "\n",
    "outpt_seq = th.ones_like(inpt_seq)\n",
    "outpt_seq[0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inpt_seq, outpt_seq, mask = make_mask_data(batch_size=batch_size, seq_len=seq_len, ntoken=ntoken)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TransformerModel(model_setup=ms).to('cuda')\n",
    "with th.no_grad():\n",
    "    model.forward(inpt_seq)\n",
    "optimizer = th.optim.Adam(params=model.parameters(), lr=1e-3)\n",
    "loss = 0\n",
    "for i in range(1000):\n",
    "    result = model.forward(inpt_seq, mask=None)\n",
    "    loss = calcMSE(result, outpt_seq)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ActiveCritic.model_src.transformer import CriticTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms = ModelSetup()\n",
    "seq_len = 6\n",
    "d_output = 1\n",
    "ms.d_output = d_output\n",
    "ms.nhead = 1\n",
    "ms.d_hid = 10\n",
    "ms.d_model = 10\n",
    "ms.nlayers = 2\n",
    "ms.seq_len = seq_len\n",
    "ms.dropout = 0\n",
    "ms.ntoken = 1\n",
    "ms.lr = None\n",
    "ms.device = 'cuda'\n",
    "ms.optimizer_class = th.optim.AdamW\n",
    "ms.optimizer_kwargs = {}\n",
    "ms.d_result = 1\n",
    "ms.model_class:TransformerModel = CriticTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inpt_seq = th.ones([2,seq_len,4], dtype=th.float, device='cuda')\n",
    "inpt_seq[0,-1,0] = 0\n",
    "\n",
    "outpt_seq = th.ones([2,1], dtype=th.float, device='cuda')\n",
    "outpt_seq[0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CriticTransformer(model_setup=ms).to('cuda')\n",
    "with th.no_grad():\n",
    "    a = model.forward(inpt_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CriticTransformer(model_setup=ms).to('cuda')\n",
    "with th.no_grad():\n",
    "    model.forward(inpt_seq)\n",
    "optimizer = th.optim.Adam(params=model.parameters(), lr=1e-3)\n",
    "loss = 0\n",
    "for i in range(2000):\n",
    "    result = model.forward(inpt_seq)\n",
    "    loss = calcMSE(result, outpt_seq)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('ac')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "c27e8fa6375f4d15af5a5f5541d8bb88746b588c9fe1102cfd8de011d36c10c2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
