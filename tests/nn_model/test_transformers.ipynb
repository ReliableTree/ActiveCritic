{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('C:/Users/Hendrik/PycharmProjects') # go to parent dir\n",
    "\n",
    "from ActiveCritic.model_src.transformer import ModelSetup, TransformerModel, CriticTransformer\n",
    "from ActiveCritic.model_src.base_transformer import DebugTEL\n",
    "import torch as th\n",
    "from ActiveCritic.utils.pytorch_utils import calcMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms = ModelSetup()\n",
    "seq_len = 3\n",
    "ntoken = 3\n",
    "batch_size = 2\n",
    "d_output = 4\n",
    "\n",
    "ms.d_output = d_output\n",
    "ms.nhead = 1\n",
    "ms.d_hid = 10\n",
    "ms.d_model = 10\n",
    "ms.nlayers = 1\n",
    "ms.seq_len = seq_len\n",
    "ms.dropout = 0\n",
    "ms.ntoken = 1\n",
    "ms.lr = None\n",
    "ms.device = 'cpu'\n",
    "ms.optimizer_class = th.optim.AdamW\n",
    "ms.optimizer_kwargs = {}\n",
    "ms.model_class:TransformerModel = TransformerModel\n",
    "device = 'cpu'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_seq_encoding_data(batch_size, seq_len, ntoken, d_out, device = 'cuda'):\n",
    "    inpt_seq = th.ones([batch_size,seq_len,ntoken], dtype=th.float, device=device)\n",
    "    outpt_seq = th.ones([batch_size,seq_len,d_out], dtype=th.float, device=device)\n",
    "    outpt_seq[:,::2] = 0\n",
    "    return inpt_seq, outpt_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_mask_data(batch_size, seq_len, ntoken, device = 'cuda'):\n",
    "    mask = generate_square_subsequent_mask(seq_len).to(device)\n",
    "    inpt_seq = th.ones([batch_size,seq_len,ntoken], dtype=th.float, device=device)\n",
    "    inpt_seq[0,-1,0] = 0\n",
    "    outpt_seq = th.ones_like(inpt_seq)\n",
    "    outpt_seq[0] = 0\n",
    "    return inpt_seq, outpt_seq, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "inpt_seq, outpt_seq = make_seq_encoding_data(batch_size, seq_len, ntoken, d_out = d_output, device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_no_conflict_part_data(batch_size, seq_len, obs_dim, d_out, device='cpu'):\n",
    "    inpt = th.ones([batch_size, seq_len, obs_dim])\n",
    "    inpt[0, 1:] = 2\n",
    "    actions = th.arange(seq_len)\n",
    "    actions = actions.reshape([1,-1,1]).repeat([batch_size, 1, d_out])\n",
    "    actions[0] += 1\n",
    "\n",
    "    res, actions = make_part_observed(inpt, actions)\n",
    "    return res, actions\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_part_observed(inpt, actions):\n",
    "    #batch, seq, dim\n",
    "    inpt = inpt.unsqueeze(1).repeat([1,inpt.shape[1], 1, 1])\n",
    "    inpt = inpt.permute([0,3,1,2])\n",
    "    res = th.triu(inpt)\n",
    "    res = res.permute([0,2,3,1]).reshape([-1,seq_len, obs_dim])\n",
    "    \n",
    "    rep_actions = actions.repeat([1,seq_len,1]).reshape([-1,seq_len, d_output])\n",
    "    return res, rep_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_conflict_part_data(batch_size, seq_len, obs_dim, d_out, device='cpu'):\n",
    "    inpt = th.ones([batch_size, seq_len, obs_dim])\n",
    "    inpt[0, :1] = 2\n",
    "    actions = th.arange(seq_len)\n",
    "    actions = actions.reshape([1,-1,1]).repeat([batch_size, 1, d_out])\n",
    "    actions[0, :1] += 1\n",
    "\n",
    "    res, actions = make_part_observed(inpt, actions)\n",
    "    rew = th.ones([batch_size * seq_len, seq_len], device = device)\n",
    "    \n",
    "    return res, actions, rew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_conflict_part_data_neg(batch_size, seq_len, obs_dim, d_out, device='cpu'):\n",
    "    inpt = th.ones([batch_size, seq_len, obs_dim])\n",
    "    inpt[0, -1:] = 2\n",
    "    actions = th.arange(seq_len)\n",
    "    actions = actions.reshape([1,-1,1]).repeat([batch_size, 1, d_out])\n",
    "    actions[0, -1:] += 1\n",
    "\n",
    "    res, actions = make_part_observed(inpt, actions)\n",
    "    rew = th.ones([batch_size * seq_len, seq_len], device = device)\n",
    "    scale = th.arange(seq_len).reshape([1,-1]).repeat([rew.shape[0], 1])\n",
    "    rew = rew * scale / (seq_len - 1)\n",
    "    rew[:,-1:] = 0\n",
    "    \n",
    "    res_copy = res.clone()\n",
    "    res[:seq_len] = res_copy[seq_len:]\n",
    "    res[seq_len:] = res_copy[:seq_len]\n",
    "    \n",
    "    return res, actions, rew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sequence(obs, acts):\n",
    "    result = th.cat((obs, acts), dim=-1)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_dim = 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_nc, act_nc = make_no_conflict_part_data(batch_size, seq_len, obs_dim, d_output, device='cpu')\n",
    "obs_c, act_c, rew_c_pos = make_conflict_part_data(batch_size, seq_len, obs_dim, d_output, device='cpu')\n",
    "obs_c_n, act_c_n, rew_c_neg = make_conflict_part_data_neg(batch_size, seq_len, obs_dim, d_output, device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.5000, 0.0000],\n",
       "        [0.0000, 0.5000, 0.0000],\n",
       "        [0.0000, 0.5000, 0.0000],\n",
       "        [0.0000, 0.5000, 0.0000],\n",
       "        [0.0000, 0.5000, 0.0000],\n",
       "        [0.0000, 0.5000, 0.0000]])"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rew_c_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_n = make_sequence(obs_c_n,act_c_n)\n",
    "seq_p = make_sequence(obs_c,act_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = th.cat((seq_n, seq_p), dim=0)\n",
    "rew = th.cat((rew_c_pos, rew_c_neg), dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms = ModelSetup()\n",
    "seq_len = 3\n",
    "ntoken = 3 + 4\n",
    "batch_size = 2\n",
    "d_output = 1\n",
    "\n",
    "ms.d_output = d_output\n",
    "ms.nhead = 1\n",
    "ms.d_hid = 10\n",
    "ms.d_model = 10\n",
    "ms.nlayers = 1\n",
    "ms.seq_len = seq_len\n",
    "ms.dropout = 0\n",
    "ms.ntoken = 1\n",
    "ms.lr = None\n",
    "ms.device = 'cpu'\n",
    "ms.optimizer_class = th.optim.AdamW\n",
    "ms.optimizer_kwargs = {}\n",
    "ms.model_class:TransformerModel = TransformerModel\n",
    "device = 'cpu'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "inpt = seq\n",
    "\n",
    "model = TransformerModel(model_setup=ms).to(device)\n",
    "with th.no_grad():\n",
    "    answer = model.forward(inpt)\n",
    "optimizer = th.optim.Adam(params=model.parameters(), lr=1e-3)\n",
    "loss = 0\n",
    "for i in range(3000):\n",
    "    result = model.forward(inpt)\n",
    "    loss = calcMSE(result, rew)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0556, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 2., 2., 2., 2.]])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inpt[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = model.forward(inpt[5].unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.4987],\n",
       "         [1.0001],\n",
       "         [0.9994]]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1.])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rew[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 2., 2., 2., 2.]])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inpt[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "result, attention = model.forward(res_c[0].unsqueeze(0), return_attention=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.0152, 0.9970, 1.0143, 0.9915],\n",
       "         [1.9825, 1.9594, 1.9742, 1.9546],\n",
       "         [2.9630, 2.9960, 2.9902, 3.0279],\n",
       "         [3.9759, 3.9846, 3.9950, 3.9762],\n",
       "         [4.9925, 4.9972, 4.9863, 4.9976]]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.8680e-05, 4.4999e-03, 9.9548e-01, 1.9782e-08, 2.7214e-10],\n",
       "         [9.6357e-06, 3.2713e-03, 9.9672e-01, 6.2094e-09, 6.4015e-11],\n",
       "         [1.2000e-05, 3.4134e-03, 9.9657e-01, 8.6596e-09, 1.0958e-10],\n",
       "         [7.7636e-04, 2.9140e-02, 9.7008e-01, 7.3897e-06, 4.3202e-07],\n",
       "         [1.4408e-03, 3.8925e-02, 9.5961e-01, 2.1836e-05, 1.7041e-06]]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result, attention = model.forward(res[4].unsqueeze(0), return_attention=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ActiveCritic.model_src.transformer import generate_square_subsequent_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = generate_square_subsequent_mask(seq_len).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inpt_seq = th.ones([2,seq_len,1], dtype=th.float, device='cuda')\n",
    "inpt_seq[0,-1,0] = 0\n",
    "\n",
    "outpt_seq = th.ones_like(inpt_seq)\n",
    "outpt_seq[0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inpt_seq, outpt_seq, mask = make_mask_data(batch_size=batch_size, seq_len=seq_len, ntoken=ntoken)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TransformerModel(model_setup=ms).to('cuda')\n",
    "with th.no_grad():\n",
    "    model.forward(inpt_seq)\n",
    "optimizer = th.optim.Adam(params=model.parameters(), lr=1e-3)\n",
    "loss = 0\n",
    "for i in range(1000):\n",
    "    result = model.forward(inpt_seq, mask=None)\n",
    "    loss = calcMSE(result, outpt_seq)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ActiveCritic.model_src.transformer import CriticTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms = ModelSetup()\n",
    "seq_len = 6\n",
    "d_output = 1\n",
    "ms.d_output = d_output\n",
    "ms.nhead = 1\n",
    "ms.d_hid = 10\n",
    "ms.d_model = 10\n",
    "ms.nlayers = 2\n",
    "ms.seq_len = seq_len\n",
    "ms.dropout = 0\n",
    "ms.ntoken = 1\n",
    "ms.lr = None\n",
    "ms.device = 'cuda'\n",
    "ms.optimizer_class = th.optim.AdamW\n",
    "ms.optimizer_kwargs = {}\n",
    "ms.d_result = 1\n",
    "ms.model_class:TransformerModel = CriticTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inpt_seq = th.ones([2,seq_len,4], dtype=th.float, device='cuda')\n",
    "inpt_seq[0,-1,0] = 0\n",
    "\n",
    "outpt_seq = th.ones([2,1], dtype=th.float, device='cuda')\n",
    "outpt_seq[0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CriticTransformer(model_setup=ms).to('cuda')\n",
    "with th.no_grad():\n",
    "    a = model.forward(inpt_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CriticTransformer(model_setup=ms).to('cuda')\n",
    "with th.no_grad():\n",
    "    model.forward(inpt_seq)\n",
    "optimizer = th.optim.Adam(params=model.parameters(), lr=1e-3)\n",
    "loss = 0\n",
    "for i in range(2000):\n",
    "    result = model.forward(inpt_seq)\n",
    "    loss = calcMSE(result, outpt_seq)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "local-venv_torch",
   "language": "python",
   "name": "local-venv_torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "bee90e249730b85f00f3915f0cf4f21bc0729131dcc7008c941068256fd0d344"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
