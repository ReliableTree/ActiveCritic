{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_policy_obs_action(seq_len, ntoken, d_out, diff_ele, device = 'cuda'):\n",
    "    o1 = th.zeros([1, seq_len, ntoken], dtype=th.float, device=device)\n",
    "    o2 = th.zeros_like(o1)\n",
    "    o2[0, diff_ele] = 1\n",
    "\n",
    "    a1 = th.zeros(1, seq_len, d_out, dtype=th.float, device=device)\n",
    "    a2 = th.zeros_like(a1)\n",
    "    a2[:, diff_ele:] = 1\n",
    "    o = th.cat((o1, o2), dim=0)\n",
    "    a = th.cat((a1, a2), dim=0)\n",
    "    \n",
    "    return o, a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observations, actions = make_policy_obs_action(3, 2, 1, 1, 'cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ActiveCritic.utils.pytorch_utils import make_partially_observed_seq\n",
    "import numpy as np\n",
    "import gym\n",
    "import torch as th\n",
    "seq_len = 3\n",
    "d_out = 2\n",
    "d_in = 3\n",
    "acts_array_low = [0]*d_out\n",
    "acts_array_high = [1]*d_out\n",
    "\n",
    "obs = th.ones([2, 1, d_in], dtype=th.float, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_space = gym.spaces.box.Box(\n",
    "    np.array(acts_array_low), np.array(acts_array_high), (d_out,), float)\n",
    "\n",
    "pos = make_partially_observed_seq(obs=obs, acts=None, seq_len=seq_len, act_space=action_space)\n",
    "expected_shape = list(obs.shape)\n",
    "expected_shape[1] = seq_len\n",
    "expected_shape[2] += action_space.shape[0]\n",
    "assert list(pos.shape) == expected_shape, f'Output shape is not as expected. Expected: {expected_shape}, but got {pos.shape}'\n",
    "assert th.all(pos[:,:,obs.shape[-1]:] == 0), 'No action input, but some action fields are not zero.'\n",
    "assert th.equal(pos[:,:obs.shape[1], :obs.shape[2]], obs), 'Observation not correctly inserted into sequence.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_obs_len = 2\n",
    "obs = th.ones([2, current_obs_len, d_in], dtype=th.float, device='cuda')\n",
    "acts = 2*th.ones([2, current_obs_len-1, d_out], dtype=th.float, device='cuda')\n",
    "pos = make_partially_observed_seq(obs=obs, acts=acts, seq_len=seq_len, act_space=action_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_shape = list(obs.shape)\n",
    "expected_shape[1] = seq_len\n",
    "expected_shape[2] += action_space.shape[0]\n",
    "assert list(pos.shape) == expected_shape, f'Output shape is not as expected. Expected: {expected_shape}, but got {pos.shape}'\n",
    "assert th.all(pos[:,acts.shape[1],obs.shape[-1]:] == 0), 'Action that werent input are displayed.'\n",
    "assert th.equal(pos[:,:obs.shape[1], :obs.shape[2]], obs), 'Observation not correctly inserted into sequence.'\n",
    "assert th.equal(pos[:,:acts.shape[1], obs.shape[2]:], acts), 'Not all actions have been inserted correctly.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from ActiveCritic.utils.gym_utils import make_policy_dict\n",
    "from ActiveCritic.metaworld.metaworld.envs import ALL_V2_ENVIRONMENTS_GOAL_OBSERVABLE\n",
    "from gym.wrappers import TimeLimit\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from imitation.data.wrappers import RolloutInfoWrapper\n",
    "from ActiveCritic.utils.gym_utils import new_epoch_reach\n",
    "import numpy as np\n",
    "import torch as th\n",
    "policy_dict = make_policy_dict()\n",
    "\n",
    "env_tag = 'reach'\n",
    "max_episode_steps = 5\n",
    "re = ALL_V2_ENVIRONMENTS_GOAL_OBSERVABLE[policy_dict[env_tag][1]]()\n",
    "re._freeze_rand_vec = False\n",
    "timelimit = TimeLimit(env=re, max_episode_steps=max_episode_steps)\n",
    "dv1 = DummyVecEnv([lambda: RolloutInfoWrapper(timelimit)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ActiveCritic.utils.gym_utils import DummyExtractor\n",
    "de = DummyExtractor()\n",
    "\n",
    "obs1 = de.forward(dv1.reset())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_epoch_reach(obs1, obs1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs2_np, _,_,_ = dv1.step(np.array([[0,1,0,0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hendrik/anaconda3/envs/ac/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/hendrik/anaconda3/envs/ac/lib/python3.10/site-packages/gym/spaces/box.py:73: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "from active_critic.utils.gym_utils import make_dummy_vec_env, sample_expert_transitions, new_epoch_reach, DummyExtractor, parse_sampled_transitions, make_vec_env, parse_sampled_transitions_legacy\n",
    "import torch as th\n",
    "import numpy as np\n",
    "seq_len = 100\n",
    "episodes = 3\n",
    "name = 'reach'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hendrik/anaconda3/envs/ac/lib/python3.10/site-packages/gym/spaces/box.py:73: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  logger.warn(\n",
      "/home/hendrik/anaconda3/envs/ac/lib/python3.10/site-packages/gym/spaces/box.py:73: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "env, exp = make_vec_env(env_id='reach', num_cpu=1, seq_len=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling transitions. 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hendrik/anaconda3/envs/ac/lib/python3.10/site-packages/metaworld/policies/policy.py:41: UserWarning: Constant(s) may be too high. Environments clip response to [-1, 1]\n",
      "  warnings.warn('Constant(s) may be too high. Environments clip response to [-1, 1]')\n"
     ]
    }
   ],
   "source": [
    "transitions = sample_expert_transitions(policy=exp.predict, env=env, episodes=episodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions, observations, rewards = parse_sampled_transitions(transitions=transitions, seq_len=seq_len, extractor=DummyExtractor())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = [0]\n",
    "for i, step in enumerate(transitions):\n",
    "    if step['dones']:\n",
    "        epochs.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = th.tensor(epochs)\n",
    "episodes_len = th.diff(epochs)\n",
    "for i, reward in enumerate(rewards):\n",
    "    assert th.all(reward[int(episodes_len[i]+1):] == -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([52, 48, 42])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "episodes_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions_leg, observations_leg, rewards_leg = parse_sampled_transitions_legacy(transitions=transitions, new_epoch=new_epoch_reach, seq_len=seq_len, extractor=DummyExtractor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert th.equal(actions, actions_leg)\n",
    "assert th.equal(observations, observations_leg)\n",
    "assert th.equal(rewards, rewards_leg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards[1][88] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "th.tensor(np.array(transitions[127]['infos']['unscaled_reward'])) == 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert list(actions.shape) == [episodes, seq_len, env.action_space.shape[0]]\n",
    "assert list(observations.shape) == [episodes, seq_len, env.observation_space.shape[0]]\n",
    "assert list(rewards.shape) == [episodes, seq_len]\n",
    "assert th.all(rewards[:,-1] == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from active_critic.utils.gym_utils import fill_arrays\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 3\n",
    "a = np.ones([3,2])\n",
    "b = np.ones([2,2])\n",
    "c = [a,b]\n",
    "d = fill_arrays(np.array(c), seq_len=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.array(c).dtype == object\n",
    "assert d.dtype is not object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('ac')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c27e8fa6375f4d15af5a5f5541d8bb88746b588c9fe1102cfd8de011d36c10c2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
