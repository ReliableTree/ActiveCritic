{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hendrik/anaconda3/envs/ac/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch as th\n",
    "import higher\n",
    "from active_critic.model_src.whole_sequence_model import CriticSequenceModel, WholeSequenceModelSetup, WholeSequenceModel\n",
    "from active_critic.model_src.transformer import (\n",
    "    ModelSetup, generate_square_subsequent_mask)\n",
    "from active_critic.utils.pytorch_utils import calcMSE\n",
    "import copy\n",
    "th.manual_seed(0)\n",
    "\n",
    "def make_wsm_setup(seq_len, d_output, weight_decay, device='cuda'):\n",
    "    wsm = WholeSequenceModelSetup()\n",
    "    wsm.model_setup = ModelSetup()\n",
    "    seq_len = seq_len\n",
    "    d_output = d_output\n",
    "    wsm.model_setup.d_output = d_output\n",
    "    wsm.model_setup.nhead = 8\n",
    "    wsm.model_setup.d_hid = 200\n",
    "    wsm.model_setup.d_model = 200\n",
    "    wsm.model_setup.nlayers = 5\n",
    "    wsm.model_setup.seq_len = seq_len\n",
    "    wsm.model_setup.dropout = 0\n",
    "    wsm.lr = 1e-4\n",
    "    wsm.model_setup.device = device\n",
    "    wsm.optimizer_class = th.optim.AdamW\n",
    "    wsm.optimizer_kwargs = {'weight_decay':weight_decay}\n",
    "    return wsm\n",
    "\n",
    "class module_parameter(th.nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "seq_len = 10\n",
    "device = 'cuda'\n",
    "weight_decay = 1e-2\n",
    "\n",
    "batch_size = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def high_step(critic:CriticSequenceModel, plan_enc, verbose, inf_opt_steps, inf_opt_lr, obsvs, acts, rewards, goal_rewards, get_critic_inpt):\n",
    "    init_plan_enc = copy.deepcopy(plan_enc)\n",
    "    meta_plan_enc = copy.deepcopy(plan_enc)\n",
    "    inpt_optim = th.optim.SGD(meta_plan_enc.parameters(), lr=inf_opt_lr)\n",
    "    if critic.model is None:\n",
    "        with th.no_grad():\n",
    "            test_inpt = get_critic_inpt(obsvs, acts, plan_enc.param)\n",
    "            critic.forward(test_inpt)\n",
    "\n",
    "    for step in range(inf_opt_steps):\n",
    "        with higher.innerloop_ctx(critic, critic.optimizer) as (higher_critic, higher_optimizer):\n",
    "            with higher.innerloop_ctx(meta_plan_enc, inpt_optim) as (higher_meta_plan_enc, higher_inpt_optim):\n",
    "                meta_inpt = get_critic_inpt(obsvs, acts, higher_meta_plan_enc.param)\n",
    "                init_meta_inpt = get_critic_inpt(obsvs, acts, init_plan_enc.param)\n",
    "                meta_res_1 = higher_critic.forward(meta_inpt)\n",
    "                forward_result = higher_critic.forward(init_meta_inpt)\n",
    "                forward_loss = calcMSE(forward_result, rewards)\n",
    "                meta_loss_1 = calcMSE(meta_res_1, goal_rewards)\n",
    "                higher_inpt_optim.step(meta_loss_1)\n",
    "\n",
    "                meta_inpt = get_critic_inpt(obsvs, acts, higher_meta_plan_enc.param)\n",
    "                meta_res_2 = higher_critic.forward(meta_inpt)\n",
    "                meta_loss_2 = calcMSE(goal_rewards, meta_res_2)\n",
    "\n",
    "                #higher_optimizer.step(loss2)\n",
    "\n",
    "                meta_plan_enc.load_state_dict(higher_meta_plan_enc.state_dict())\n",
    "                grad_of_grads = th.autograd.grad(\n",
    "                    meta_loss_2 + forward_loss, higher_critic.parameters(time=0))\n",
    "                if verbose:\n",
    "                    print(f'{step}___________________________________ meta')\n",
    "                    print(f'loss2: {meta_loss_2}')\n",
    "                    print(f'forward: {forward_loss}')\n",
    "                    print(f'total: {meta_loss_2 + forward_loss}')\n",
    "                    print(f'diff: {meta_loss_1-meta_loss_2}')\n",
    "                    #print(grad_of_grads[0])\n",
    "        critic_param_list = list(critic.parameters())\n",
    "        max_grad = 0\n",
    "        for index in range(len(grad_of_grads)):\n",
    "            critic_param_list[index].grad = grad_of_grads[index]\n",
    "            abs_grad = th.abs(grad_of_grads[index]).max()\n",
    "            max_grad = max(max_grad, abs_grad)\n",
    "        if verbose:\n",
    "            print(max_grad)\n",
    "        critic.optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_planner_inpt(acts, obsvs):\n",
    "    return th.cat((acts, obsvs), dim=-1)\n",
    "\n",
    "def get_actor_inpt(plans, obsvs):\n",
    "    return th.cat((plans, obsvs), dim=-1)\n",
    "\n",
    "def get_critic_inpt(obsvs, acts, plan):\n",
    "    return th.cat((obsvs, acts, plan), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def critic_step(\n",
    "        critic:CriticSequenceModel, \n",
    "        planner:WholeSequenceModel, \n",
    "        verbose, \n",
    "        inf_opt_steps, \n",
    "        inf_opt_lr, \n",
    "        obsvs, \n",
    "        acts, \n",
    "        rewards, \n",
    "        goal_rewards,\n",
    "        get_critic_inpt, \n",
    "        get_planner_inpt,\n",
    "        expert_trjs,\n",
    "        ):\n",
    "    planner_inpt = get_planner_inpt(acts=acts, obsvs=obsvs)\n",
    "    with th.no_grad():\n",
    "        plans = planner.forward(planner_inpt)\n",
    "        plans[expert_trjs] = 0\n",
    "    plans_param = th.nn.parameter.Parameter(plans.detach())\n",
    "    plans_module = module_parameter()\n",
    "    plans_module.register_parameter('param', param=plans_param)\n",
    "    high_step(critic=critic, plan_enc=plans_module, verbose=verbose, inf_opt_steps=inf_opt_steps, inf_opt_lr=inf_opt_lr, obsvs=obsvs, acts=acts, rewards=rewards, goal_rewards=goal_rewards, get_critic_inpt=get_critic_inpt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def actor_step(actor:WholeSequenceModel, planner:WholeSequenceModel, obsvs:th.Tensor, acts:th.Tensor, expert_trjs:th.Tensor, get_planner_inpt, get_actor_inpt, verbose):\n",
    "\n",
    "    planner_inpt = get_planner_inpt(acts=acts, obsvs=obsvs)\n",
    "    plans = planner.forward(planner_inpt)\n",
    "    plans[expert_trjs] = 0\n",
    "\n",
    "    actor_input = get_actor_inpt(plans=plans, obsvs=obsvs)\n",
    "    actor_result = actor.forward(actor_input)\n",
    "    loss = ((actor_result.reshape(-1) - acts.reshape(-1))**2).mean()\n",
    "    actor.optimizer.zero_grad()\n",
    "    planner.optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    actor.optimizer.step()\n",
    "    planner.optimizer.step()\n",
    "    if verbose:\n",
    "        print('actor________________________________________')\n",
    "        print(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "obsvs = th.zeros([batch_size, seq_len, 3], dtype=th.float32, device=device)\n",
    "obsvs[1] = 1\n",
    "acts = th.rand([batch_size, seq_len, 2], dtype=th.float32, device=device)\n",
    "rewards = th.zeros([batch_size, 1, 1], dtype=th.float32, device=device)\n",
    "goal_rewards = th.ones_like(rewards)\n",
    "expert_trjs = th.ones([batch_size], device=device, dtype=th.bool)\n",
    "expert_trjs[0] = 1\n",
    "\n",
    "wsm_planner_setup = make_wsm_setup(\n",
    "        seq_len=seq_len, d_output=3, device=device, weight_decay=weight_decay)\n",
    "planner = WholeSequenceModel(wsm_planner_setup)\n",
    "\n",
    "wsm_actor_setup = make_wsm_setup(\n",
    "        seq_len=seq_len, d_output=2, device=device, weight_decay=weight_decay)\n",
    "actor = WholeSequenceModel(wsm_actor_setup)\n",
    "\n",
    "wsm_critic_setup = make_wsm_setup(\n",
    "        seq_len=seq_len, d_output=1, device=device, weight_decay=weight_decay)\n",
    "critic = CriticSequenceModel(wsm_critic_setup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0___________________________________ meta\n",
      "loss2: 1.5033451318740845\n",
      "forward: 0.05153676122426987\n",
      "total: 1.5548819303512573\n",
      "diff: 0.00046312808990478516\n",
      "tensor(2.9788, device='cuda:0')\n",
      "1___________________________________ meta\n",
      "loss2: 1.3436613082885742\n",
      "forward: 0.02607967145740986\n",
      "total: 1.3697409629821777\n",
      "diff: 0.0003428459167480469\n",
      "tensor(4.1799, device='cuda:0')\n",
      "2___________________________________ meta\n",
      "loss2: 1.2100670337677002\n",
      "forward: 0.011262440122663975\n",
      "total: 1.2213294506072998\n",
      "diff: 0.00029838085174560547\n",
      "tensor(5.0468, device='cuda:0')\n",
      "actor________________________________________\n",
      "tensor(0.3334, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "actor________________________________________\n",
      "tensor(0.1347, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "actor________________________________________\n",
      "tensor(0.1115, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "actor________________________________________\n",
      "tensor(0.1280, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "actor________________________________________\n",
      "tensor(0.1466, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "actor________________________________________\n",
      "tensor(0.1480, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "actor________________________________________\n",
      "tensor(0.1317, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "actor________________________________________\n",
      "tensor(0.1103, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "actor________________________________________\n",
      "tensor(0.0956, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "actor________________________________________\n",
      "tensor(0.0913, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "0___________________________________ meta\n",
      "loss2: 0.25231295824050903\n",
      "forward: 0.24667133390903473\n",
      "total: 0.49898427724838257\n",
      "diff: 0.0010406970977783203\n",
      "tensor(0.0615, device='cuda:0')\n",
      "1___________________________________ meta\n",
      "loss2: 0.25115150213241577\n",
      "forward: 0.2467523217201233\n",
      "total: 0.49790382385253906\n",
      "diff: 0.0010592341423034668\n",
      "tensor(0.0486, device='cuda:0')\n",
      "2___________________________________ meta\n",
      "loss2: 0.24959120154380798\n",
      "forward: 0.24710121750831604\n",
      "total: 0.496692419052124\n",
      "diff: 0.0011330246925354004\n",
      "tensor(0.0273, device='cuda:0')\n",
      "actor________________________________________\n",
      "tensor(0.0749, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "actor________________________________________\n",
      "tensor(0.0747, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "actor________________________________________\n",
      "tensor(0.0746, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "actor________________________________________\n",
      "tensor(0.0747, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "actor________________________________________\n",
      "tensor(0.0747, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "actor________________________________________\n",
      "tensor(0.0745, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "actor________________________________________\n",
      "tensor(0.0743, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "actor________________________________________\n",
      "tensor(0.0743, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "actor________________________________________\n",
      "tensor(0.0743, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "actor________________________________________\n",
      "tensor(0.0743, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "0___________________________________ meta\n",
      "loss2: 0.14313967525959015\n",
      "forward: 0.11899279057979584\n",
      "total: 0.262132465839386\n",
      "diff: 0.4720878005027771\n",
      "tensor(0.4902, device='cuda:0')\n",
      "1___________________________________ meta\n",
      "loss2: 0.13116011023521423\n",
      "forward: 0.11882004141807556\n",
      "total: 0.2499801516532898\n",
      "diff: 0.0029534995555877686\n",
      "tensor(0.1201, device='cuda:0')\n",
      "2___________________________________ meta\n",
      "loss2: 0.13097146153450012\n",
      "forward: 0.11909544467926025\n",
      "total: 0.2500669062137604\n",
      "diff: 0.002516508102416992\n",
      "tensor(0.1079, device='cuda:0')\n",
      "actor________________________________________\n",
      "tensor(0.0595, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "actor________________________________________\n",
      "tensor(0.0605, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "actor________________________________________\n",
      "tensor(0.0625, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "actor________________________________________\n",
      "tensor(0.0652, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "actor________________________________________\n",
      "tensor(0.0671, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "actor________________________________________\n",
      "tensor(0.0675, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "actor________________________________________\n",
      "tensor(0.0642, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "actor________________________________________\n",
      "tensor(0.0606, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "actor________________________________________\n",
      "tensor(0.0592, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "actor________________________________________\n",
      "tensor(0.0618, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "0___________________________________ meta\n",
      "loss2: 0.15834340453147888\n",
      "forward: 2.3548886019852944e-05\n",
      "total: 0.15836694836616516\n",
      "diff: 0.8469241857528687\n",
      "tensor(2.0525, device='cuda:0')\n",
      "1___________________________________ meta\n",
      "loss2: 0.0006761929835192859\n",
      "forward: 0.09431266784667969\n",
      "total: 0.0949888601899147\n",
      "diff: 0.002043412998318672\n",
      "tensor(1.2924, device='cuda:0')\n",
      "2___________________________________ meta\n",
      "loss2: 0.000333120085997507\n",
      "forward: 0.04612353444099426\n",
      "total: 0.046456653624773026\n",
      "diff: 0.0018341136164963245\n",
      "tensor(0.6134, device='cuda:0')\n",
      "actor________________________________________\n",
      "tensor(0.0335, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "actor________________________________________\n",
      "tensor(0.0331, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "actor________________________________________\n",
      "tensor(0.0330, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "actor________________________________________\n",
      "tensor(0.0323, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "actor________________________________________\n",
      "tensor(0.0328, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "actor________________________________________\n",
      "tensor(0.0333, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "actor________________________________________\n",
      "tensor(0.0353, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "actor________________________________________\n",
      "tensor(0.0361, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "actor________________________________________\n",
      "tensor(0.0386, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "actor________________________________________\n",
      "tensor(0.0358, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "0___________________________________ meta\n",
      "loss2: 0.00034731061896309257\n",
      "forward: 0.0001857951283454895\n",
      "total: 0.0005331057473085821\n",
      "diff: 0.9846574664115906\n",
      "tensor(0.0697, device='cuda:0')\n",
      "1___________________________________ meta\n",
      "loss2: 4.13284851674689e-06\n",
      "forward: 7.148053555283695e-05\n",
      "total: 7.561338134109974e-05\n",
      "diff: 0.0003671232843771577\n",
      "tensor(0.0177, device='cuda:0')\n",
      "2___________________________________ meta\n",
      "loss2: 1.3267572285258211e-06\n",
      "forward: 2.4742312234593555e-06\n",
      "total: 3.8009884519851767e-06\n",
      "diff: 0.00011071046174038202\n",
      "tensor(0.0050, device='cuda:0')\n",
      "actor________________________________________\n",
      "tensor(0.0059, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "actor________________________________________\n",
      "tensor(0.0079, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "actor________________________________________\n",
      "tensor(0.0095, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "actor________________________________________\n",
      "tensor(0.0092, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "actor________________________________________\n",
      "tensor(0.0069, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "actor________________________________________\n",
      "tensor(0.0076, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "actor________________________________________\n",
      "tensor(0.0098, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "actor________________________________________\n",
      "tensor(0.0092, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "actor________________________________________\n",
      "tensor(0.0104, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "actor________________________________________\n",
      "tensor(0.0128, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "0___________________________________ meta\n",
      "loss2: 5.74260639041313e-09\n",
      "forward: 1.104368863025229e-08\n",
      "total: 1.678629502066542e-08\n",
      "diff: 1.0001037120819092\n",
      "tensor(0.0006, device='cuda:0')\n",
      "1___________________________________ meta\n",
      "loss2: 5.568523420151905e-11\n",
      "forward: 1.2166418983383664e-09\n",
      "total: 1.2723271325398855e-09\n",
      "diff: 7.26267757045207e-09\n",
      "tensor(9.6118e-05, device='cuda:0')\n",
      "2___________________________________ meta\n",
      "loss2: 4.664713060265058e-11\n",
      "forward: 3.1831732805187585e-09\n",
      "total: 3.229820411121409e-09\n",
      "diff: 5.582911910551047e-09\n",
      "tensor(0.0001, device='cuda:0')\n",
      "actor________________________________________\n",
      "tensor(0.0005, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "actor________________________________________\n",
      "tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "actor________________________________________\n",
      "tensor(0.0005, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "actor________________________________________\n",
      "tensor(0.0007, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "actor________________________________________\n",
      "tensor(0.0005, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "actor________________________________________\n",
      "tensor(0.0004, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "actor________________________________________\n",
      "tensor(0.0002, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "actor________________________________________\n",
      "tensor(0.0001, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "actor________________________________________\n",
      "tensor(0.0003, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "actor________________________________________\n",
      "tensor(0.0004, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "0___________________________________ meta\n",
      "loss2: 1.2967404927621828e-10\n",
      "forward: 1.3713474800169934e-12\n",
      "total: 1.3104539675623528e-10\n",
      "diff: 1.0000005960464478\n",
      "tensor(5.6394e-05, device='cuda:0')\n",
      "1___________________________________ meta\n",
      "loss2: 1.1652900866465643e-12\n",
      "forward: 1.191047260817868e-11\n",
      "total: 1.3075762694825244e-11\n",
      "diff: 9.757883390193456e-11\n",
      "tensor(1.1109e-05, device='cuda:0')\n",
      "2___________________________________ meta\n",
      "loss2: 1.7763568394002505e-13\n",
      "forward: 1.6051604490030513e-11\n",
      "total: 1.6229240173970538e-11\n",
      "diff: 5.755396159656812e-13\n",
      "tensor(1.3058e-05, device='cuda:0')\n",
      "actor________________________________________\n",
      "tensor(1.4524e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "actor________________________________________\n",
      "tensor(1.3556e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "actor________________________________________\n",
      "tensor(7.1201e-09, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "actor________________________________________\n",
      "tensor(8.8719e-09, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "actor________________________________________\n",
      "tensor(6.3097e-09, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "actor________________________________________\n",
      "tensor(9.2012e-09, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "actor________________________________________\n",
      "tensor(8.6813e-09, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "actor________________________________________\n",
      "tensor(9.9495e-09, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "actor________________________________________\n",
      "tensor(9.6583e-09, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "actor________________________________________\n",
      "tensor(8.3545e-09, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "0___________________________________ meta\n",
      "loss2: 2.6041391265607672e-11\n",
      "forward: 8.523404204652252e-12\n",
      "total: 3.4564795470259924e-11\n",
      "diff: 0.9999977350234985\n",
      "tensor(3.2518e-05, device='cuda:0')\n",
      "1___________________________________ meta\n",
      "loss2: 5.755396159656812e-13\n",
      "forward: 4.440892098500626e-16\n",
      "total: 5.759837051755312e-13\n",
      "diff: 3.559108563422342e-11\n",
      "tensor(3.0423e-07, device='cuda:0')\n",
      "2___________________________________ meta\n",
      "loss2: 1.7763568394002505e-13\n",
      "forward: 1.269429006356404e-11\n",
      "total: 1.2871925747504065e-11\n",
      "diff: 5.258016244624741e-12\n",
      "tensor(9.5598e-06, device='cuda:0')\n",
      "actor________________________________________\n",
      "tensor(8.9202e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "actor________________________________________\n",
      "tensor(9.5001e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "actor________________________________________\n",
      "tensor(7.1902e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "actor________________________________________\n",
      "tensor(3.6079e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "actor________________________________________\n",
      "tensor(4.6301e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "actor________________________________________\n",
      "tensor(2.3851e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "actor________________________________________\n",
      "tensor(2.5845e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "actor________________________________________\n",
      "tensor(3.8503e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "actor________________________________________\n",
      "tensor(1.7221e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "actor________________________________________\n",
      "tensor(3.6458e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [7], line 18\u001b[0m\n\u001b[1;32m      3\u001b[0m critic_step(\n\u001b[1;32m      4\u001b[0m     critic\u001b[39m=\u001b[39mcritic,\n\u001b[1;32m      5\u001b[0m     planner\u001b[39m=\u001b[39mplanner,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     15\u001b[0m     expert_trjs\u001b[39m=\u001b[39mexpert_trjs\n\u001b[1;32m     16\u001b[0m )\n\u001b[1;32m     17\u001b[0m \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m10\u001b[39m):\n\u001b[0;32m---> 18\u001b[0m     actor_step(\n\u001b[1;32m     19\u001b[0m         actor\u001b[39m=\u001b[39;49mactor,\n\u001b[1;32m     20\u001b[0m         planner\u001b[39m=\u001b[39;49mplanner,\n\u001b[1;32m     21\u001b[0m         obsvs\u001b[39m=\u001b[39;49mobsvs,\n\u001b[1;32m     22\u001b[0m         acts\u001b[39m=\u001b[39;49macts,\n\u001b[1;32m     23\u001b[0m         expert_trjs\u001b[39m=\u001b[39;49mexpert_trjs,\n\u001b[1;32m     24\u001b[0m         get_actor_inpt\u001b[39m=\u001b[39;49mget_actor_inpt,\n\u001b[1;32m     25\u001b[0m         get_planner_inpt\u001b[39m=\u001b[39;49mget_planner_inpt,\n\u001b[1;32m     26\u001b[0m         verbose\u001b[39m=\u001b[39;49mverbose\n\u001b[1;32m     27\u001b[0m     )\n",
      "Cell \u001b[0;32mIn [5], line 4\u001b[0m, in \u001b[0;36mactor_step\u001b[0;34m(actor, planner, obsvs, acts, expert_trjs, get_planner_inpt, get_actor_inpt, verbose)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mactor_step\u001b[39m(actor:WholeSequenceModel, planner:WholeSequenceModel, obsvs:th\u001b[39m.\u001b[39mTensor, acts:th\u001b[39m.\u001b[39mTensor, expert_trjs:th\u001b[39m.\u001b[39mTensor, get_planner_inpt, get_actor_inpt, verbose):\n\u001b[1;32m      3\u001b[0m     planner_inpt \u001b[39m=\u001b[39m get_planner_inpt(acts\u001b[39m=\u001b[39macts, obsvs\u001b[39m=\u001b[39mobsvs)\n\u001b[0;32m----> 4\u001b[0m     plans \u001b[39m=\u001b[39m planner\u001b[39m.\u001b[39;49mforward(planner_inpt)\n\u001b[1;32m      5\u001b[0m     plans[expert_trjs] \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m      7\u001b[0m     actor_input \u001b[39m=\u001b[39m get_actor_inpt(plans\u001b[39m=\u001b[39mplans, obsvs\u001b[39m=\u001b[39mobsvs)\n",
      "File \u001b[0;32m~/Documents/master_project/Code/active_critic/src/active_critic/model_src/whole_sequence_model.py:33\u001b[0m, in \u001b[0;36mWholeSequenceModel.forward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwsms\u001b[39m.\u001b[39mmodel_setup\u001b[39m.\u001b[39mntoken \u001b[39m=\u001b[39m inputs\u001b[39m.\u001b[39msize(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     31\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel \u001b[39m=\u001b[39m TransformerModel(\n\u001b[1;32m     32\u001b[0m         model_setup\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwsms\u001b[39m.\u001b[39mmodel_setup)\u001b[39m.\u001b[39mto(inputs\u001b[39m.\u001b[39mdevice)\n\u001b[0;32m---> 33\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mforward(inputs)\n\u001b[1;32m     34\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     35\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwsms\u001b[39m.\u001b[39moptimizer_class(\n\u001b[1;32m     36\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mparameters(), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwsms\u001b[39m.\u001b[39mlr, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwsms\u001b[39m.\u001b[39moptimizer_kwargs)\n",
      "File \u001b[0;32m~/Documents/master_project/Code/active_critic/src/active_critic/model_src/transformer.py:62\u001b[0m, in \u001b[0;36mTransformerModel.forward\u001b[0;34m(self, src, mask, return_attention)\u001b[0m\n\u001b[1;32m     60\u001b[0m     output, attention \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransformer_encoder\u001b[39m.\u001b[39mforward(src\u001b[39m=\u001b[39msrc, mask\u001b[39m=\u001b[39mmask, return_attention\u001b[39m=\u001b[39mreturn_attention)\n\u001b[1;32m     61\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 62\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransformer_encoder\u001b[39m.\u001b[39;49mforward(src\u001b[39m=\u001b[39;49msrc, mask\u001b[39m=\u001b[39;49mmask)\n\u001b[1;32m     63\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdecoder(output)\n\u001b[1;32m     64\u001b[0m \u001b[39mif\u001b[39;00m return_attention:\n",
      "File \u001b[0;32m~/Documents/master_project/Code/active_critic/src/active_critic/model_src/base_transformer.py:58\u001b[0m, in \u001b[0;36mDebugTE.forward\u001b[0;34m(self, src, return_attention, mask, src_key_padding_mask)\u001b[0m\n\u001b[1;32m     55\u001b[0m         output, attention \u001b[39m=\u001b[39m mod(output, src_mask\u001b[39m=\u001b[39mmask, src_key_padding_mask\u001b[39m=\u001b[39msrc_key_padding_mask,\n\u001b[1;32m     56\u001b[0m                                 return_attention\u001b[39m=\u001b[39mreturn_attention)\n\u001b[1;32m     57\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m         output \u001b[39m=\u001b[39m mod(output, src_mask\u001b[39m=\u001b[39;49mmask, src_key_padding_mask\u001b[39m=\u001b[39;49msrc_key_padding_mask)\n\u001b[1;32m     60\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     61\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm(output)\n",
      "File \u001b[0;32m~/anaconda3/envs/ac/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Documents/master_project/Code/active_critic/src/active_critic/model_src/base_transformer.py:25\u001b[0m, in \u001b[0;36mDebugTEL.forward\u001b[0;34m(self, src, src_mask, src_key_padding_mask, return_attention)\u001b[0m\n\u001b[1;32m     22\u001b[0m attn \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mself_attn(src, src, src, attn_mask\u001b[39m=\u001b[39msrc_mask,\n\u001b[1;32m     23\u001b[0m                       key_padding_mask\u001b[39m=\u001b[39msrc_key_padding_mask)\n\u001b[1;32m     24\u001b[0m src \u001b[39m=\u001b[39m src \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout1(attn[\u001b[39m0\u001b[39m])\n\u001b[0;32m---> 25\u001b[0m src \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnorm1(src)\n\u001b[1;32m     26\u001b[0m src2 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlinear2(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mactivation(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlinear1(src))))\n\u001b[1;32m     27\u001b[0m src \u001b[39m=\u001b[39m src \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout2(src2)\n",
      "File \u001b[0;32m~/anaconda3/envs/ac/lib/python3.10/site-packages/torch/nn/modules/module.py:1256\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1253\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39m_is_full_backward_hook\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__dict__\u001b[39m:\n\u001b[1;32m   1254\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_full_backward_hook \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1256\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getattr__\u001b[39m(\u001b[39mself\u001b[39m, name: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Union[Tensor, \u001b[39m'\u001b[39m\u001b[39mModule\u001b[39m\u001b[39m'\u001b[39m]:\n\u001b[1;32m   1257\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39m_parameters\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__dict__\u001b[39m:\n\u001b[1;32m   1258\u001b[0m         _parameters \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__dict__\u001b[39m[\u001b[39m'\u001b[39m\u001b[39m_parameters\u001b[39m\u001b[39m'\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(1000):\n",
    "    verbose = i%30==0\n",
    "    critic_step(\n",
    "        critic=critic,\n",
    "        planner=planner,\n",
    "        verbose=verbose,\n",
    "        inf_opt_lr=1e-2,\n",
    "        inf_opt_steps=3,\n",
    "        obsvs=obsvs,\n",
    "        acts=acts,\n",
    "        rewards=rewards,\n",
    "        goal_rewards=goal_rewards,\n",
    "        get_critic_inpt=get_critic_inpt,\n",
    "        get_planner_inpt=get_planner_inpt,\n",
    "        expert_trjs=expert_trjs\n",
    "    )\n",
    "    for j in range(10):\n",
    "        actor_step(\n",
    "            actor=actor,\n",
    "            planner=planner,\n",
    "            obsvs=obsvs,\n",
    "            acts=acts,\n",
    "            expert_trjs=expert_trjs,\n",
    "            get_actor_inpt=get_actor_inpt,\n",
    "            get_planner_inpt=get_planner_inpt,\n",
    "            verbose=verbose\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(3000):\n",
    "    res = actor.optimizer_step(inputs=obsvs, label=acts)\n",
    "    if i%100==0:\n",
    "        print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actor.optimizer.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obsvs = th.zeros([batch_size, seq_len, 3], dtype=th.float32, device=device)\n",
    "obsvs[1] = 1\n",
    "acts = th.rand([batch_size, seq_len, 2], dtype=th.float32, device=device)\n",
    "\n",
    "actor = WholeSequenceModel(wsm_actor_setup)\n",
    "\n",
    "for i in range(2000):\n",
    "    verbose = i%100==0\n",
    "    actor_step(actor=actor, planner=planner, obsvs=obsvs, acts=acts, expert_trjs=expert_trjs, get_planner_inpt=get_planner_inpt, get_actor_inpt=get_actor_inpt, verbose=verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = actor.forward(obsvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actor.optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(actor.parameters())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ac",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c27e8fa6375f4d15af5a5f5541d8bb88746b588c9fe1102cfd8de011d36c10c2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
