{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hendrik/anaconda3/envs/ac/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/hendrik/anaconda3/envs/ac/lib/python3.10/site-packages/gym/spaces/box.py:73: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "import unittest\n",
    "\n",
    "import torch as th\n",
    "import numpy as np\n",
    "\n",
    "from active_critic.model_src.whole_sequence_model import WholeSequenceModel\n",
    "from active_critic.policy.active_critic_policy import *\n",
    "from active_critic.utils.test_utils import (make_acps, make_obs_act_space,\n",
    "                                            make_wsm_setup)\n",
    "from active_critic.utils.gym_utils import (DummyExtractor, make_dummy_vec_env,\n",
    "                                           new_epoch_pap,\n",
    "                                           new_epoch_reach)\n",
    "\n",
    "from active_critic.utils.gym_utils import make_policy_dict, new_epoch_reach, make_dummy_vec_env, sample_expert_transitions, parse_sampled_transitions\n",
    "from active_critic.model_src.state_model import StateModel, StateModelArgs\n",
    "from active_critic.utils.pytorch_utils import build_tf_horizon_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from active_critic.model_src.whole_sequence_model import *\n",
    "\n",
    "\n",
    "def setup_opt_state(device='cuda'):\n",
    "    seq_len = 6\n",
    "    action_dim = 2\n",
    "    obs_dim = 3\n",
    "    batch_size = 2\n",
    "    embed_dim = 4\n",
    "    lr = 1e-3\n",
    "\n",
    "    actor_args = StateModelArgs()\n",
    "    actor_args.arch = [20, action_dim]\n",
    "    actor_args.device = device\n",
    "    actor_args.lr = lr\n",
    "    actor = StateModel(args=actor_args)\n",
    "\n",
    "    critic_args = StateModelArgs()\n",
    "    critic_args.arch = [10, 1]\n",
    "    critic_args.device = device\n",
    "    critic_args.lr = lr\n",
    "    critic = StateModel(args=critic_args)\n",
    "\n",
    "    emitter_args = StateModelArgs()\n",
    "    emitter_args.arch = [20, embed_dim]\n",
    "    emitter_args.device = device\n",
    "    emitter_args.lr = lr\n",
    "    emitter = StateModel(args=emitter_args)\n",
    "\n",
    "    predictor_args = make_wsm_setup(\n",
    "        seq_len=seq_len, d_output=embed_dim, device=device)\n",
    "    predictor_args.model_setup.d_hid = 200\n",
    "    predictor_args.model_setup.d_model = 200\n",
    "    predictor_args.model_setup.nlayers = 1\n",
    "    predictor = WholeSequenceModel(args=predictor_args)\n",
    "\n",
    "\n",
    "    acps = make_acps(\n",
    "        seq_len=seq_len, extractor=DummyExtractor(), new_epoch=new_epoch_pap, device=device)\n",
    "    acps.opt_steps = 2\n",
    "    obs_space, acts_space = make_obs_act_space(\n",
    "        obs_dim=obs_dim, action_dim=action_dim)\n",
    "    ac = ActiveCriticPolicy(observation_space=obs_space, \n",
    "                            action_space=acts_space,\n",
    "                            actor=actor,\n",
    "                            critic=critic,\n",
    "                            predictor=predictor,\n",
    "                            emitter=emitter,\n",
    "                            acps=acps)\n",
    "    return ac, acps, action_dim, obs_dim, batch_size, embed_dim, seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hendrik/anaconda3/envs/ac/lib/python3.10/site-packages/gym/spaces/box.py:73: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float64\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "th.manual_seed(0)\n",
    "device = 'cuda'\n",
    "ac, acps, action_dim, obs_dim, batch_size, embed_dim, seq_len = setup_opt_state(device=device)\n",
    "horizon = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = th.ones([batch_size, 1, embed_dim], device=device)\n",
    "actions = th.ones([batch_size, seq_len, action_dim], device=device, requires_grad=True)\n",
    "goal_embeddings = th.ones_like(embeddings)\n",
    "action_optim = th.optim.Adam([actions], lr=1e-1)\n",
    "opt_paras = action_optim.state_dict()\n",
    "\n",
    "mask = build_tf_horizon_mask(seq_len=seq_len, horizon=horizon, device=device)\n",
    "seq_embeddings = ac.build_sequence(embeddings=embeddings, actions=actions, seq_len=seq_len, mask=mask, detach=True)\n",
    "opt_actions = actions.detach()\n",
    "opt_actions.requires_grad = True\n",
    "next_embedding = ac.predict_step(embeddings=seq_embeddings.detach(), actions=opt_actions, mask=mask)\n",
    "seq_embedding = th.cat((embeddings[:,:1], next_embedding[:,:-1]), dim=1)\n",
    "loss = ((seq_embedding - th.ones_like(seq_embedding))**2).mean()\n",
    "loss.backward()\n",
    "assert (opt_actions.grad != 0).sum() == opt_actions[:,:-1].numel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = th.ones([batch_size, 1, embed_dim], device=device)\n",
    "actions = th.ones([batch_size, seq_len, action_dim], device=device, requires_grad=True)\n",
    "goal_embeddings = th.ones_like(embeddings)\n",
    "action_optim = th.optim.Adam([actions], lr=1e-1)\n",
    "opt_paras = action_optim.state_dict()\n",
    "\n",
    "mask = build_tf_horizon_mask(seq_len=seq_len, horizon=horizon, device=device)\n",
    "seq_embeddings = ac.build_sequence(embeddings=embeddings, actions=actions, seq_len=seq_len, mask=mask, detach=True)\n",
    "opt_actions = actions.detach()\n",
    "opt_actions.requires_grad = True\n",
    "next_embedding = ac.predict_step(embeddings=seq_embeddings.detach(), actions=opt_actions, mask=mask)\n",
    "seq_embedding = th.cat((embeddings[:,:1], next_embedding[:,:-1]), dim=1)\n",
    "loss = ((seq_embedding[:,-1] - th.ones_like(seq_embedding[:,-1] ))**2).mean()\n",
    "loss.backward()\n",
    "assert (opt_actions.grad != 0).sum() == (min(seq_len-1, 1+horizon) * action_dim*batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "horizon = 1\n",
    "embeddings = th.ones([batch_size, 1, embed_dim], device=device)\n",
    "actions = th.ones([batch_size, seq_len, action_dim], device=device, requires_grad=True)\n",
    "goal_embeddings = th.ones_like(embeddings)\n",
    "action_optim = th.optim.Adam([actions], lr=1e-1)\n",
    "opt_paras = action_optim.state_dict()\n",
    "\n",
    "mask = build_tf_horizon_mask(seq_len=seq_len, horizon=horizon, device=device)\n",
    "seq_embeddings = ac.build_sequence(embeddings=embeddings, actions=actions, seq_len=seq_len, mask=mask, detach=True)\n",
    "opt_actions = actions.detach()\n",
    "opt_actions.requires_grad = True\n",
    "next_embedding = ac.predict_step(embeddings=seq_embeddings.detach(), actions=opt_actions, mask=mask)\n",
    "seq_embedding = th.cat((embeddings[:,:1], next_embedding[:,:-1]), dim=1)\n",
    "loss = ((seq_embedding[:,-1] - th.ones_like(seq_embedding[:,-1] ))**2).mean()\n",
    "loss.backward()\n",
    "assert (opt_actions.grad != 0).sum() == (min(seq_len-1, 1+horizon) * action_dim*batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "horizon = seq_len\n",
    "embeddings = th.ones([batch_size, 1, embed_dim], device=device)\n",
    "actions = th.ones([batch_size, seq_len, action_dim], device=device, requires_grad=True)\n",
    "goal_embeddings = th.ones_like(embeddings)\n",
    "action_optim = th.optim.Adam([actions], lr=1e-1)\n",
    "opt_paras = action_optim.state_dict()\n",
    "\n",
    "mask = build_tf_horizon_mask(seq_len=seq_len, horizon=horizon, device=device)\n",
    "seq_embeddings = ac.build_sequence(embeddings=embeddings, actions=actions, seq_len=seq_len, mask=mask, detach=True)\n",
    "opt_actions = actions.detach()\n",
    "opt_actions.requires_grad = True\n",
    "next_embedding = ac.predict_step(embeddings=seq_embeddings.detach(), actions=opt_actions, mask=mask)\n",
    "seq_embedding = th.cat((embeddings[:,:1], next_embedding[:,:-1]), dim=1)\n",
    "loss = ((seq_embedding[:,-1] - th.ones_like(seq_embedding[:,-1] ))**2).mean()\n",
    "loss.backward()\n",
    "assert (opt_actions.grad != 0).sum() == (min(seq_len-1, 1+horizon) * action_dim*batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "horizon = seq_len\n",
    "embeddings = th.ones([batch_size, 1, embed_dim], device=device)\n",
    "actions = th.ones([batch_size, seq_len, action_dim], device=device, requires_grad=True)\n",
    "goal_embeddings = th.ones_like(embeddings)\n",
    "action_optim = th.optim.Adam([actions], lr=1e-1)\n",
    "opt_paras = action_optim.state_dict()\n",
    "\n",
    "mask = build_tf_horizon_mask(seq_len=seq_len, horizon=horizon, device=device)\n",
    "seq_embeddings = ac.build_sequence(embeddings=embeddings, actions=actions, seq_len=seq_len, mask=mask, detach=True)\n",
    "opt_actions = actions.detach()\n",
    "opt_actions.requires_grad = True\n",
    "next_embedding = ac.predict_step(embeddings=seq_embeddings.detach(), actions=opt_actions, mask=mask)\n",
    "seq_embedding = th.cat((embeddings[:,:1], next_embedding[:,:-1]), dim=1)\n",
    "loss = ((seq_embedding[:,-1] - th.ones_like(seq_embedding[:,-1] ))**2).mean()\n",
    "loss.backward()\n",
    "assert (opt_actions.grad != 0).sum() == (min(seq_len-1, 1+horizon) * action_dim*batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "horizon = seq_len\n",
    "embeddings = th.ones([batch_size, 1, embed_dim], device=device)\n",
    "actions = th.ones([batch_size, seq_len, action_dim], device=device, requires_grad=True)\n",
    "goal_embeddings = th.ones_like(embeddings)\n",
    "action_optim = th.optim.Adam([actions], lr=1e-1)\n",
    "opt_paras = action_optim.state_dict()\n",
    "\n",
    "mask = build_tf_horizon_mask(seq_len=seq_len, horizon=horizon, device=device)\n",
    "seq_embeddings = ac.build_sequence(embeddings=embeddings, actions=actions, seq_len=seq_len, mask=mask, detach=True)\n",
    "opt_actions = actions.detach()\n",
    "opt_actions.requires_grad = True\n",
    "next_embedding = ac.predict_step(embeddings=seq_embeddings.detach(), actions=opt_actions, mask=mask)\n",
    "seq_embedding = th.cat((embeddings[:,:1], next_embedding[:,:-1]), dim=1)\n",
    "loss = ((seq_embedding[:,-1] - th.ones_like(seq_embedding[:,-1] ))**2).mean()\n",
    "loss.backward()\n",
    "assert (opt_actions.grad != 0).sum() == (min(seq_len-1, 1+horizon) * action_dim*batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "horizon = 0\n",
    "embeddings = th.ones([batch_size, 1, embed_dim], device=device, requires_grad=True)\n",
    "actions = th.ones([batch_size, seq_len, action_dim], device=device, requires_grad=True)\n",
    "action_optim = th.optim.Adam([actions], lr=1e-1)\n",
    "opt_paras = action_optim.state_dict()\n",
    "\n",
    "mask = build_tf_horizon_mask(seq_len=seq_len, horizon=horizon, device=device)\n",
    "seq_embeddings = ac.build_sequence(embeddings=embeddings, actions=actions, seq_len=seq_len, mask=mask, detach=False)\n",
    "loss = ((seq_embeddings[:,-1] - th.ones_like(seq_embeddings[:,-1] ))**2).mean()\n",
    "loss.backward()\n",
    "assert (actions.grad!=0).sum() == actions.numel() - action_dim*batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "horizon = 0\n",
    "embeddings = th.ones([batch_size, 1, embed_dim], device=device, requires_grad=True)\n",
    "actions = th.ones([batch_size, seq_len, action_dim], device=device, requires_grad=True)\n",
    "action_optim = th.optim.Adam([actions], lr=1e-1)\n",
    "opt_paras = action_optim.state_dict()\n",
    "\n",
    "mask = build_tf_horizon_mask(seq_len=seq_len, horizon=horizon, device=device)\n",
    "seq_embeddings = ac.build_sequence(embeddings=embeddings, actions=actions, seq_len=seq_len, mask=mask, detach=True)\n",
    "opt_actions = actions.detach()\n",
    "opt_actions.requires_grad = True\n",
    "next_embedding = ac.predict_step(embeddings=seq_embeddings.detach(), actions=opt_actions, mask=mask)\n",
    "seq_embedding = th.cat((embeddings[:,:1], next_embedding[:,:-1]), dim=1)\n",
    "loss = ((seq_embedding[:,-1] - th.ones_like(seq_embedding[:,-1] ))**2).mean()\n",
    "loss.backward()\n",
    "assert (opt_actions.grad != 0).sum() == batch_size*action_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "ac = ac.double()\n",
    "seq_len = 100\n",
    "horizon = 0\n",
    "embeddings = th.ones([batch_size, 1, embed_dim], device=device, requires_grad=True, dtype=th.double)\n",
    "actions = th.ones([batch_size, seq_len, action_dim], device=device, requires_grad=True, dtype=th.double)\n",
    "org_actions = th.ones([batch_size, seq_len, action_dim], device=device, requires_grad=True, dtype=th.double)\n",
    "action_optim = th.optim.Adam([actions], lr=1e-1)\n",
    "opt_paras = action_optim.state_dict()\n",
    "\n",
    "mask = build_tf_horizon_mask(seq_len=seq_len, horizon=0, device=device).double()\n",
    "seq_embeddings = ac.build_sequence(embeddings=embeddings, actions=actions, seq_len=seq_len, mask=mask, detach=True)\n",
    "org_embeddings = seq_embeddings.clone()\n",
    "\n",
    "goal_embeddings = th.ones_like(seq_embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_sequence(actions:th.Tensor, seq_embeddings:th.Tensor, mask:th.Tensor, goal_label:th.Tensor, steps:int, current_step:int):\n",
    "    actions = actions.detach().clone()\n",
    "    org_actions = actions.detach().clone()\n",
    "\n",
    "    actions.requires_grad = True\n",
    "    seq_embeddings = seq_embeddings.detach().clone()\n",
    "    org_embeddings = seq_embeddings.detach().clone()\n",
    "    \n",
    "    optimizer = th.optim.Adam([actions], lr=1e-2)\n",
    "    opt_paras = optimizer.state_dict()\n",
    "    for i in range(steps):\n",
    "        actions = actions.detach().clone()\n",
    "        actions.requires_grad = True\n",
    "        optimizer = th.optim.Adam([actions], lr=1e-2)\n",
    "        seq_embeddings = ac.build_sequence(embeddings=seq_embeddings.detach()[:,:current_step], actions=actions, seq_len=actions.shape[1], mask=mask, detach=False)\n",
    "        critic_input = ac.make_input(embeddings=seq_embeddings, actions=actions)\n",
    "\n",
    "        scores = ac.critic.forward(critic_input)\n",
    "        optimizer.load_state_dict(opt_paras)\n",
    "\n",
    "        loss_reward = calcMSE(scores[:, current_step:], goal_label[:, current_step:])\n",
    "        loss = loss_reward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        opt_paras = optimizer.state_dict()\n",
    "        with th.no_grad():\n",
    "            actions[:,:current_step] = org_actions[:,:current_step]\n",
    "\n",
    "    return loss_reward, actions, seq_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "goal_label = th.ones([batch_size, seq_len], device=device, dtype=th.double)\n",
    "loss_reward, new_actions, seq_embeddings = optimize_sequence(actions, seq_embeddings, mask, steps=1000, current_step=4, goal_label=goal_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8428, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#step 1:\n",
    "print(loss_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8182, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#step 10:\n",
    "print(loss_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(7.3251e-06, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#step 1000:\n",
    "print(loss_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2348, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([[[ 0.1066,  0.4179],\n",
      "         [ 1.5041,  1.8790],\n",
      "         [ 0.0492,  0.3346],\n",
      "         [ 1.3072,  1.8222],\n",
      "         [ 0.0747,  0.1828],\n",
      "         [ 1.0924,  1.7648],\n",
      "         [-0.0277,  0.2482],\n",
      "         [ 1.9838,  1.4988]],\n",
      "\n",
      "        [[ 0.1066,  0.4179],\n",
      "         [ 1.5041,  1.8790],\n",
      "         [ 0.0492,  0.3346],\n",
      "         [ 1.3072,  1.8222],\n",
      "         [ 0.0747,  0.1828],\n",
      "         [ 1.0924,  1.7648],\n",
      "         [-0.0277,  0.2482],\n",
      "         [ 1.9838,  1.4988]]], device='cuda:0', dtype=torch.float64,\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "#step 100:\n",
    "print(loss_reward)\n",
    "print(actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.5065e-05, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<MeanBackward0>)\n",
      "tensor([[[-1.0833,  0.3981],\n",
      "         [ 0.6716,  2.8688],\n",
      "         [-0.9287,  0.0447],\n",
      "         [ 0.4664,  2.8516],\n",
      "         [-0.9128, -0.9740],\n",
      "         [ 0.8113,  2.8568],\n",
      "         [-0.9601,  0.0815],\n",
      "         [ 4.1606,  3.5901]],\n",
      "\n",
      "        [[-1.0833,  0.3981],\n",
      "         [ 0.6716,  2.8688],\n",
      "         [-0.9287,  0.0447],\n",
      "         [ 0.4664,  2.8516],\n",
      "         [-0.9128, -0.9740],\n",
      "         [ 0.8113,  2.8568],\n",
      "         [-0.9601,  0.0815],\n",
      "         [ 4.1606,  3.5901]]], device='cuda:0', dtype=torch.float64,\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "#step 500:\n",
    "print(loss_reward)\n",
    "print(actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0303, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([[[ 2.3527, -4.0498],\n",
      "         [ 4.5213,  6.0304],\n",
      "         [ 3.1638, -3.9057],\n",
      "         [ 4.0586,  6.6364],\n",
      "         [ 2.7037, -4.8174],\n",
      "         [ 4.5412,  5.6293],\n",
      "         [ 3.0826, -3.5615],\n",
      "         [ 5.6890,  4.5788]],\n",
      "\n",
      "        [[ 2.3527, -4.0498],\n",
      "         [ 4.5213,  6.0304],\n",
      "         [ 3.1638, -3.9057],\n",
      "         [ 4.0586,  6.6364],\n",
      "         [ 2.7037, -4.8174],\n",
      "         [ 4.5412,  5.6293],\n",
      "         [ 3.0826, -3.5615],\n",
      "         [ 5.6890,  4.5788]]], device='cuda:0', dtype=torch.float64,\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "#step 500 all:\n",
    "print(loss_reward)\n",
    "print(actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8213, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([[[1., 1.],\n",
      "         [1., 1.],\n",
      "         [1., 1.],\n",
      "         [1., 1.],\n",
      "         [1., 1.],\n",
      "         [1., 1.],\n",
      "         [1., 1.],\n",
      "         [1., 1.]],\n",
      "\n",
      "        [[1., 1.],\n",
      "         [1., 1.],\n",
      "         [1., 1.],\n",
      "         [1., 1.],\n",
      "         [1., 1.],\n",
      "         [1., 1.],\n",
      "         [1., 1.],\n",
      "         [1., 1.]]], device='cuda:0', dtype=torch.float64, requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "#step 1 all:\n",
    "print(loss_reward)\n",
    "print(actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('ac')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c27e8fa6375f4d15af5a5f5541d8bb88746b588c9fe1102cfd8de011d36c10c2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
