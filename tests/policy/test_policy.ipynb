{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as th\n",
    "import numpy as np\n",
    "\n",
    "from active_critic.model_src.whole_sequence_model import WholeSequenceModel\n",
    "from active_critic.policy.active_critic_policy import *\n",
    "from active_critic.utils.test_utils import (make_obs_act_space,\n",
    "                                            make_wsm_setup)\n",
    "from active_critic.utils.gym_utils import (DummyExtractor, make_dummy_vec_env,\n",
    "                                           new_epoch_pap,\n",
    "                                           new_epoch_reach)\n",
    "\n",
    "from active_critic.utils.gym_utils import make_policy_dict, new_epoch_reach, make_dummy_vec_env, sample_expert_transitions, parse_sampled_transitions\n",
    "from active_critic.model_src.state_model import StateModel, StateModelArgs\n",
    "from active_critic.utils.pytorch_utils import build_tf_horizon_mask\n",
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from active_critic.model_src.whole_sequence_model import *\n",
    "'''\n",
    "self.extractor: BaseFeaturesExtractor = None\n",
    "        self.new_epoch = None\n",
    "        self.optimisation_threshold: float = None\n",
    "        self.inference_opt_lr: float = None\n",
    "        self.opt_steps: int = None\n",
    "        self.optimizer_class:th.optim.Optimizer = None\n",
    "        self.epoch_len: int = None\n",
    "        self.device: str = None\n",
    "        self.optimize: bool = None\n",
    "        self.batch_size: int = None\n",
    "        self.pred_mask:th.Tensor = None,\n",
    "        self.opt_mask:th.Tensor=None,\n",
    "        self.opt_goal:th.Tensor=None,\n",
    "        self.clip:bool = True\n",
    "'''\n",
    "\n",
    "\n",
    "def make_acps(seq_len, new_epoch, batch_size = 32, device='cpu', horizon = 0):\n",
    "    acps = ActiveCriticPolicySetup()\n",
    "    acps.device=device\n",
    "    acps.epoch_len=seq_len\n",
    "    acps.extractor=DummyExtractor()\n",
    "    acps.new_epoch=new_epoch\n",
    "    acps.opt_steps=100\n",
    "    acps.inference_opt_lr = 1e-1\n",
    "    acps.optimizer_class = th.optim.Adam\n",
    "    acps.optimize = True\n",
    "    acps.batch_size = batch_size\n",
    "    acps.pred_mask = build_tf_horizon_mask(seq_len=seq_len, horizon=horizon, device=device)\n",
    "    acps.opt_mask = th.zeros([seq_len, 1], device=device, dtype=bool)\n",
    "    acps.opt_mask[-1] = 1\n",
    "    acps.clip = False\n",
    "    acps.opt_goal = True\n",
    "    return acps\n",
    "\n",
    "class DummyHistory:\n",
    "    def __init__(self) -> None:\n",
    "        self.reset()\n",
    "\n",
    "\n",
    "    def reset(self):\n",
    "        self.scores = []\n",
    "        self.goal_scores = []\n",
    "        self.gen_trj = []\n",
    "        self.opt_trj = []\n",
    "        self.pred_emb = []\n",
    "        self.act_emb = []\n",
    "\n",
    "\n",
    "    def new_epoch(self, history:list([th.Tensor]), size:list([int, int, int, int]), device:str): #batch size, opt step, seq len, score\n",
    "        pass\n",
    "\n",
    "\n",
    "    def add_value(self, history:list([th.Tensor]), value:th.Tensor, opt_step:int=0, step:int=0):\n",
    "        pass\n",
    "\n",
    "def setup_opt_ws(device='cuda'):\n",
    "    seq_len = 6\n",
    "    action_dim = 2\n",
    "    obs_dim = 3\n",
    "    batch_size = 2\n",
    "    embed_dim = 4\n",
    "    lr = 1e-3\n",
    "\n",
    "    actor_args = StateModelArgs()\n",
    "    actor_args.arch = [20, action_dim]\n",
    "    actor_args.device = device\n",
    "    actor_args.lr = lr\n",
    "    actor = StateModel(args=actor_args)\n",
    "\n",
    "    critic_args = StateModelArgs()\n",
    "    critic_args.arch = [10, 1]\n",
    "    critic_args.device = device\n",
    "    critic_args.lr = lr\n",
    "    critic = StateModel(args=critic_args)\n",
    "\n",
    "    inv_critic_args = StateModelArgs()\n",
    "    inv_critic_args.arch = [10, embed_dim+action_dim]\n",
    "    inv_critic_args.device = device\n",
    "    inv_critic_args.lr = lr\n",
    "    inv_critic = StateModel(args=inv_critic_args)\n",
    "\n",
    "    emitter_args = StateModelArgs()\n",
    "    emitter_args.arch = [20, embed_dim]\n",
    "    emitter_args.device = device\n",
    "    emitter_args.lr = lr\n",
    "    emitter = StateModel(args=emitter_args)\n",
    "\n",
    "    predictor_args = make_wsm_setup(\n",
    "        seq_len=seq_len, d_output=embed_dim, device=device)\n",
    "    predictor_args.model_setup.d_hid = 200\n",
    "    predictor_args.model_setup.d_model = 200\n",
    "    predictor_args.model_setup.nlayers = 1\n",
    "    predictor = WholeSequenceModel(args=predictor_args)\n",
    "\n",
    "\n",
    "    acps = make_acps(\n",
    "        seq_len=seq_len, new_epoch=new_epoch_pap, device=device, batch_size=batch_size)\n",
    "    acps.opt_steps = 2\n",
    "    obs_space, acts_space = make_obs_act_space(\n",
    "        obs_dim=obs_dim, action_dim=action_dim)\n",
    "    ac = ActiveCriticPolicy(observation_space=obs_space, \n",
    "                            action_space=acts_space,\n",
    "                            actor=actor,\n",
    "                            critic=critic,\n",
    "                            predictor=predictor,\n",
    "                            emitter=emitter,\n",
    "                            inverse_critic=inv_critic,\n",
    "                            acps=acps)\n",
    "    return ac, acps, action_dim, obs_dim, batch_size, embed_dim, seq_len\n",
    "\n",
    "def setup_opt_state(device='cpu'):\n",
    "    seq_len = 6\n",
    "    action_dim = 2\n",
    "    obs_dim = 3\n",
    "    batch_size = 2\n",
    "    embed_dim = 4\n",
    "    lr = 1e-3\n",
    "\n",
    "    actor_args = StateModelArgs()\n",
    "    actor_args.arch = [20, action_dim]\n",
    "    actor_args.device = device\n",
    "    actor_args.lr = lr\n",
    "    actor = StateModel(args=actor_args)\n",
    "\n",
    "    critic_args = StateModelArgs()\n",
    "    critic_args.arch = [10, 1]\n",
    "    critic_args.device = device\n",
    "    critic_args.lr = lr\n",
    "    critic = StateModel(args=critic_args)\n",
    "\n",
    "    inv_critic_args = StateModelArgs()\n",
    "    inv_critic_args.arch = [10, embed_dim+action_dim]\n",
    "    inv_critic_args.device = device\n",
    "    inv_critic_args.lr = lr\n",
    "    inv_critic = StateModel(args=inv_critic_args)\n",
    "\n",
    "    emitter_args = StateModelArgs()\n",
    "    emitter_args.arch = [20, embed_dim]\n",
    "    emitter_args.device = device\n",
    "    emitter_args.lr = lr\n",
    "    emitter = StateModel(args=emitter_args)\n",
    "\n",
    "    predictor_args = StateModelArgs()\n",
    "    predictor_args.arch = [20, embed_dim]\n",
    "    predictor_args.device = device\n",
    "    predictor_args.lr = lr\n",
    "    predictor = StateModel(args=predictor_args)\n",
    "\n",
    "\n",
    "    acps = make_acps(\n",
    "        seq_len=seq_len, new_epoch=new_epoch_pap, device=device, batch_size=batch_size)\n",
    "    acps.opt_steps = 2\n",
    "    obs_space, acts_space = make_obs_act_space(\n",
    "        obs_dim=obs_dim, action_dim=action_dim)\n",
    "    ac = ActiveCriticPolicy(observation_space=obs_space, \n",
    "                            action_space=acts_space,\n",
    "                            actor=actor,\n",
    "                            critic=critic,\n",
    "                            predictor=predictor,\n",
    "                            emitter=emitter,\n",
    "                            inverse_critic=inv_critic,\n",
    "                            acps=acps)\n",
    "    return ac, acps, action_dim, obs_dim, batch_size, embed_dim, seq_len\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "th.manual_seed(0)\n",
    "device = 'cpu'\n",
    "ac, acps, action_dim, obs_dim, batch_size, embed_dim, seq_len = setup_opt_ws(device=device)\n",
    "acps.opt_steps = 10\n",
    "acps.inference_opt_lr = 1\n",
    "observation = th.ones([batch_size, 1, obs_dim])\n",
    "action = ac.predict(observation=observation)\n",
    "assert th.all((ac.history.scores[0][:,-1,-1] - ac.history.scores[0][:,0,-1]) >= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ac.args_obj.opt_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = ac.emitter.forward(inpt=observation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings, actions = ac.build_sequence(\n",
    "    embeddings=embedding, \n",
    "    actions=None, \n",
    "    seq_len=4, \n",
    "    goal_state=None, \n",
    "    goal_emb_acts=None, \n",
    "    tf_mask=ac.args_obj.pred_mask,\n",
    "    actor=ac.actor,\n",
    "    predictor=ac.predicor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = actions.detach()\n",
    "actions.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sembeddings, sactions = ac.build_sequence(\n",
    "    embeddings=embedding, \n",
    "    actions=actions, \n",
    "    seq_len=4, \n",
    "    goal_state=None, \n",
    "    goal_emb_acts=None, \n",
    "    tf_mask=ac.args_obj.pred_mask,\n",
    "    actor=ac.actor,\n",
    "    predictor=ac.predicor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "((sembeddings[:,-1] - th.ones_like(sembeddings[:,-1]))**2).mean().backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000],\n",
       "         [-0.2477,  0.0292],\n",
       "         [ 0.0000,  0.0000]],\n",
       "\n",
       "        [[ 0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000],\n",
       "         [-0.2477,  0.0292],\n",
       "         [ 0.0000,  0.0000]]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings, actions = ac.build_sequence(embeddings=embedding, actions=actions, seq_len=4, goal_state=ac.last_goal, goal_emb_acts=goal_emb_acts, mask=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((embeddings[:,-1] - th.ones_like(embeddings[:,-1]))**2).mean().backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = th.optim.Adam([actions], lr=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ac.history.gen_trj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test Projection\n",
    "th.manual_seed(0)\n",
    "device = 'cpu'\n",
    "ac, acps, action_dim, obs_dim, batch_size, embed_dim, seq_len = setup_opt_state(device=device)\n",
    "acps.opt_steps = 2\n",
    "goal_dim = 1\n",
    "change_dim = 2\n",
    "acps.inference_opt_lr = 1\n",
    "observations = th.ones([batch_size, 3, obs_dim], dtype=float)\n",
    "observations[:,:,:change_dim] = 0\n",
    "org_obs = observations.detach().clone()\n",
    "observations.requires_grad = True\n",
    "observations.mean().backward()\n",
    "goal = th.ones([batch_size, goal_dim])\n",
    "proj_obs = ac.project_embeddings(embeddings=observations, goal_state=goal)\n",
    "\n",
    "assert th.all(proj_obs[:,:,:goal_dim] == goal[:, None])\n",
    "assert th.all(proj_obs[:,:,goal_dim:] == org_obs[:,:,goal_dim:])\n",
    "assert th.all(proj_obs.grad != 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test INv Critic Input\n",
    "th.manual_seed(0)\n",
    "device = 'cpu'\n",
    "ac, acps, action_dim, obs_dim, batch_size, embed_dim, seq_len = setup_opt_state(device=device)\n",
    "acps.opt_steps = 2\n",
    "goal_dim = 1\n",
    "\n",
    "embeddings = th.ones([batch_size, seq_len, embed_dim], dtype=th.float32)\n",
    "actions = th.ones([batch_size, seq_len, action_dim], dtype=th.float32)\n",
    "goal_state = th.zeros([batch_size, goal_dim], dtype=th.float32)\n",
    "goal_label = th.ones([batch_size, seq_len, 1])\n",
    "opt_steps = 100\n",
    "lr = 1\n",
    "\n",
    "inv_inpt = ac.get_inverse_critic_input(goal_state=goal_state, goal_scores=goal_label[:,-1])\n",
    "assert th.all(inv_inpt[:,:goal_dim] == goal_state)\n",
    "assert th.all(inv_inpt[:,goal_dim:] == goal_label[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goal_embeddings = ac.inverse_critic.forward(inv_inpt)\n",
    "goal_embeddings = ac.project_embeddings(embeddings=goal_embeddings, goal_state=goal_state)\n",
    "expected_goal_shape = [batch_size, embed_dim]\n",
    "assert list(goal_embeddings.shape) == expected_goal_shape\n",
    "assert th.all(goal_embeddings[:, :goal_dim] == goal_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1\n",
    "opt_steps = 100\n",
    "ac.history = DummyHistory()\n",
    "opt_goal_embeddings = ac.optimize_goal_embedding(\n",
    "    goal_embeddings=goal_embeddings,\n",
    "    goal_state=goal_state,\n",
    "    goal_label=goal_label,\n",
    "    lr=lr,\n",
    "    opt_steps=opt_steps\n",
    ")\n",
    "assert list(goal_embeddings.shape) == expected_goal_shape\n",
    "assert th.all(goal_embeddings[:, :goal_dim] == goal_state)\n",
    "old_critic_scores = ac.critic.forward(goal_embeddings)\n",
    "new_critic_scores = ac.critic.forward(opt_goal_embeddings)\n",
    "assert th.all(new_critic_scores > old_critic_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ac_opt_goal_embeddings = ac.get_goal_embeddings(\n",
    "    goal_state=goal_state,\n",
    "    goal_label=goal_label,\n",
    "    lr=lr,\n",
    "    opt_steps=opt_steps\n",
    ")\n",
    "\n",
    "assert th.equal(ac_opt_goal_embeddings, opt_goal_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = th.tensor([float('inf')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "th.inf in a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "th.manual_seed(0)\n",
    "device = 'cpu'\n",
    "ac, acps, action_dim, obs_dim, batch_size, embed_dim, seq_len = setup_opt_state(device=device)\n",
    "acps.clip = True\n",
    "acps.opt_steps = 8\n",
    "acps.inference_opt_lr = 1\n",
    "observation = th.ones([batch_size, 1, obs_dim])\n",
    "action = ac.predict(observation=observation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "th.manual_seed(0)\n",
    "device = 'cpu'\n",
    "ac, acps, action_dim, obs_dim, batch_size, embed_dim, seq_len = setup_opt_state(device=device)\n",
    "acps.opt_steps = 100\n",
    "acps.inference_opt_lr = 1\n",
    "observation = th.ones([batch_size, 1, obs_dim])\n",
    "action = ac.predict(observation=observation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert th.all((ac.history.scores[0][:,1:,-1] - ac.history.scores[0][:,:-1,-1]) >= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ac.history.scores[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_actions = action.clone().unsqueeze(1)\n",
    "all_embeddings = ac.current_embeddings.clone()\n",
    "expected_action_shape = [batch_size, 1, action_dim]\n",
    "expected_embedding_shape = [batch_size, 1, embed_dim]\n",
    "assert list(all_actions.shape) == expected_action_shape\n",
    "assert list(all_embeddings.shape) == expected_embedding_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(seq_len-1):\n",
    "    observation = th.ones([batch_size, 1, obs_dim])\n",
    "    action = ac.predict(observation=observation)\n",
    "    print(ac.current_actions)\n",
    "    print(all_actions)\n",
    "    assert th.equal(ac.current_actions[:,:-1], all_actions)\n",
    "    assert th.equal(ac.current_embeddings[:,:-1], all_embeddings)\n",
    "    all_actions = th.cat((all_actions, action.clone().unsqueeze(1)), dim=1)\n",
    "    all_embeddings = ac.current_embeddings.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ac.current_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observation = 2*th.ones([batch_size, 1, obs_dim])\n",
    "action = ac.predict(observation=observation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_actions = action.clone().unsqueeze(1)\n",
    "all_embeddings = ac.current_embeddings.clone()\n",
    "expected_action_shape = [batch_size, 1, action_dim]\n",
    "expected_embedding_shape = [batch_size, 1, embed_dim]\n",
    "assert list(all_actions.shape) == expected_action_shape\n",
    "assert list(all_embeddings.shape) == expected_embedding_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "th.manual_seed(0)\n",
    "device = 'cpu'\n",
    "ac, acps, action_dim, obs_dim, batch_size, embed_dim, seq_len = setup_opt_state(device=device)\n",
    "horizon = 0\n",
    "embeddings = th.ones([batch_size, 1, embed_dim], device=device, requires_grad=True)\n",
    "actions = th.ones([batch_size, seq_len, action_dim], device=device, requires_grad=True)\n",
    "\n",
    "mask = build_tf_horizon_mask(seq_len=seq_len, horizon=horizon, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "th.manual_seed(0)\n",
    "device = 'cpu'\n",
    "ac, acps, action_dim, obs_dim, batch_size, embed_dim, seq_len = setup_opt_state(device=device)\n",
    "horizon = 0\n",
    "embeddings = th.ones([batch_size, 1, embed_dim], device=device, requires_grad=True)\n",
    "mask = build_tf_horizon_mask(seq_len=seq_len, horizon=horizon, device=device)\n",
    "seq_embeddings, actions = ac.build_sequence(embeddings=embeddings, actions=None, seq_len=seq_len, mask=mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "th.manual_seed(0)\n",
    "device = 'cpu'\n",
    "ac, acps, action_dim, obs_dim, batch_size, embed_dim, seq_len = setup_opt_state(device=device)\n",
    "horizon = 0\n",
    "embeddings = th.ones([batch_size, 1, embed_dim], device=device, requires_grad=True)\n",
    "mask = build_tf_horizon_mask(seq_len=seq_len, horizon=horizon, device=device)\n",
    "steps = 100\n",
    "current_step = 2\n",
    "\n",
    "mask = build_tf_horizon_mask(seq_len=seq_len, horizon=horizon, device=device)\n",
    "goal_label = th.ones([batch_size, seq_len], device=device, dtype=th.double)\n",
    "opt_mask = th.zeros_like(goal_label, dtype=th.bool)\n",
    "opt_mask[:,-current_step:] = 1\n",
    "loss_reward, actions, seq_embeddings, scores = ac.optimize_sequence(actions=None, seq_embeddings=embeddings, pred_mask=mask, opt_mask=opt_mask, steps=steps, current_step=current_step, goal_label=goal_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "th.manual_seed(0)\n",
    "device = 'cpu'\n",
    "ac, acps, action_dim, obs_dim, batch_size, embed_dim, seq_len = setup_opt_state(device=device)\n",
    "horizon = 0\n",
    "embeddings = th.ones([batch_size, 1, embed_dim], device=device, requires_grad=True)\n",
    "actions = th.ones([batch_size, seq_len, action_dim], device=device, requires_grad=True)\n",
    "\n",
    "mask = build_tf_horizon_mask(seq_len=seq_len, horizon=horizon, device=device)\n",
    "seq_embeddings, actions = ac.build_sequence(embeddings=embeddings, actions=actions, seq_len=seq_len, mask=mask)\n",
    "loss = ((seq_embeddings[:,-1] - th.ones_like(seq_embeddings[:,-1] ))**2).mean()\n",
    "loss.backward()\n",
    "assert (actions.grad!=0).sum() == actions.numel() - action_dim*batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "horizon = 0\n",
    "embeddings = th.ones([batch_size, 1, embed_dim], device=device, requires_grad=True)\n",
    "actions = th.ones([batch_size, seq_len, action_dim], device=device, requires_grad=True)\n",
    "action_optim = th.optim.Adam([actions], lr=1e-1)\n",
    "opt_paras = action_optim.state_dict()\n",
    "\n",
    "mask = build_tf_horizon_mask(seq_len=seq_len, horizon=horizon, device=device)\n",
    "seq_embeddings, na = ac.build_sequence(embeddings=embeddings, actions=actions, seq_len=seq_len, mask=mask)\n",
    "opt_actions = actions.detach()\n",
    "opt_actions.requires_grad = True\n",
    "next_embedding = ac.predict_step(embeddings=seq_embeddings.detach(), actions=opt_actions, mask=mask)\n",
    "seq_embedding = th.cat((embeddings[:,:1], next_embedding[:,:-1]), dim=1)\n",
    "loss = ((seq_embedding[:,-1] - th.ones_like(seq_embedding[:,-1] ))**2).mean()\n",
    "loss.backward()\n",
    "assert (opt_actions.grad != 0).sum() == batch_size*action_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "th.manual_seed(0)\n",
    "device = 'cpu'\n",
    "ac, acps, action_dim, obs_dim, batch_size, embed_dim, seq_len = setup_opt_state(device=device)\n",
    "horizon = 0\n",
    "embeddings = th.ones([batch_size, 1, embed_dim], device=device, requires_grad=True)\n",
    "mask = build_tf_horizon_mask(seq_len=seq_len, horizon=horizon, device=device)\n",
    "seq_embeddings, na = ac.build_sequence(embeddings=embeddings, actions=actions, seq_len=seq_len, mask=mask)\n",
    "actions = th.ones([batch_size, seq_len, action_dim], device=device, requires_grad=True)\n",
    "\n",
    "steps = 1\n",
    "current_step = 4\n",
    "\n",
    "mask = build_tf_horizon_mask(seq_len=seq_len, horizon=horizon, device=device)\n",
    "goal_label = th.ones([batch_size, seq_len], device=device, dtype=th.double)\n",
    "opt_mask = th.zeros_like(goal_label, dtype=th.bool)\n",
    "opt_mask[:,-current_step:] = 1\n",
    "loss_reward, actions, seq_embeddings, scores = ac.optimize_sequence(actions, seq_embeddings, pred_mask=mask, opt_mask=opt_mask, steps=steps, current_step=current_step, goal_label=goal_label)\n",
    "\n",
    "assert loss_reward > 1e-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "th.manual_seed(0)\n",
    "device = 'cpu'\n",
    "ac, acps, action_dim, obs_dim, batch_size, embed_dim, seq_len = setup_opt_state(device=device)\n",
    "horizon = 0\n",
    "embeddings = th.ones([batch_size, 1, embed_dim], device=device, requires_grad=True)\n",
    "mask = build_tf_horizon_mask(seq_len=seq_len, horizon=horizon, device=device)\n",
    "seq_embeddings, na = ac.build_sequence(embeddings=embeddings, actions=actions, seq_len=seq_len, mask=mask)\n",
    "actions = th.ones([batch_size, seq_len, action_dim], device=device, requires_grad=True)\n",
    "org_actions = actions.detach().clone()\n",
    "steps = 100\n",
    "current_step = 2\n",
    "\n",
    "mask = build_tf_horizon_mask(seq_len=seq_len, horizon=horizon, device=device)\n",
    "goal_label = th.ones([batch_size, seq_len], device=device, dtype=th.double)\n",
    "opt_mask = th.zeros_like(goal_label, dtype=th.bool)\n",
    "opt_mask[:,-current_step:] = 1\n",
    "loss_reward, actions, seq_embeddings, scores = ac.optimize_sequence(actions, seq_embeddings, pred_mask=mask, opt_mask=opt_mask, steps=steps, current_step=current_step, goal_label=goal_label)\n",
    "\n",
    "assert loss_reward < 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert th.equal(actions[:, :current_step], org_actions[:,:current_step])\n",
    "assert not th.equal(actions[:,current_step:], org_actions[:,current_step:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "th.manual_seed(0)\n",
    "device = 'cpu'\n",
    "ac, acps, action_dim, obs_dim, batch_size, embed_dim, seq_len = setup_opt_state(device=device)\n",
    "seq_len = 100\n",
    "horizon = 0\n",
    "steps = 100\n",
    "current_step = 0\n",
    "embeddings = th.ones([batch_size, 1, embed_dim], device=device, requires_grad=True)\n",
    "mask = build_tf_horizon_mask(seq_len=seq_len, horizon=horizon, device=device)\n",
    "seq_embeddings, na = ac.build_sequence(embeddings=embeddings, actions=actions, seq_len=seq_len, mask=mask)\n",
    "actions = th.ones([batch_size, seq_len, action_dim], device=device, requires_grad=True)\n",
    "org_actions = actions.detach().clone()\n",
    "\n",
    "goal_label = th.ones([batch_size, seq_len], device=device, dtype=th.double)\n",
    "opt_mask = th.zeros_like(goal_label, dtype=th.bool)\n",
    "opt_mask[:,-1] = 1\n",
    "acps.optimizer_class = th.optim.Adam\n",
    "acps.inference_opt_lr = 1e-1\n",
    "loss_reward_full, actions, seq_embeddings, scores = ac.optimize_sequence(actions, seq_embeddings, pred_mask=mask, opt_mask=opt_mask, steps=steps, current_step=current_step, goal_label=goal_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_reward_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "th.manual_seed(0)\n",
    "device = 'cpu'\n",
    "ac, acps, action_dim, obs_dim, batch_size, embed_dim, seq_len = setup_opt_state(device=device)\n",
    "seq_len = 100\n",
    "horizon = 0\n",
    "steps = 100\n",
    "current_step = 98\n",
    "embeddings = th.ones([batch_size, 1, embed_dim], device=device, requires_grad=True)\n",
    "mask = build_tf_horizon_mask(seq_len=seq_len, horizon=horizon, device=device)\n",
    "seq_embeddings, na = ac.build_sequence(embeddings=embeddings, actions=actions, seq_len=seq_len, mask=mask)\n",
    "actions = th.ones([batch_size, seq_len, action_dim], device=device, requires_grad=True)\n",
    "org_actions = actions.detach().clone()\n",
    "\n",
    "goal_label = th.ones([batch_size, seq_len], device=device, dtype=th.double)\n",
    "opt_mask = th.zeros_like(goal_label, dtype=th.bool)\n",
    "opt_mask[:,-1] = 1\n",
    "acps.optimizer_class = th.optim.Adam\n",
    "acps.inference_opt_lr = 1e-1\n",
    "loss_reward_part, actions, seq_embeddings, scores = ac.optimize_sequence(actions, seq_embeddings, pred_mask=mask, opt_mask=opt_mask, steps=steps, current_step=current_step, goal_label=goal_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_reward_part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert loss_reward_part > loss_reward_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('ac')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c27e8fa6375f4d15af5a5f5541d8bb88746b588c9fe1102cfd8de011d36c10c2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
