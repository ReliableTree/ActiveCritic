{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import torch as th\n",
    "from ActiveCritic.metaworld.metaworld.envs import \\\n",
    "    ALL_V2_ENVIRONMENTS_GOAL_OBSERVABLE\n",
    "from ActiveCritic.model_src.transformer import (ModelSetup,\n",
    "                                                TransformerModel)\n",
    "from ActiveCritic.model_src.whole_sequence_model import (WholeSequenceModelSetup)\n",
    "from ActiveCritic.policy.active_critic_policy import (ACPOptResult,\n",
    "                                                      ActiveCriticPolicy,\n",
    "                                                      ActiveCriticPolicySetup)\n",
    "from ActiveCritic.tests.test_utils.utils import make_wsm_setup\n",
    "from ActiveCritic.utils.gym_utils import (DummyExtractor, make_policy_dict,\n",
    "                                          new_epoch_reach)\n",
    "from ActiveCritic.utils.pytorch_utils import make_partially_observed_seq\n",
    "from ActiveCritic.utils.gym_utils import make_dummy_vec_env\n",
    "\n",
    "from gym.wrappers import TimeLimit\n",
    "from imitation.data.wrappers import RolloutInfoWrapper\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "\n",
    "th.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_obs_act_space(obs_dim, action_dim):\n",
    "    obs_array_low = [0]*obs_dim\n",
    "    obs_array_high = [1]*obs_dim\n",
    "    action_low = [0]*action_dim\n",
    "    action_high = [1]*action_dim\n",
    "    observation_space = gym.spaces.box.Box(\n",
    "        np.array(obs_array_low), np.array(obs_array_high), (obs_dim,), float)\n",
    "    action_space = gym.spaces.box.Box(\n",
    "        np.array(action_low), np.array(action_high), (action_dim,), float)\n",
    "    return observation_space, action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ActiveCritic.model_src.whole_sequence_model import WholeSequenceModel\n",
    "\n",
    "\n",
    "seq_len = 20\n",
    "d_output = 2\n",
    "d_result = 1\n",
    "\n",
    "wsm_actor_setup = make_wsm_setup(seq_len=seq_len, d_output=d_output)\n",
    "wsm_critic_setup = make_wsm_setup(seq_len=seq_len, d_output=1)\n",
    "actor = WholeSequenceModel(wsm_actor_setup)\n",
    "critic = WholeSequenceModel(wsm_critic_setup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_dim = 4\n",
    "act_dim = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs, acts = make_obs_act_space(obs_dim, act_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_acps(seq_len, extractor, new_epoch):\n",
    "    acps = ActiveCriticPolicySetup()\n",
    "    acps.device='cuda'\n",
    "    acps.epoch_len=seq_len\n",
    "    acps.extractor=extractor\n",
    "    acps.new_epoch=new_epoch\n",
    "    acps.opt_steps=100\n",
    "    acps.optimisation_threshold=0.5\n",
    "    acps.inference_opt_lr = 1e-1\n",
    "    acps.optimize = True\n",
    "    return acps\n",
    "\n",
    "acps = make_acps(seq_len=seq_len, extractor=DummyExtractor(), new_epoch=new_epoch_reach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ac = ActiveCriticPolicy(observation_space=obs, action_space=acts, actor=actor, critic=critic, acps=acps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_step = 2\n",
    "batch_size = 2\n",
    "org_actions = th.ones([batch_size,acps.epoch_len,act_dim], device=acps.device, dtype=th.float, requires_grad=True)\n",
    "opt_actions = th.zeros([batch_size,acps.epoch_len,act_dim], device=acps.device, dtype=th.float, requires_grad=True)\n",
    "\n",
    "pro_opt_actions = ac.proj_actions(org_actions, opt_actions, current_step=current_step)\n",
    "\n",
    "assert th.equal(org_actions[:,:current_step], pro_opt_actions[:, :current_step])\n",
    "assert th.equal(opt_actions[:,current_step:], pro_opt_actions[:, current_step:])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_step = 3\n",
    "org_actions = th.ones([batch_size,acps.epoch_len,act_dim], device=acps.device, dtype=th.float, requires_grad=False)\n",
    "opt_actions = th.zeros([batch_size,acps.epoch_len,act_dim], device=acps.device, dtype=th.float, requires_grad=True)\n",
    "obs_seq = 2*th.ones([batch_size,current_step+1,obs_dim], device=acps.device, dtype=th.float, requires_grad=False)\n",
    "org_obs_seq = 2*th.ones([batch_size,current_step+1,obs_dim], device=acps.device, dtype=th.float, requires_grad=False)\n",
    "optimizer = th.optim.Adam([opt_actions], lr=1e-1)\n",
    "goal_label = th.ones([batch_size, seq_len, 1], device=acps.device, dtype=th.float)\n",
    "\n",
    "actions, critic_result = ac.inference_opt_step(org_actions=org_actions, opt_actions=opt_actions, obs_seq=obs_seq, optimizer=optimizer, goal_label=goal_label, current_step=current_step)\n",
    "\n",
    "last_critic_result = th.clone(critic_result.detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    actions, critic_result = ac.inference_opt_step(org_actions=org_actions, opt_actions=opt_actions, obs_seq=obs_seq, optimizer=optimizer, goal_label=goal_label, current_step=current_step)\n",
    "    print(critic_result)\n",
    "    assert th.equal(org_actions[:,:current_step], actions[:, :current_step]), 'org_actions were overwritten'\n",
    "    assert not th.equal(opt_actions[:,current_step:], org_actions[:, current_step:])\n",
    "    assert th.all(critic_result > last_critic_result), 'optimisation does not work.'\n",
    "    last_critic_result = th.clone(critic_result.detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_critic_result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions, expected_success = ac.optimize_act_sequence(actions=actions, observations=obs_seq, current_step=current_step)\n",
    "assert th.equal(org_actions[:,:current_step], actions[:, :current_step]), 'org_actions were overwritten'\n",
    "assert not th.equal(opt_actions[:,current_step:], org_actions[:, current_step:])\n",
    "assert th.all(expected_success >= ac.args_obj.optimisation_threshold), 'optimisation does not work.'\n",
    "assert th.equal(obs_seq, org_obs_seq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ActiveCritic.tests.test_utils.utils import make_wsm_setup, make_obs_act_space, make_acps\n",
    "from ActiveCritic.utils.gym_utils import new_epoch_pap, DummyExtractor\n",
    "\n",
    "import gym\n",
    "import numpy as np\n",
    "import torch as th\n",
    "from ActiveCritic.metaworld.metaworld.envs import \\\n",
    "    ALL_V2_ENVIRONMENTS_GOAL_OBSERVABLE\n",
    "from ActiveCritic.model_src.transformer import (ModelSetup,\n",
    "                                                TransformerModel)\n",
    "from ActiveCritic.model_src.whole_sequence_model import (WholeSequenceModelSetup, WholeSequenceModel)\n",
    "from ActiveCritic.policy.active_critic_policy import (ACPOptResult,\n",
    "                                                      ActiveCriticPolicy,\n",
    "                                                      ActiveCriticPolicySetup)\n",
    "from ActiveCritic.tests.test_utils.utils import make_wsm_setup\n",
    "from ActiveCritic.utils.gym_utils import (DummyExtractor, make_policy_dict,\n",
    "                                          new_epoch_reach)\n",
    "from ActiveCritic.utils.pytorch_utils import make_partially_observed_seq\n",
    "from ActiveCritic.utils.gym_utils import make_dummy_vec_env\n",
    "\n",
    "from gym.wrappers import TimeLimit\n",
    "from imitation.data.wrappers import RolloutInfoWrapper\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "\n",
    "th.manual_seed(0)\n",
    "def setup_ac():\n",
    "    seq_len = 4\n",
    "    d_output = 2\n",
    "    d_result = 1\n",
    "    obs_dim = 3\n",
    "    batch_size = 2\n",
    "    wsm_actor_setup = make_wsm_setup(\n",
    "        seq_len=seq_len, d_output=d_output)\n",
    "    wsm_critic_setup = make_wsm_setup(\n",
    "        seq_len=seq_len, d_output=1)\n",
    "    acps = make_acps(\n",
    "        seq_len=seq_len, extractor=DummyExtractor(), new_epoch=new_epoch_pap)\n",
    "    obs_space, acts_space = make_obs_act_space(\n",
    "        obs_dim=obs_dim, action_dim=d_output)\n",
    "    actor = WholeSequenceModel(wsm_actor_setup)\n",
    "    critic = WholeSequenceModel(wsm_critic_setup)\n",
    "    ac = ActiveCriticPolicy(observation_space=obs_space, action_space=acts_space,\n",
    "                            actor=actor, critic=critic, acps=acps)\n",
    "    return ac, acps, d_output, obs_dim, batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "th.manual_seed(0)\n",
    "\n",
    "current_step = 1\n",
    "ac, acps, act_dim, obs_dim, batch_size = setup_ac()\n",
    "\n",
    "\n",
    "org_actions = th.zeros([batch_size, acps.epoch_len, act_dim],\n",
    "                        device=acps.device, dtype=th.float, requires_grad=False)\n",
    "opt_actions = th.zeros([batch_size, acps.epoch_len, act_dim],\n",
    "                        device=acps.device, dtype=th.float, requires_grad=True)\n",
    "obs_seq = 2*th.ones([batch_size, acps.epoch_len, obs_dim],\n",
    "                    device=acps.device, dtype=th.float, requires_grad=False)\n",
    "org_obs_seq = 2*th.ones([batch_size, acps.epoch_len, obs_dim],\n",
    "                        device=acps.device, dtype=th.float, requires_grad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_ac_reach():\n",
    "    seq_len = 5\n",
    "    env, gt_policy = make_dummy_vec_env('reach', seq_len=seq_len)\n",
    "    d_result = 1\n",
    "    d_output = env.action_space.shape[0]\n",
    "    wsm_actor_setup = make_wsm_setup(\n",
    "        seq_len=seq_len, d_output=d_output)\n",
    "    wsm_critic_setup = make_wsm_setup(\n",
    "        seq_len=seq_len, d_output=1)\n",
    "    acps = make_acps(\n",
    "        seq_len=seq_len, extractor=DummyExtractor(), new_epoch=new_epoch_reach)\n",
    "    actor = WholeSequenceModel(wsm_actor_setup)\n",
    "    critic = WholeSequenceModel(wsm_critic_setup)\n",
    "    ac = ActiveCriticPolicy(observation_space=env.observation_space, action_space=env.action_space,\n",
    "                            actor=actor, critic=critic, acps=acps)\n",
    "    return ac, acps, env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "th.manual_seed(0)\n",
    "ac, acps, env = setup_ac_reach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obsv = env.reset()\n",
    "last_obsv = th.tensor(obsv)\n",
    "all_taken_actions = []\n",
    "all_observations = [obsv]\n",
    "for i in range(5):\n",
    "    action = ac.predict(obsv)\n",
    "    all_taken_actions.append(action)\n",
    "    obsv, rew, dones, info = env.step(action)\n",
    "    all_observations.append(obsv)\n",
    "    assert len(th.nonzero(ac.obs_seq[:,ac.current_step+1:])) == 0\n",
    "    if new_epoch_reach(last_obsv, th.tensor(obsv)):\n",
    "        assert ac.current_step == ac.args_obj.epoch_len - 1\n",
    "        ata = th.tensor(all_taken_actions).transpose(0,1)\n",
    "        print(th.equal(ata.to('cuda'), ac.current_result.gen_trj))\n",
    "        aob = th.tensor(all_observations).transpose(0,1)[:,:5]\n",
    "        print(th.equal(aob.to('cuda'), ac.obs_seq))\n",
    "        assert ac.current_result.expected_succes_before < ac.current_result.expected_succes_after\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aob.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('tfTest')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bee90e249730b85f00f3915f0cf4f21bc0729131dcc7008c941068256fd0d344"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
