{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hendrik/anaconda3/envs/tfTest/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/hendrik/anaconda3/envs/tfTest/lib/python3.9/site-packages/gym/spaces/box.py:73: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f1288006cb0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import torch as th\n",
    "from ActiveCritic.metaworld.metaworld.envs import \\\n",
    "    ALL_V2_ENVIRONMENTS_GOAL_OBSERVABLE\n",
    "from ActiveCritic.model_src.transformer import (CriticTransformer, ModelSetup,\n",
    "                                                TransformerModel)\n",
    "from ActiveCritic.model_src.whole_sequence_model import (\n",
    "    WholeSequenceActor, WholeSequenceCritic, WholeSequenceModelSetup)\n",
    "from ActiveCritic.policy.active_critic_policy import (ACPOptResult,\n",
    "                                                      ActiveCriticPolicy,\n",
    "                                                      ActiveCriticPolicySetup)\n",
    "from ActiveCritic.tests.test_utils.utils import make_wsm_setup\n",
    "from ActiveCritic.utils.gym_utils import (DummyExtractor, make_policy_dict,\n",
    "                                          new_epoch_reach)\n",
    "from ActiveCritic.utils.pytorch_utils import make_partially_observed_seq\n",
    "from ActiveCritic.utils.gym_utils import make_dummy_vec_env\n",
    "\n",
    "from gym.wrappers import TimeLimit\n",
    "from imitation.data.wrappers import RolloutInfoWrapper\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "\n",
    "th.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_obs_act_space(obs_dim, action_dim):\n",
    "    obs_array_low = [0]*obs_dim\n",
    "    obs_array_high = [1]*obs_dim\n",
    "    action_low = [0]*action_dim\n",
    "    action_high = [1]*action_dim\n",
    "    observation_space = gym.spaces.box.Box(\n",
    "        np.array(obs_array_low), np.array(obs_array_high), (obs_dim,), float)\n",
    "    action_space = gym.spaces.box.Box(\n",
    "        np.array(action_low), np.array(action_high), (action_dim,), float)\n",
    "    return observation_space, action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 4\n",
    "d_output = 2\n",
    "d_result = 1\n",
    "\n",
    "wsm_actor_setup = make_wsm_setup(seq_len=seq_len, d_output=d_output, model_class=TransformerModel)\n",
    "wsm_critic_setup = make_wsm_setup(seq_len=seq_len, d_output=d_output, model_class=CriticTransformer, d_result=d_result)\n",
    "actor = WholeSequenceActor(wsm_actor_setup)\n",
    "critic = WholeSequenceCritic(wsm_critic_setup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_dim = 4\n",
    "act_dim = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hendrik/anaconda3/envs/tfTest/lib/python3.9/site-packages/gym/spaces/box.py:73: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float64\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "obs, acts = make_obs_act_space(obs_dim, act_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_acps(seq_len, extractor, new_epoch):\n",
    "    acps = ActiveCriticPolicySetup()\n",
    "    acps.device='cuda'\n",
    "    acps.epoch_len=seq_len\n",
    "    acps.extractor=extractor\n",
    "    acps.new_epoch=new_epoch\n",
    "    acps.opt_steps=100\n",
    "    acps.optimisation_threshold=0.5\n",
    "    acps.inference_opt_lr = 1e-1\n",
    "    acps.optimize = True\n",
    "    return acps\n",
    "\n",
    "acps = make_acps(seq_len=seq_len, extractor=DummyExtractor(), new_epoch=new_epoch_reach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ac = ActiveCriticPolicy(observation_space=obs, action_space=acts, actor=actor, critic=critic, acps=acps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_step = 2\n",
    "batch_size = 2\n",
    "org_actions = th.ones([batch_size,acps.epoch_len,act_dim], device=acps.device, dtype=th.float, requires_grad=True)\n",
    "opt_actions = th.zeros([batch_size,acps.epoch_len,act_dim], device=acps.device, dtype=th.float, requires_grad=True)\n",
    "\n",
    "pro_opt_actions = ac.proj_actions(org_actions, opt_actions, current_step=current_step)\n",
    "\n",
    "assert th.equal(org_actions[:,:current_step], pro_opt_actions[:, :current_step])\n",
    "assert th.equal(opt_actions[:,current_step:], pro_opt_actions[:, current_step:])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_step = 0\n",
    "org_actions = th.ones([batch_size,acps.epoch_len,act_dim], device=acps.device, dtype=th.float, requires_grad=False)\n",
    "opt_actions = th.zeros([batch_size,acps.epoch_len,act_dim], device=acps.device, dtype=th.float, requires_grad=True)\n",
    "obs_seq = 2*th.ones([batch_size,current_step+1,obs_dim], device=acps.device, dtype=th.float, requires_grad=False)\n",
    "org_obs_seq = 2*th.ones([batch_size,current_step+1,obs_dim], device=acps.device, dtype=th.float, requires_grad=False)\n",
    "optimizer = th.optim.Adam([opt_actions], lr=1e-1)\n",
    "goal_label = th.ones([batch_size], device=acps.device, dtype=th.float)\n",
    "\n",
    "actions, critic_result = ac.inference_opt_step(org_actions=org_actions, opt_actions=opt_actions, obs_seq=obs_seq, optimizer=optimizer, goal_label=goal_label, current_step=current_step)\n",
    "\n",
    "last_critic_result = th.clone(critic_result.detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.2089],\n",
      "        [-0.2089]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-0.1465],\n",
      "        [-0.1465]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-0.0714],\n",
      "        [-0.0714]], device='cuda:0', grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    actions, critic_result = ac.inference_opt_step(org_actions=org_actions, opt_actions=opt_actions, obs_seq=obs_seq, optimizer=optimizer, goal_label=goal_label, current_step=current_step)\n",
    "    print(critic_result)\n",
    "    assert th.equal(org_actions[:,:current_step], actions[:, :current_step]), 'org_actions were overwritten'\n",
    "    assert not th.equal(opt_actions[:,current_step:], org_actions[:, current_step:])\n",
    "    assert th.all(critic_result > last_critic_result), 'optimisation does not work.'\n",
    "    last_critic_result = th.clone(critic_result.detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.3926, -0.3934],\n",
       "         [ 0.2593,  0.3866],\n",
       "         [ 0.3968, -0.4009],\n",
       "         [ 0.4011, -0.4001]],\n",
       "\n",
       "        [[-0.3926, -0.3934],\n",
       "         [ 0.2593,  0.3866],\n",
       "         [ 0.3968, -0.4009],\n",
       "         [ 0.4011, -0.4001]]], device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions, expected_success = ac.optimize_act_sequence(actions=actions, observations=obs_seq, current_step=current_step)\n",
    "assert th.equal(org_actions[:,:current_step], actions[:, :current_step]), 'org_actions were overwritten'\n",
    "assert not th.equal(opt_actions[:,current_step:], org_actions[:, current_step:])\n",
    "assert th.all(expected_success >= ac.args_obj.optimisation_threshold), 'optimisation does not work.'\n",
    "assert th.equal(obs_seq, org_obs_seq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5048],\n",
       "        [0.5048]], device='cuda:0', grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expected_success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[2., 2., 2., 2.]],\n",
       "\n",
       "        [[2., 2., 2., 2.]]], device='cuda:0')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[2., 2., 2., 2.]],\n",
       "\n",
       "        [[2., 2., 2., 2.]]], device='cuda:0')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "org_obs_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ActiveCritic.tests.test_utils.utils import make_wsm_setup, make_obs_act_space, make_acps\n",
    "from ActiveCritic.utils.gym_utils import new_epoch_pap, DummyExtractor\n",
    "\n",
    "import gym\n",
    "import numpy as np\n",
    "import torch as th\n",
    "from ActiveCritic.metaworld.metaworld.envs import \\\n",
    "    ALL_V2_ENVIRONMENTS_GOAL_OBSERVABLE\n",
    "from ActiveCritic.model_src.transformer import (CriticTransformer, ModelSetup,\n",
    "                                                TransformerModel)\n",
    "from ActiveCritic.model_src.whole_sequence_model import (\n",
    "    WholeSequenceActor, WholeSequenceCritic, WholeSequenceModelSetup)\n",
    "from ActiveCritic.policy.active_critic_policy import (ACPOptResult,\n",
    "                                                      ActiveCriticPolicy,\n",
    "                                                      ActiveCriticPolicySetup)\n",
    "from ActiveCritic.tests.test_utils.utils import make_wsm_setup\n",
    "from ActiveCritic.utils.gym_utils import (DummyExtractor, make_policy_dict,\n",
    "                                          new_epoch_reach)\n",
    "from ActiveCritic.utils.pytorch_utils import make_partially_observed_seq\n",
    "from ActiveCritic.utils.gym_utils import make_dummy_vec_env\n",
    "\n",
    "from gym.wrappers import TimeLimit\n",
    "from imitation.data.wrappers import RolloutInfoWrapper\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "\n",
    "th.manual_seed(0)\n",
    "def setup_ac():\n",
    "    seq_len = 4\n",
    "    d_output = 2\n",
    "    d_result = 1\n",
    "    obs_dim = 3\n",
    "    batch_size = 2\n",
    "    wsm_actor_setup = make_wsm_setup(\n",
    "        seq_len=seq_len, d_output=d_output, model_class=TransformerModel)\n",
    "    wsm_critic_setup = make_wsm_setup(\n",
    "        seq_len=seq_len, d_output=d_output, model_class=CriticTransformer, d_result=d_result)\n",
    "    acps = make_acps(\n",
    "        seq_len=seq_len, extractor=DummyExtractor(), new_epoch=new_epoch_pap)\n",
    "    obs_space, acts_space = make_obs_act_space(\n",
    "        obs_dim=obs_dim, action_dim=d_output)\n",
    "    actor = WholeSequenceActor(wsm_actor_setup)\n",
    "    critic = WholeSequenceCritic(wsm_critic_setup)\n",
    "    ac = ActiveCriticPolicy(observation_space=obs_space, action_space=acts_space,\n",
    "                            actor=actor, critic=critic, acps=acps)\n",
    "    return ac, acps, d_output, obs_dim, batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "th.manual_seed(0)\n",
    "\n",
    "current_step = 1\n",
    "ac, acps, act_dim, obs_dim, batch_size = setup_ac()\n",
    "\n",
    "\n",
    "org_actions = th.zeros([batch_size, acps.epoch_len, act_dim],\n",
    "                        device=acps.device, dtype=th.float, requires_grad=False)\n",
    "opt_actions = th.zeros([batch_size, acps.epoch_len, act_dim],\n",
    "                        device=acps.device, dtype=th.float, requires_grad=True)\n",
    "obs_seq = 2*th.ones([batch_size, acps.epoch_len, obs_dim],\n",
    "                    device=acps.device, dtype=th.float, requires_grad=False)\n",
    "org_obs_seq = 2*th.ones([batch_size, acps.epoch_len, obs_dim],\n",
    "                        device=acps.device, dtype=th.float, requires_grad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 3])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs_seq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = ac.forward(observation_seq=obs_seq, action_seq =org_actions, optimize=True, current_step=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hendrik/anaconda3/envs/tfTest/lib/python3.9/site-packages/gym/spaces/box.py:73: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "dve, gt_policy = make_dummy_vec_env('reach', 10)\n",
    "de = DummyExtractor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_ac_reach():\n",
    "    seq_len = 50\n",
    "    env, gt_policy = make_dummy_vec_env('reach', seq_len=seq_len)\n",
    "    d_result = 1\n",
    "    d_output = env.action_space.shape[0]\n",
    "    wsm_actor_setup = make_wsm_setup(\n",
    "        seq_len=seq_len, d_output=d_output, model_class=TransformerModel)\n",
    "    wsm_critic_setup = make_wsm_setup(\n",
    "        seq_len=seq_len, d_output=d_output, model_class=CriticTransformer, d_result=d_result)\n",
    "    acps = make_acps(\n",
    "        seq_len=seq_len, extractor=DummyExtractor(), new_epoch=new_epoch_reach)\n",
    "    actor = WholeSequenceActor(wsm_actor_setup)\n",
    "    critic = WholeSequenceCritic(wsm_critic_setup)\n",
    "    ac = ActiveCriticPolicy(observation_space=env.observation_space, action_space=env.action_space,\n",
    "                            actor=actor, critic=critic, acps=acps)\n",
    "    return ac, acps, env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hendrik/anaconda3/envs/tfTest/lib/python3.9/site-packages/gym/spaces/box.py:73: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "th.manual_seed(0)\n",
    "ac, acps, env = setup_ac_reach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "obsv = env.reset()\n",
    "last_obsv = th.tensor(obsv)\n",
    "all_taken_actions = []\n",
    "all_observations = [obsv]\n",
    "for i in range(50):\n",
    "    action = ac.predict(obsv)\n",
    "    all_taken_actions.append(action)\n",
    "    obsv, rew, dones, info = env.step(action)\n",
    "    all_observations.append(obsv)\n",
    "    assert len(th.nonzero(ac.obs_seq[:,ac.current_step+1:])) == 0\n",
    "    if new_epoch_reach(last_obsv, th.tensor(obsv)):\n",
    "        assert ac.current_step == ac.args_obj.epoch_len - 1\n",
    "        ata = th.tensor(all_taken_actions).transpose(0,1)\n",
    "        print(th.equal(ata.to('cuda'), ac.current_result.gen_trj))\n",
    "        aob = th.tensor(all_observations).transpose(0,1)[:,:50]\n",
    "        print(th.equal(aob.to('cuda'), ac.obs_seq))\n",
    "        assert ac.current_result.expected_succes_before < ac.current_result.expected_succes_after\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ac.current_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ac.args_obj.optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ac.args_obj.optimisation_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ac.args_obj.opt_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0657]], device='cuda:0', grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ac.current_result.expected_succes_after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4587]], device='cuda:0', grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ac.current_result.expected_succes_before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('tfTest')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bee90e249730b85f00f3915f0cf4f21bc0729131dcc7008c941068256fd0d344"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
