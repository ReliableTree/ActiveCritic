{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hendrik/anaconda3/envs/ac/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/hendrik/anaconda3/envs/ac/lib/python3.10/site-packages/gym/spaces/box.py:73: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "import unittest\n",
    "\n",
    "import torch as th\n",
    "import numpy as np\n",
    "\n",
    "from active_critic.model_src.whole_sequence_model import WholeSequenceModel\n",
    "from active_critic.policy.active_critic_policy import *\n",
    "from active_critic.utils.test_utils import (make_acps, make_obs_act_space,\n",
    "                                            make_wsm_setup)\n",
    "from active_critic.utils.gym_utils import (DummyExtractor, make_dummy_vec_env,\n",
    "                                           new_epoch_pap,\n",
    "                                           new_epoch_reach)\n",
    "\n",
    "from active_critic.utils.gym_utils import make_policy_dict, new_epoch_reach, make_dummy_vec_env, sample_expert_transitions, parse_sampled_transitions\n",
    "from active_critic.model_src.state_model import StateModel, StateModelArgs\n",
    "from active_critic.utils.pytorch_utils import build_tf_horizon_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from active_critic.model_src.whole_sequence_model import *\n",
    "\n",
    "\n",
    "def setup_opt_state(device='cuda'):\n",
    "    seq_len = 6\n",
    "    action_dim = 2\n",
    "    obs_dim = 3\n",
    "    batch_size = 2\n",
    "    embed_dim = 4\n",
    "    lr = 1e-3\n",
    "\n",
    "    actor_args = StateModelArgs()\n",
    "    actor_args.arch = [20, action_dim]\n",
    "    actor_args.device = device\n",
    "    actor_args.lr = lr\n",
    "    actor = StateModel(args=actor_args)\n",
    "\n",
    "    critic_args = StateModelArgs()\n",
    "    critic_args.arch = [10, 1]\n",
    "    critic_args.device = device\n",
    "    critic_args.lr = lr\n",
    "    critic = StateModel(args=critic_args)\n",
    "\n",
    "    emitter_args = StateModelArgs()\n",
    "    emitter_args.arch = [20, embed_dim]\n",
    "    emitter_args.device = device\n",
    "    emitter_args.lr = lr\n",
    "    emitter = StateModel(args=emitter_args)\n",
    "\n",
    "    predictor_args = make_wsm_setup(\n",
    "        seq_len=seq_len, d_output=embed_dim, device=device)\n",
    "    predictor_args.model_setup.d_hid = 200\n",
    "    predictor_args.model_setup.d_model = 200\n",
    "    predictor_args.model_setup.nlayers = 1\n",
    "    predictor = WholeSequenceModel(args=predictor_args)\n",
    "\n",
    "\n",
    "    acps = make_acps(\n",
    "        seq_len=seq_len, extractor=DummyExtractor(), new_epoch=new_epoch_pap, device=device)\n",
    "    acps.opt_steps = 2\n",
    "    obs_space, acts_space = make_obs_act_space(\n",
    "        obs_dim=obs_dim, action_dim=action_dim)\n",
    "    ac = ActiveCriticPolicy(observation_space=obs_space, \n",
    "                            action_space=acts_space,\n",
    "                            actor=actor,\n",
    "                            critic=critic,\n",
    "                            predictor=predictor,\n",
    "                            emitter=emitter,\n",
    "                            acps=acps)\n",
    "    return ac, acps, action_dim, obs_dim, batch_size, embed_dim, seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hendrik/anaconda3/envs/ac/lib/python3.10/site-packages/gym/spaces/box.py:73: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float64\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "th.manual_seed(0)\n",
    "device = 'cuda'\n",
    "ac, acps, action_dim, obs_dim, batch_size, embed_dim, seq_len = setup_opt_state(device=device)\n",
    "horizon = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = th.ones([batch_size, 1, embed_dim], device=device)\n",
    "actions = th.ones([batch_size, seq_len, action_dim], device=device, requires_grad=True)\n",
    "goal_embeddings = th.ones_like(embeddings)\n",
    "action_optim = th.optim.Adam([actions], lr=1e-1)\n",
    "opt_paras = action_optim.state_dict()\n",
    "\n",
    "mask = build_tf_horizon_mask(seq_len=seq_len, horizon=horizon, device=device)\n",
    "seq_embeddings = ac.build_sequence(embeddings=embeddings, actions=actions, seq_len=seq_len, mask=mask, detach=True)\n",
    "opt_actions = actions.detach()\n",
    "opt_actions.requires_grad = True\n",
    "next_embedding = ac.predict_step(embeddings=seq_embeddings.detach(), actions=opt_actions, mask=mask)\n",
    "seq_embedding = th.cat((embeddings[:,:1], next_embedding[:,:-1]), dim=1)\n",
    "loss = ((seq_embedding - th.ones_like(seq_embedding))**2).mean()\n",
    "loss.backward()\n",
    "assert (opt_actions.grad != 0).sum() == opt_actions[:,:-1].numel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = th.ones([batch_size, 1, embed_dim], device=device)\n",
    "actions = th.ones([batch_size, seq_len, action_dim], device=device, requires_grad=True)\n",
    "goal_embeddings = th.ones_like(embeddings)\n",
    "action_optim = th.optim.Adam([actions], lr=1e-1)\n",
    "opt_paras = action_optim.state_dict()\n",
    "\n",
    "mask = build_tf_horizon_mask(seq_len=seq_len, horizon=horizon, device=device)\n",
    "seq_embeddings = ac.build_sequence(embeddings=embeddings, actions=actions, seq_len=seq_len, mask=mask, detach=True)\n",
    "opt_actions = actions.detach()\n",
    "opt_actions.requires_grad = True\n",
    "next_embedding = ac.predict_step(embeddings=seq_embeddings.detach(), actions=opt_actions, mask=mask)\n",
    "seq_embedding = th.cat((embeddings[:,:1], next_embedding[:,:-1]), dim=1)\n",
    "loss = ((seq_embedding[:,-1] - th.ones_like(seq_embedding[:,-1] ))**2).mean()\n",
    "loss.backward()\n",
    "assert (opt_actions.grad != 0).sum() == (min(seq_len-1, 1+horizon) * action_dim*batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "horizon = 1\n",
    "embeddings = th.ones([batch_size, 1, embed_dim], device=device)\n",
    "actions = th.ones([batch_size, seq_len, action_dim], device=device, requires_grad=True)\n",
    "goal_embeddings = th.ones_like(embeddings)\n",
    "action_optim = th.optim.Adam([actions], lr=1e-1)\n",
    "opt_paras = action_optim.state_dict()\n",
    "\n",
    "mask = build_tf_horizon_mask(seq_len=seq_len, horizon=horizon, device=device)\n",
    "seq_embeddings = ac.build_sequence(embeddings=embeddings, actions=actions, seq_len=seq_len, mask=mask, detach=True)\n",
    "opt_actions = actions.detach()\n",
    "opt_actions.requires_grad = True\n",
    "next_embedding = ac.predict_step(embeddings=seq_embeddings.detach(), actions=opt_actions, mask=mask)\n",
    "seq_embedding = th.cat((embeddings[:,:1], next_embedding[:,:-1]), dim=1)\n",
    "loss = ((seq_embedding[:,-1] - th.ones_like(seq_embedding[:,-1] ))**2).mean()\n",
    "loss.backward()\n",
    "assert (opt_actions.grad != 0).sum() == (min(seq_len-1, 1+horizon) * action_dim*batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "horizon = seq_len\n",
    "embeddings = th.ones([batch_size, 1, embed_dim], device=device)\n",
    "actions = th.ones([batch_size, seq_len, action_dim], device=device, requires_grad=True)\n",
    "goal_embeddings = th.ones_like(embeddings)\n",
    "action_optim = th.optim.Adam([actions], lr=1e-1)\n",
    "opt_paras = action_optim.state_dict()\n",
    "\n",
    "mask = build_tf_horizon_mask(seq_len=seq_len, horizon=horizon, device=device)\n",
    "seq_embeddings = ac.build_sequence(embeddings=embeddings, actions=actions, seq_len=seq_len, mask=mask, detach=True)\n",
    "opt_actions = actions.detach()\n",
    "opt_actions.requires_grad = True\n",
    "next_embedding = ac.predict_step(embeddings=seq_embeddings.detach(), actions=opt_actions, mask=mask)\n",
    "seq_embedding = th.cat((embeddings[:,:1], next_embedding[:,:-1]), dim=1)\n",
    "loss = ((seq_embedding[:,-1] - th.ones_like(seq_embedding[:,-1] ))**2).mean()\n",
    "loss.backward()\n",
    "assert (opt_actions.grad != 0).sum() == (min(seq_len-1, 1+horizon) * action_dim*batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "horizon = seq_len\n",
    "embeddings = th.ones([batch_size, 1, embed_dim], device=device)\n",
    "actions = th.ones([batch_size, seq_len, action_dim], device=device, requires_grad=True)\n",
    "goal_embeddings = th.ones_like(embeddings)\n",
    "action_optim = th.optim.Adam([actions], lr=1e-1)\n",
    "opt_paras = action_optim.state_dict()\n",
    "\n",
    "mask = build_tf_horizon_mask(seq_len=seq_len, horizon=horizon, device=device)\n",
    "seq_embeddings = ac.build_sequence(embeddings=embeddings, actions=actions, seq_len=seq_len, mask=mask, detach=True)\n",
    "opt_actions = actions.detach()\n",
    "opt_actions.requires_grad = True\n",
    "next_embedding = ac.predict_step(embeddings=seq_embeddings.detach(), actions=opt_actions, mask=mask)\n",
    "seq_embedding = th.cat((embeddings[:,:1], next_embedding[:,:-1]), dim=1)\n",
    "loss = ((seq_embedding[:,-1] - th.ones_like(seq_embedding[:,-1] ))**2).mean()\n",
    "loss.backward()\n",
    "assert (opt_actions.grad != 0).sum() == (min(seq_len-1, 1+horizon) * action_dim*batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "horizon = seq_len\n",
    "embeddings = th.ones([batch_size, 1, embed_dim], device=device)\n",
    "actions = th.ones([batch_size, seq_len, action_dim], device=device, requires_grad=True)\n",
    "goal_embeddings = th.ones_like(embeddings)\n",
    "action_optim = th.optim.Adam([actions], lr=1e-1)\n",
    "opt_paras = action_optim.state_dict()\n",
    "\n",
    "mask = build_tf_horizon_mask(seq_len=seq_len, horizon=horizon, device=device)\n",
    "seq_embeddings = ac.build_sequence(embeddings=embeddings, actions=actions, seq_len=seq_len, mask=mask, detach=True)\n",
    "opt_actions = actions.detach()\n",
    "opt_actions.requires_grad = True\n",
    "next_embedding = ac.predict_step(embeddings=seq_embeddings.detach(), actions=opt_actions, mask=mask)\n",
    "seq_embedding = th.cat((embeddings[:,:1], next_embedding[:,:-1]), dim=1)\n",
    "loss = ((seq_embedding[:,-1] - th.ones_like(seq_embedding[:,-1] ))**2).mean()\n",
    "loss.backward()\n",
    "assert (opt_actions.grad != 0).sum() == (min(seq_len-1, 1+horizon) * action_dim*batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "horizon = 0\n",
    "embeddings = th.ones([batch_size, 1, embed_dim], device=device, requires_grad=True)\n",
    "actions = th.ones([batch_size, seq_len, action_dim], device=device, requires_grad=True)\n",
    "action_optim = th.optim.Adam([actions], lr=1e-1)\n",
    "opt_paras = action_optim.state_dict()\n",
    "\n",
    "mask = build_tf_horizon_mask(seq_len=seq_len, horizon=horizon, device=device)\n",
    "seq_embeddings = ac.build_sequence(embeddings=embeddings, actions=actions, seq_len=seq_len, mask=mask, detach=False)\n",
    "loss = ((seq_embeddings[:,-1] - th.ones_like(seq_embeddings[:,-1] ))**2).mean()\n",
    "loss.backward()\n",
    "assert (actions.grad!=0).sum() == actions.numel() - action_dim*batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "horizon = 0\n",
    "embeddings = th.ones([batch_size, 1, embed_dim], device=device, requires_grad=True)\n",
    "actions = th.ones([batch_size, seq_len, action_dim], device=device, requires_grad=True)\n",
    "action_optim = th.optim.Adam([actions], lr=1e-1)\n",
    "opt_paras = action_optim.state_dict()\n",
    "\n",
    "mask = build_tf_horizon_mask(seq_len=seq_len, horizon=horizon, device=device)\n",
    "seq_embeddings = ac.build_sequence(embeddings=embeddings, actions=actions, seq_len=seq_len, mask=mask, detach=True)\n",
    "opt_actions = actions.detach()\n",
    "opt_actions.requires_grad = True\n",
    "next_embedding = ac.predict_step(embeddings=seq_embeddings.detach(), actions=opt_actions, mask=mask)\n",
    "seq_embedding = th.cat((embeddings[:,:1], next_embedding[:,:-1]), dim=1)\n",
    "loss = ((seq_embedding[:,-1] - th.ones_like(seq_embedding[:,-1] ))**2).mean()\n",
    "loss.backward()\n",
    "assert (opt_actions.grad != 0).sum() == batch_size*action_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "ac = ac.double()\n",
    "seq_len = 8\n",
    "horizon = 0\n",
    "embeddings = th.ones([batch_size, 1, embed_dim], device=device, requires_grad=True, dtype=th.double)\n",
    "org_embeddings = th.ones([batch_size, 1, embed_dim], device=device, requires_grad=True, dtype=th.double)\n",
    "actions = th.ones([batch_size, seq_len, action_dim], device=device, requires_grad=True, dtype=th.double)\n",
    "org_actions = th.ones([batch_size, seq_len, action_dim], device=device, requires_grad=True, dtype=th.double)\n",
    "action_optim = th.optim.Adam([actions], lr=1e-1)\n",
    "opt_paras = action_optim.state_dict()\n",
    "\n",
    "mask = build_tf_horizon_mask(seq_len=seq_len, horizon=0, device=device).double()\n",
    "seq_embeddings = ac.build_sequence(embeddings=embeddings, actions=actions, seq_len=seq_len, mask=mask, detach=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "goal_embeddings = th.ones_like(seq_embeddings)\n",
    "\n",
    "def optimize_sequence(actions:th.Tensor, seq_embeddings:th.Tensor, mask:th.Tensor, goal_embeddings:th.Tensor, steps:int, detach:bool, current_step:int, reward_weight:float = 0):\n",
    "    th.manual_seed(0)\n",
    "    actions = actions.detach().clone()\n",
    "    actions.requires_grad = True\n",
    "    seq_embeddings = seq_embeddings.detach().clone()\n",
    "    seq_embeddings.requires_grad = True\n",
    "    optimizer = th.optim.Adam([actions, seq_embeddings], lr=1e-2)\n",
    "    opt_paras = optimizer.state_dict()\n",
    "    for i in range(steps):\n",
    "        actions = actions.detach().clone()\n",
    "        actions.requires_grad = True\n",
    "        seq_embeddings = seq_embeddings.detach().clone()\n",
    "        seq_embeddings.requires_grad = True\n",
    "\n",
    "        last_embeddings = seq_embeddings.detach().clone()\n",
    "\n",
    "        optimizer = th.optim.Adam([actions, seq_embeddings], lr=1e-2)\n",
    "\n",
    "\n",
    "        if detach:\n",
    "            next_seq_embeddings = ac.predict_step(embeddings=seq_embeddings, actions=actions, mask=mask)\n",
    "            loss_embedding = calcMSE(next_seq_embeddings[:,:-1], goal_embeddings[:,1:])\n",
    "\n",
    "        else:\n",
    "            seq_embeddings = ac.build_sequence(embeddings=seq_embedding.detach()[:,:current_step], actions=actions, seq_len=actions.shape[1], mask=mask, detach=False)\n",
    "            loss_embedding = 0\n",
    "\n",
    "\n",
    "        optimizer.load_state_dict(opt_paras)\n",
    "\n",
    "        loss_reward = calcMSE(seq_embeddings[:,-1], goal_embeddings[:,1])\n",
    "        loss = loss_embedding + loss_reward * reward_weight\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        opt_paras = optimizer.state_dict()\n",
    "\n",
    "    return loss_reward, loss_embedding, actions, seq_embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_reward, loss_embedding, na, ns = optimize_sequence(actions=actions, seq_embeddings=seq_embeddings, mask=mask, goal_embeddings=goal_embeddings, steps=1, detach=True, current_step=1, reward_weight=1)\n",
    "assert loss_embedding == 0\n",
    "assert th.equal(org_actions, actions)\n",
    "assert th.equal(embeddings, org_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_reward, loss_embedding, na, ns = optimize_sequence(actions=actions, seq_embeddings=seq_embeddings, mask=mask, goal_embeddings=goal_embeddings, steps=5000, detach=True, current_step=1, reward_weight=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "tensor(3.1139, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([[[0.9900, 0.9900],\n",
      "         [0.9900, 0.9900],\n",
      "         [0.9900, 0.9900],\n",
      "         [0.9900, 0.9900],\n",
      "         [0.9900, 0.9900],\n",
      "         [0.9900, 0.9900],\n",
      "         [0.9900, 0.9900],\n",
      "         [1.0000, 1.0000]],\n",
      "\n",
      "        [[0.9900, 0.9900],\n",
      "         [0.9900, 0.9900],\n",
      "         [0.9900, 0.9900],\n",
      "         [0.9900, 0.9900],\n",
      "         [0.9900, 0.9900],\n",
      "         [0.9900, 0.9900],\n",
      "         [0.9900, 0.9900],\n",
      "         [1.0000, 1.0000]]], device='cuda:0', dtype=torch.float64,\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "#steps: 1\n",
    "print(loss_reward)\n",
    "print(loss_embedding)\n",
    "print(na)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "tensor(2.8329, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([[[0.8998, 0.8998],\n",
      "         [0.9000, 0.8999],\n",
      "         [0.8995, 0.9000],\n",
      "         [0.8998, 0.8997],\n",
      "         [0.9000, 0.8996],\n",
      "         [0.8996, 0.8998],\n",
      "         [0.9002, 0.8994],\n",
      "         [1.0000, 1.0000]],\n",
      "\n",
      "        [[0.8998, 0.8998],\n",
      "         [0.9000, 0.8999],\n",
      "         [0.8995, 0.9000],\n",
      "         [0.8998, 0.8997],\n",
      "         [0.9000, 0.8996],\n",
      "         [0.8996, 0.8998],\n",
      "         [0.9002, 0.8994],\n",
      "         [1.0000, 1.0000]]], device='cuda:0', dtype=torch.float64,\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "#steps: 10\n",
    "print(loss_reward)\n",
    "print(loss_embedding)\n",
    "print(na)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "tensor(1.1696, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([[[-2.9414e-01,  2.5817e-03],\n",
      "         [-3.0123e-01, -4.9969e-04],\n",
      "         [-2.9671e-01, -9.1164e-03],\n",
      "         [-2.8929e-01, -2.4488e-02],\n",
      "         [-2.6265e-01, -4.3764e-02],\n",
      "         [-2.3138e-01,  4.8827e-03],\n",
      "         [-2.3820e-01,  2.1441e-02],\n",
      "         [ 1.0000e+00,  1.0000e+00]],\n",
      "\n",
      "        [[-2.9414e-01,  2.5817e-03],\n",
      "         [-3.0123e-01, -4.9969e-04],\n",
      "         [-2.9671e-01, -9.1164e-03],\n",
      "         [-2.8929e-01, -2.4488e-02],\n",
      "         [-2.6265e-01, -4.3764e-02],\n",
      "         [-2.3138e-01,  4.8827e-03],\n",
      "         [-2.3820e-01,  2.1441e-02],\n",
      "         [ 1.0000e+00,  1.0000e+00]]], device='cuda:0', dtype=torch.float64,\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "#steps: 1000\n",
    "print(loss_reward)\n",
    "print(loss_embedding)\n",
    "print(na)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "tensor(1.1696, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([[[-2.9424e-01,  2.7234e-03],\n",
      "         [-3.0127e-01,  1.3389e-04],\n",
      "         [-2.9732e-01, -9.3588e-03],\n",
      "         [-2.9111e-01, -2.4961e-02],\n",
      "         [-2.6100e-01, -4.6579e-02],\n",
      "         [-2.3155e-01,  4.7419e-03],\n",
      "         [-2.3852e-01,  2.1526e-02],\n",
      "         [ 1.0000e+00,  1.0000e+00]],\n",
      "\n",
      "        [[-2.9424e-01,  2.7234e-03],\n",
      "         [-3.0127e-01,  1.3389e-04],\n",
      "         [-2.9732e-01, -9.3588e-03],\n",
      "         [-2.9111e-01, -2.4961e-02],\n",
      "         [-2.6100e-01, -4.6579e-02],\n",
      "         [-2.3155e-01,  4.7419e-03],\n",
      "         [-2.3852e-01,  2.1526e-02],\n",
      "         [ 1.0000e+00,  1.0000e+00]]], device='cuda:0', dtype=torch.float64,\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "#steps: 5000\n",
    "print(loss_reward)\n",
    "print(loss_embedding)\n",
    "print(na)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0693, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3587, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([[[0.3825, 0.8234],\n",
      "         [0.6761, 1.9818],\n",
      "         [0.8022, 1.0552],\n",
      "         [0.5206, 2.0053],\n",
      "         [0.9305, 0.9750],\n",
      "         [1.3733, 1.1619],\n",
      "         [0.1467, 0.6618],\n",
      "         [1.0000, 1.0000]],\n",
      "\n",
      "        [[0.3825, 0.8234],\n",
      "         [0.6761, 1.9818],\n",
      "         [0.8022, 1.0552],\n",
      "         [0.5206, 2.0053],\n",
      "         [0.9305, 0.9750],\n",
      "         [1.3733, 1.1619],\n",
      "         [0.1467, 0.6618],\n",
      "         [1.0000, 1.0000]]], device='cuda:0', dtype=torch.float64,\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "#steps: 100\n",
    "print(loss_reward)\n",
    "print(loss_embedding)\n",
    "print(na)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8319, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor(0., device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([[[1.0000, 1.0000],\n",
      "         [1.0000, 1.0000],\n",
      "         [1.0000, 1.0000],\n",
      "         [1.0000, 1.0000],\n",
      "         [1.0000, 1.0000],\n",
      "         [1.0000, 1.0000],\n",
      "         [0.9900, 0.9900],\n",
      "         [1.0000, 1.0000]],\n",
      "\n",
      "        [[1.0000, 1.0000],\n",
      "         [1.0000, 1.0000],\n",
      "         [1.0000, 1.0000],\n",
      "         [1.0000, 1.0000],\n",
      "         [1.0000, 1.0000],\n",
      "         [1.0000, 1.0000],\n",
      "         [0.9900, 0.9900],\n",
      "         [1.0000, 1.0000]]], device='cuda:0', dtype=torch.float64,\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "#steps: 30\n",
    "print(loss_reward)\n",
    "print(loss_embedding)\n",
    "print(na)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.0000, 1.0000],\n",
       "         [1.0000, 1.0000],\n",
       "         [1.0000, 1.0000],\n",
       "         [1.0000, 1.0000],\n",
       "         [1.0000, 1.0000],\n",
       "         [1.0000, 1.0000],\n",
       "         [0.9800, 0.9800],\n",
       "         [1.0000, 1.0000]],\n",
       "\n",
       "        [[1.0000, 1.0000],\n",
       "         [1.0000, 1.0000],\n",
       "         [1.0000, 1.0000],\n",
       "         [1.0000, 1.0000],\n",
       "         [1.0000, 1.0000],\n",
       "         [1.0000, 1.0000],\n",
       "         [0.9800, 0.9800],\n",
       "         [1.0000, 1.0000]]], device='cuda:0', dtype=torch.float64,\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "na"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7650, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0., device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "optimize_sequence() got an unexpected keyword argument 'score_weight'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [73], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m loss, na, ns \u001b[39m=\u001b[39m optimize_sequence(actions\u001b[39m=\u001b[39;49mactions, seq_embeddings\u001b[39m=\u001b[39;49mseq_embeddings, mask\u001b[39m=\u001b[39;49mmask, goal_embeddings\u001b[39m=\u001b[39;49mgoal_embeddings, steps\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, detach\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, current_step\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, score_weight\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n",
      "\u001b[0;31mTypeError\u001b[0m: optimize_sequence() got an unexpected keyword argument 'score_weight'"
     ]
    }
   ],
   "source": [
    "loss, na, ns = optimize_sequence(actions=actions, seq_embeddings=seq_embeddings, mask=mask, goal_embeddings=goal_embeddings, steps=1, detach=True, current_step=1, score_weight=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1.],\n",
       "         [1., 1.],\n",
       "         [1., 1.],\n",
       "         [1., 1.],\n",
       "         [1., 1.],\n",
       "         [1., 1.],\n",
       "         [1., 1.],\n",
       "         [1., 1.]],\n",
       "\n",
       "        [[1., 1.],\n",
       "         [1., 1.],\n",
       "         [1., 1.],\n",
       "         [1., 1.],\n",
       "         [1., 1.],\n",
       "         [1., 1.],\n",
       "         [1., 1.],\n",
       "         [1., 1.]]], device='cuda:0', dtype=torch.float64, requires_grad=True)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('ac')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c27e8fa6375f4d15af5a5f5541d8bb88746b588c9fe1102cfd8de011d36c10c2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
