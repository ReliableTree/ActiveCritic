{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as th\n",
    "from active_critic.utils.pytorch_utils import calcMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_input(inpt:th.Tensor, ntokens:int, minimum:float, maximum:float):\n",
    "    output = th.zeros([inpt.shape[0], inpt.shape[1], ntokens*inpt.shape[2]])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "seq_len = 3\n",
    "dim = 4\n",
    "\n",
    "a = th.rand([batch_size, seq_len, dim])\n",
    "a[0,0,0] = -1\n",
    "a[0,0,1] = 1\n",
    "minimum = -1\n",
    "maximum = 1\n",
    "ntokens = 10\n",
    "scale = maximum - minimum\n",
    "trans_a = ((a - minimum) / scale)*(ntokens-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_indices(num, repeats):\n",
    "    indices = th.arange(num).reshape([1,-1]).repeat([repeats,1]).T.reshape([-1])\n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(inpt, minimum, maximum, ntokens):\n",
    "    scale = maximum - minimum\n",
    "    rec_inpt = ((inpt - minimum) / scale)*(ntokens-1)\n",
    "    rounded = th.round(rec_inpt).type(th.long).reshape([-1])\n",
    "    batch_indices = make_indices(batch_size, seq_len*dim).to(inpt.device)\n",
    "    seq_indices = make_indices(seq_len, dim).repeat(batch_size).to(inpt.device)\n",
    "    dim_indices = make_indices(dim, 1).repeat(batch_size*seq_len).to(inpt.device)\n",
    "    result = th.zeros([inpt.shape[0], inpt.shape[1], inpt.shape[2], ntokens], dtype=float, device=inpt.device)\n",
    "    result[tuple((batch_indices, seq_indices, dim_indices, rounded))] = 1\n",
    "    result = result.reshape([inpt.shape[0], inpt.shape[1], -1])\n",
    "    return result\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_result = tokenize(inpt=a, minimum=-1, maximum=1, ntokens=ntokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 40])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 5, 6],\n",
       "        [7, 5, 6]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_result.argmax(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detokenize(inpt:th.Tensor, minimum, maximum, ntokens):\n",
    "    exp_inpt = inpt.reshape([inpt.shape[0], inpt.shape[0], -1, ntokens])\n",
    "    values = exp_inpt.argmax(dim=-1)\n",
    "    scale = maximum - minimum\n",
    "    values = values/(ntokens-1) * scale\n",
    "    values = values.reshape([inpt.shape[0], inpt.shape[1], -1])\n",
    "    values = values + minimum\n",
    "    return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_a = detokenize(new_result, minimum=-1, maximum=1, ntokens=ntokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unstack_tokens(inpt, ntokens):\n",
    "    result = inpt.reshape([inpt.shape[0], inpt.shape[1], -1, ntokens])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "unstacked_result = unstack_tokens(new_result, ntokens=ntokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[True, True, True, True],\n",
       "         [True, True, True, True],\n",
       "         [True, True, True, True]],\n",
       "\n",
       "        [[True, True, True, True],\n",
       "         [True, True, True, True],\n",
       "         [True, True, True, True]]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "th.abs(a - new_a) < (maximum - minimum)/ntokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('ac')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "55d3bc2b8c4272bbea65d85e1c1c189fa11db70743df9511061edc4d7dc4f3cd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
