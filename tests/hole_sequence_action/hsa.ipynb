{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as th\n",
    "import torch.nn as nn\n",
    "from active_critic.model_src.state_model import StateModel, StateModelArgs\n",
    "from active_critic.model_src.whole_sequence_model import WholeSequenceModel, WholeSequenceModelArgs\n",
    "from active_critic.model_src.transformer import TransformerModel, ModelSetup\n",
    "from active_critic.utils.pytorch_utils import generate_square_subsequent_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_seq(actor:StateModel, predictor:WholeSequenceModel, seq_len:int, embeddings:th.Tensor, tf_mask:th.Tensor, actions:th.Tensor=None):\n",
    "    init_embedding = embeddings.detach().clone()\n",
    "    for i in range(seq_len):\n",
    "        embeddings = embeddings.detach()\n",
    "        if actions is None or actions.shape[1] == i:\n",
    "            actions = actor.forward(embeddings)\n",
    "        act_emb = th.cat((actions[:,:i+1], embeddings), dim=-1)\n",
    "        next_embedings = predictor.forward(inputs=act_emb, tf_mask=tf_mask[:i+1, :i+1])\n",
    "        embeddings = th.cat((init_embedding.clone(), next_embedings), dim=1)\n",
    "    return embeddings, actions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 3\n",
    "embedding_size = 20\n",
    "action_dim = 10\n",
    "layers = 2\n",
    "seq_len = 1\n",
    "ac_seq_len = 4\n",
    "\n",
    "ms = ModelSetup()\n",
    "ms.d_hid=20\n",
    "ms.d_model = 20\n",
    "ms.d_output=embedding_size\n",
    "ms.device='cpu'\n",
    "ms.dropout=0\n",
    "ms.nhead=1\n",
    "ms.nlayers=2\n",
    "ms.seq_len = ac_seq_len+1\n",
    "\n",
    "wsma = WholeSequenceModelArgs()\n",
    "wsma.model_setup = ms\n",
    "wsma.optimizer_class = th.optim.Adam\n",
    "wsma.lr = 1e-3\n",
    "wsma.name = 'test'\n",
    "\n",
    "predictor = WholeSequenceModel(args=wsma)\n",
    "\n",
    "sma = StateModelArgs()\n",
    "sma.arch = [10,action_dim]\n",
    "sma.device = 'cpu'\n",
    "sma.lr = 1e-3\n",
    "action_model = StateModel(args=sma)\n",
    "\n",
    "zero_actions = th.zeros([batch_size, ac_seq_len+1, action_dim], dtype=th.float32, requires_grad=True)\n",
    "\n",
    "init_embeddng = th.ones([batch_size, 1, embedding_size], requires_grad=True, dtype=th.float32)\n",
    "konstant_embedding = th.ones([batch_size, ac_seq_len+1, embedding_size])\n",
    "goal_embeddng = th.zeros([batch_size, embedding_size], requires_grad=True, dtype=th.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_mask = generate_square_subsequent_mask(ac_seq_len+1)\n",
    "embeddings, actions = build_seq(actor=action_model, predictor=predictor, seq_len=ac_seq_len, embeddings=init_embeddng, tf_mask=tf_mask, actions=zero_actions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "((embeddings[0,-1] - th.ones_like(embeddings[0,-1]))**2).mean().backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_list = []\n",
    "params_list += list(action_model.parameters())\n",
    "params_list+= list(predictor.parameters())\n",
    "\n",
    "optimizer = th.optim.Adam(params_list, lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______________________\n",
      "kl: 0.0006082796608097851\n",
      "el: 9.607563697500154e-05\n",
      "______________________\n",
      "kl: 0.0005140891298651695\n",
      "el: 6.922691682120785e-05\n",
      "______________________\n",
      "kl: 0.00047120917588472366\n",
      "el: 4.0036913560470566e-05\n",
      "______________________\n",
      "kl: 0.00044673739466816187\n",
      "el: 6.001058500260115e-05\n",
      "______________________\n",
      "kl: 0.00041722905007191\n",
      "el: 3.6524284951156005e-05\n",
      "______________________\n",
      "kl: 0.0003933057887479663\n",
      "el: 5.6502649385947734e-05\n",
      "______________________\n",
      "kl: 0.00037595638423226774\n",
      "el: 3.781697523663752e-05\n",
      "______________________\n",
      "kl: 0.0003434489481151104\n",
      "el: 7.229750917758793e-05\n",
      "______________________\n",
      "kl: 0.0003429613425396383\n",
      "el: 7.22010518074967e-05\n",
      "______________________\n",
      "kl: 0.00032454082975164056\n",
      "el: 3.0326085834531114e-05\n"
     ]
    }
   ],
   "source": [
    "tf_mask = generate_square_subsequent_mask(ac_seq_len+1)\n",
    "for i in range(100):\n",
    "    embeddings, actions = build_seq(actor=action_model, predictor=predictor, seq_len=ac_seq_len, embeddings=init_embeddng, tf_mask=tf_mask)\n",
    "    optimizer.zero_grad()\n",
    "    emb_loss = ((embeddings[:, -1] - goal_embeddng)**2).mean()\n",
    "    emb_loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    embeddings, actions = build_seq(actor=action_model, predictor=predictor, seq_len=ac_seq_len, embeddings=init_embeddng, tf_mask=tf_mask, actions=zero_actions)\n",
    "    optimizer.zero_grad()\n",
    "    konst_loss = ((embeddings - konstant_embedding)**2).mean()\n",
    "    konst_loss.backward()\n",
    "    optimizer.step()\n",
    "    if i % 10 == 0:\n",
    "        print('______________________')\n",
    "        print(f'kl: {konst_loss}')\n",
    "        print(f'el: {emb_loss}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('ac')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "55d3bc2b8c4272bbea65d85e1c1c189fa11db70743df9511061edc4d7dc4f3cd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
